<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/Echo/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/Echo/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/Echo/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/Echo/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="5ZQ9pmEjPOsQmbBYQoUK41fLaMMyEK5pDRa34TE8fW4">
  <meta name="msvalidate.01" content="58AE2D56435A76DA1BF1341C2E6930C1">

<link rel="stylesheet" href="/Echo/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hugfeature.github.io","root":"/Echo/","images":"/Echo/images","scheme":"Gemini","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/Echo/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/Echo/js/config.js"></script>
<meta name="description" content="曾经梦想仗剑走天涯!因为遇见她，所以回了家！">
<meta property="og:type" content="website">
<meta property="og:title" content="小缺の域">
<meta property="og:url" content="https://hugfeature.github.io/Echo/archives/index.html">
<meta property="og:site_name" content="小缺の域">
<meta property="og:description" content="曾经梦想仗剑走天涯!因为遇见她，所以回了家！">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="丑牛">
<meta property="article:tag" content="大数据测试，性能测试，测试，自动化测试，K8S，Kubernetes，接口测试，测试管理，测试计划，测试策略">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://hugfeature.github.io/Echo/archives/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"archives/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>小缺の域 - Stay hungry, Stay foolish</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-SY6RK3NESF"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"G-SY6RK3NESF","only_pageview":false}</script>
  <script src="/Echo/js/third-party/analytics/google-analytics.js"></script>




  <script async src="https://www.clarity.ms/tag/myblog"></script>

  <noscript>
    <link rel="stylesheet" href="/Echo/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/Echo/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">小缺の域</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Stay hungry, Stay foolish</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/Echo/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/Echo/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-categories"><a href="/Echo/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-commonweal"><a href="/Echo/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">丑牛</p>
  <div class="site-description" itemprop="description">曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-categories">
          <a href="/Echo/categories/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/Echo/tags/">
        <span class="site-state-item-count">68</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/hugfeature/" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;hugfeature&#x2F;" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdn.jsdelivr.net/npm/@creativecommons/vocabulary@2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/hugfeature" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/d8a49be1.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/d8a49be1.html" class="post-title-link" itemprop="url">SaaS测试</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-23 13:37:07" itemprop="dateCreated datePublished" datetime="2022-04-23T13:37:07+08:00">2022-04-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E6%B5%8B%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">测试</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="什么是SaaS？"><a href="#什么是SaaS？" class="headerlink" title="什么是SaaS？"></a>什么是SaaS？</h4><p>SaaS被称为软件即服务，可以通过网络轻松提供给客户，它可以帮助公司绕过相应计算机上运行和安装程序的需求，从而降低硬件购买、安装、维护和支持成本的费用。</p>
<h4 id="什么是SaaS测试？"><a href="#什么是SaaS测试？" class="headerlink" title="什么是SaaS测试？"></a>什么是SaaS测试？</h4><p>随着云计算概念在行业和研究社区中的进步，SaaS平台也通过在云上提供多样化的服务而获得了非凡的地位。在应用程序的开发过程完成后，SaaS应用程序测试开始发挥作用，其中整个测试周期的持续时间是根据选择服务的软件类型决定的。</p>
<p>此外，以定义格式说，SaaS平台测试被定义为通过进行不同的验证活动来确保软件质量的方法。</p>
<p>这些涉及测试性能，安全性，数据集成，可扩展性，可靠性等。Cisco Web Ex，Google Apps等是SaaS应用程序的一些着名示例，这些应用程序可在互联网上轻松访问并且不需要任何安装。</p>
<p>在这个竞争激烈的世界中，企业正在通过SaaS模型不断向云计算和软件交付迈进。它提供的好处，如“按需服务”和“按使用付费”是其背后的主要原因。</p>
<p>*<strong>了选择SaaS应用程序测试的更多原因：*</strong></p>
<ol>
<li>提高了可靠性、可扩展性和可用性</li>
<li>降低软件部署和维护成本</li>
<li>轻松恢复故障</li>
<li>快速部署具有更高可访问性的软件</li>
<li>按使用量付费</li>
<li>添加新租户时的持续升级测试</li>
<li>内部系统依赖性减少到多个级别</li>
<li>资源扩展和定价的灵活性</li>
<li>SaaS 应用程序可以轻松更新和升级（新版本），并可供客户使用。</li>
</ol>
<p>从上面的讨论中，可以很容易的看出，SaaS程序测试基本上是SaaS应用程序相对于各种组件（安全性、兼容性、性能）的验证。SaaS测试被认为提供最快，最有效的产品，但它需要在多个步骤中提供大量的质量保证。</p>
<h4 id="SaaS测试VS传统测试"><a href="#SaaS测试VS传统测试" class="headerlink" title="SaaS测试VS传统测试"></a>SaaS测试VS传统测试</h4><ul>
<li>产品以非常快的速度交付，因此“质量保证”成为一个值得关注的因素</li>
<li>它需要丰富的业务和领域知识来处理SaaS应用程序的可配置和不可配置组件</li>
<li>SaaS应用程序测试人员经过全面测试，以使用户能够利用此类应用程序的所有优势</li>
<li>测试环境应支持应用程序的自动部署、执行和验证</li>
<li>与传统测试相比，SaaS测试还具有以下优势：<ul>
<li>维护成本和应用程序升级成本更低</li>
<li>涉及的风险更小，因此更注重采用新的创新理念</li>
<li>按使用量付费</li>
<li>直接通过互联网轻松访问，无需安装任何软件。</li>
</ul>
</li>
</ul>
<p>综上SaaS应用测试与传统测试的方法有一些相似之处，但是SaaS比传统测试更难。</p>
<h4 id="SaaS开发生命周期"><a href="#SaaS开发生命周期" class="headerlink" title="SaaS开发生命周期"></a>SaaS开发生命周期</h4><p><img src="/Echo/posts/d8a49be1/saas2.jpg" alt="saas2"></p>
<ol>
<li>通过各种市场研究，这里确定了***设想阶段***的业务需求和机会。</li>
<li>***平台评估阶段***可确保正确检查并成功实施计划的功能，如性能、安全性、可伸缩性、灾难恢复等。</li>
<li>***规划阶段***包括将收集到的所有信息（如项目计划，规范，人员等）的形式化到开发人员所需的技术规范中。</li>
<li>*<strong>订阅阶段*</strong> 重要决策（包括体系结构、定价和灾难恢复策略）已最终确定，以确保服务的高可用性。</li>
<li>*<strong>开发阶段*<strong>顾名思义，设置了开发环境，包括各种形式的测试。SaaS应用程序应始终在重负载下工作，因此</strong>SaaS负载和性能测试</strong>起着重要作用。</li>
<li>***操作阶段***服务在此阶段部署。但是，需要对应用程序进行频繁的更新和安全检查，以增强用户体验并减少支持问题。</li>
</ol>
<h4 id="SaaS测试方法的重点"><a href="#SaaS测试方法的重点" class="headerlink" title="SaaS测试方法的重点"></a>SaaS测试方法的重点</h4><p>程序本身、基础结构和网络一般被认为是SaaS测试的核心组件。下面简单列一些SaaS的关键领域。</p>
<ul>
<li>白盒和黑盒测试作为组件测试的一部分</li>
<li>功能测试，严格检查应用程序是否按要求工作</li>
<li>执行集成测试以检查SaaS系统与其他系统的集成</li>
<li>对新测试用例执行探索性测试</li>
<li>测试网络安全、安全威胁、完整性和可访问性，作为基础架构和安全测试的一部分</li>
<li>确保SaaS连接的质量，并在可移植性和兼容性方面测试用户界面</li>
<li>应用程序中的任何升级、发布和数据迁移都需要适当的回归测试</li>
<li>执行可靠性测试以降低实时部署中的故障风险</li>
<li>执行每个可能的测试，以确保网络的安全性</li>
<li>由于 SaaS 应用程序预计具有繁重的负载，因此需要在多个环境中验证应用程序在峰值负载下的行为，从而进行性能和可伸缩性测试</li>
<li>当不同的人在不同的浏览器上访问应用程序时，应用程序的兼容性需要测试</li>
<li>每当添加新功能或更新旧功能时，都需要对 SaaS 应用程序进行持续的升级测试</li>
<li>执行 API 测试以确保文档的功能、安全性、完整性和性能</li>
<li>客户查询、付款和计费作为运营测试的一部分进行处理。</li>
</ul>
<h4 id="SaaS应用程序测试挑战"><a href="#SaaS应用程序测试挑战" class="headerlink" title="SaaS应用程序测试挑战"></a>SaaS应用程序测试挑战</h4><p>根据项目类型不同，SaaS测试会面临不同的挑战。在这里让我们看一下SaaS应用测试时遇到的一些常见挑战：</p>
<ol>
<li>在很短的时间内频繁升级和发布，可以减少检查应用程序的有效性和安全性的时间</li>
<li>有时，与应用程序的用户界面关联的后端组件有待验证</li>
<li>由于同时存在不同的用户行为，保护隐私并确保不交换客户数据成为一项非常困难的任务</li>
<li>我们已经讨论了为什么SaaS应用程序需要性能测试，但这方面的主要关注点和挑战是确定访问量最大的区域，并与来自不同位置的大量用户一起测试它们。</li>
<li>在SaaS应用程序的集成和迁移时，维护测试数据的隐私和完整性变得非常困难</li>
<li>每当发布新版本时，SaaS测试人员都需要测试所有许可因素，包括使用情况，用户数量和应用程序的功能</li>
<li>应用程序没有标准化。</li>
</ol>
<p>为了客服这些挑战，我们可以看一下其中常见的应对方法：</p>
<ul>
<li>自动执行脚本以应对频繁的更新挑战</li>
<li>根据观察结果，确定更频繁访问的应用程序区域。这将有助于在时间限制有限制时进行更好的性能测试</li>
<li>为了 SaaS 应用程序的数据安全性，建议在集成时进行强加密。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/c265aad9.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/c265aad9.html" class="post-title-link" itemprop="url">大数据面试-hbase</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-11 22:08:58" itemprop="dateCreated datePublished" datetime="2022-04-11T22:08:58+08:00">2022-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="一、HBASE的特点是什么？"><a href="#一、HBASE的特点是什么？" class="headerlink" title="一、HBASE的特点是什么？"></a>一、HBASE的特点是什么？</h4><p>1）大：一个表可以有数十亿行，上百万列；<br>2）无模式：每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一张表中不同的行可以有截然不同的列；<br>3）面向列：面向列（族）的存储和权限控制，列（族）独立检索；<br>4）稀疏：空（null）列并不占用存储空间，表可以设计的非常稀疏；<br>5）数据多版本：每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元格插入时的时间戳；<br>6）数据类型单一：Hbase 中的数据都是字符串，没有类型。</p>
<h4 id="二、HBASE适用于什么场景？"><a href="#二、HBASE适用于什么场景？" class="headerlink" title="二、HBASE适用于什么场景？"></a>二、HBASE适用于什么场景？</h4><p>① 半结构化或非结构化数据 对于数据结构字段不够确定或杂乱无章很难按一个概念去进行抽取的数据适合用 HBase。以上面的例子为例，当业务发展需要存储 author 的 email，phone， address 信息时 RDBMS 需要停机维护，而 HBase 支持动态增加。<br>② 记录非常稀疏<br>RDBMS 的行有多少列是固定的，为 null 的列浪费了存储空间。而如上文提到的，HBase 为 null 的 Column 不会被存储，这样既节省了空间又提高了读性能。<br>③ 多版本数据<br>如上文提到的根据 Row key 和 Column key 定位到的 Value 可以有任意数量的版本值，因此对于需要存储变动历史记录的数据，用 HBase 就非常方便了。比如上例中的 author 的 Address 是会变动的，业务上一般只需要最新的值，但有时可能需要查询到历史值。<br>④ 超大数据量<br>当数据量越来越大，RDBMS 数据库撑不住了，就出现了读写分离策略，通过一个 Master 专门负责写操作，多个 Slave 负责读操作，服务器成本倍增。 随着压力增加，Master 撑不住了，这时就要分库了，把关联不大的数据分开部署，一些 join 查询不能用了，需要借助中间层。随着数据量的进一步增加， 一个表的记录越来越大，查询就变得很慢，于是又得搞分表，比如按 ID 取模分成多个表以减少单个表的记录数。经历过这些事的人都知道过程是多么的折腾。 采用HBase 就简单了，只需要加机器即可，HBase 会自动水平切分扩展，跟Hadoop 的无缝集成保障了其数据可靠性（HDFS）和海量数据分析的高性能（MapReduce）。</p>
<h4 id="三、HBASE的rowkey的设计原则？"><a href="#三、HBASE的rowkey的设计原则？" class="headerlink" title="三、HBASE的rowkey的设计原则？"></a>三、HBASE的rowkey的设计原则？</h4><p>（1）Rowkey 长度原则<br>Rowkey 是一个二进制码流，Rowkey 的长度被很多开发者建议说设计在10~100 个字节，不过建议是越短越好，不要超过 16 个字节。<br>原因如下：<br>① 数据的持久化文件 HFile 中是按照 KeyValue 存储的，如果 Rowkey 过长比如 100 个字节，1000 万列数据光 Rowkey 就要占用 100*1000 万&#x3D;10 亿个字节， 将近 1G 数据，这会极大影响 HFile 的存储效率；<br>② MemStore 将缓存部分数据到内存，如果 Rowkey 字段过长内存的有效利用率会降低，系统将无法缓存更多的数据，这会降低检索效率。 因此 Rowkey的字节长度越短越好。<br>③ 目前操作系统是都是 64 位系统，内存 8 字节对齐。控制在 16 个字节，8字节的整数倍利用操作系统的最佳特性。<br>（2）Rowkey 散列原则<br>如果 Rowkey 是按时间戳的方式递增，不要将时间放在二进制码的前面，建议将 Rowkey 的高位作为散列字段，由程序循环生成，低位放时间字段， 这样将提高数据均衡分布在每个 Regionserver 实现负载均衡的几率。如果没有散列字段，首字段直接是时间信息将产生所有新数据都在一个 RegionServer 上堆积的 热点现象，这样在做数据检索的时候负载将会集中在个别RegionServer，降低查询效率。<br>（3）Rowkey 唯一原则<br>必须在设计上保证其唯一性。</p>
<h4 id="四、hbase中scan和get的功能以及实现的异同？"><a href="#四、hbase中scan和get的功能以及实现的异同？" class="headerlink" title="四、hbase中scan和get的功能以及实现的异同？"></a>四、hbase中scan和get的功能以及实现的异同？</h4><p>HBase 的查询实现只提供两种方式：<br>1）按指定 RowKey 获取唯一一条记录，get 方法（org.apache.hadoop.hbase.client.Get） Get 的方法处理分两种 : 设置了ClosestRowBefore 和 没有设置 ClosestRowBefore 的 rowlock。主要是用来保证行的事务性，即每个 get 是以一个 row 来标记的。一个 row 中可以有很多 family 和 column。<br>2）按指定的条件获取一批记录，scan 方法<br>(org.apache.Hadoop.hbase.client.Scan）实现条件查询功能使用的就是 scan方式。<br>（1）scan 可以通过 setCaching 与 setBatch 方法提高速度(以空间换时间)；<br>（2）scan 可以通过 setStartRow 与 setEndRow 来限定范围([start，end)start 是闭区间，end 是开区间)。范围越小，性能越高。<br>（3）scan 可以通过 setFilter 方法添加过滤器，这也是分页、多条件查询的基础。</p>
<h4 id="五、hbase中的cell结构？"><a href="#五、hbase中的cell结构？" class="headerlink" title="五、hbase中的cell结构？"></a>五、hbase中的cell结构？</h4><p>HBase 中通过 row 和 columns 确定的为一个存贮单元称为 cell。<br>Cell：由{row key, column(&#x3D; + ), version}唯一确定的单元。cell 中的数据是没有类型的，全部是字节码形式存贮。</p>
<h4 id="六、简述-HBase-中-compact-用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？"><a href="#六、简述-HBase-中-compact-用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？" class="headerlink" title="六、简述 HBase 中 compact 用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？"></a>六、简述 HBase 中 compact 用途是什么，什么时候触发，分为哪两种，有什么区别，有哪些相关配置参数？</h4><p>在 hbase 中每当有 memstore 数据 flush 到磁盘之后，就形成一个 storefile，当 storeFile 的数量达到一定程度后，就需要将 storefile 文件来 进行compaction 操作。<br>Compact 的作用：<br>① 合并文件<br>② 清除过期，多余版本的数据<br>③ 提高读写数据的效率<br>HBase 中实现了两种 compaction 的方式：minor and major. 这两种compaction 方式的区别是：<br>1）Minor 操作只用来做部分文件的合并操作以及包括 minVersion&#x3D;0 并且设置 ttl 的过期版本清理，不做任何删除数据、多版本数据的清理工作。<br>2）Major 操作是对 Region 下的 HStore 下的所有 StoreFile 执行合并操作，最终的结果是整理合并出一个文件。</p>
<h4 id="七、每天百亿数据存入-HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？"><a href="#七、每天百亿数据存入-HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？" class="headerlink" title="七、每天百亿数据存入 HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？"></a>七、每天百亿数据存入 HBase，如何保证数据的存储正确和在规定的时间里全部录入完毕，不残留数据？</h4><p>需求分析：<br>1）百亿数据：证明数据量非常大；<br>2）存入 HBase：证明是跟 HBase 的写入数据有关；<br>3）保证数据的正确：要设计正确的数据结构保证正确性；<br>4）在规定时间内完成：对存入速度是有要求的。<br>解决思路：<br>1）数据量百亿条，什么概念呢？假设一整天 60x60x24 &#x3D; 86400 秒都在写入数据，那么每秒的写入条数高达 100 万条，HBase 当然是支持不了每秒百万条数据的， 所以这百亿条数据可能不是通过实时地写入，而是批量地导入。批量导入推荐使用 BulkLoad 方式（推荐阅读：Spark 之读写 HBase），性能是普通写入方式几倍以上；<br>2）存入 HBase：普通写入是用 JavaAPI put 来实现，批量导入推荐使用BulkLoad；<br>3）保证数据的正确：这里需要考虑 RowKey 的设计、预建分区和列族设计等问题；<br>4）在规定时间内完成也就是存入速度不能过慢，并且当然是越快越好，使用BulkLoad。</p>
<h4 id="八、hbase优化方法？"><a href="#八、hbase优化方法？" class="headerlink" title="八、hbase优化方法？"></a>八、hbase优化方法？</h4><p>1）减少调整<br>减少调整这个如何理解呢？HBase 中有几个内容会动态调整，如 region（分区）、HFile，所以通过一些方法来减少这些会带来 I&#x2F;O 开销的调整。<br>① Region<br>如果没有预建分区的话，那么随着 region 中条数的增加，region 会进行分裂，这将增加 I&#x2F;O 开销，所以解决方法就是根据你的 RowKey 设计来进行预建分区， 减少 region 的动态分裂。<br>② HFile<br>HFile 是数据底层存储文件，在每个 memstore 进行刷新时会生成一个HFile，当 HFile 增加到一定程度时，会将属于一个 region 的 HFile 进行合并，这个步骤会带来开销但不可避免，但是合并后 HFile 大小如果大于设定的值，那么 HFile 会重新分裂。为了减少这样的无谓的 I&#x2F;O 开销，建议估计项目数据量大小， 给 HFile 设定一个合适的值。<br>2）减少启停<br>数据库事务机制就是为了更好地实现批量写入，较少数据库的开启关闭带来的开销，那么 HBase 中也存在频繁开启关闭带来的问题。<br>① 关闭 Compaction，在闲时进行手动 Compaction。<br>因为 HBase 中存在 Minor Compaction 和 Major Compaction，也就是对HFile 进行合并，所谓合并就是 I&#x2F;O 读写，大量的 HFile 进行肯定会带来 I&#x2F;O开销， 甚至是 I&#x2F;O 风暴，所以为了避免这种不受控制的意外发生，建议关闭自动 Compaction，在闲时进行 compaction。<br>② 批量数据写入时采用 BulkLoad。<br>如果通过 HBase-Shell 或者 JavaAPI 的 put 来实现大量数据的写入，那么性能差是肯定并且还可能带来一些意想不到的问题，所以当需要写入大量离线数据时 建议使用 BulkLoad。<br>3）减少数据量<br>虽然我们是在进行大数据开发，但是如果可以通过某些方式在保证数据准确性同时减少数据量，何乐而不为呢？<br>① 开启过滤，提高查询速度<br>开启 BloomFilter，BloomFilter 是列族级别的过滤，在生成一个 StoreFile同时会生成一个 MetaBlock，用于查询时过滤数据<br>② 使用压缩<br>一般推荐使用 Snappy 和 LZO 压缩<br>4）合理设计<br>在一张 HBase 表格中 RowKey 和 ColumnFamily 的设计是非常重要，好的设计能够提高性能和保证数据的准确性<br>① RowKey 设计：应该具备以下几个属性<br>散列性：散列性能够保证相同相似的 rowkey 聚合，相异的 rowkey 分散，有利于查询。<br>简短性：rowkey 作为 key 的一部分存储在 HFile 中，如果为了可读性将rowKey 设计得过长，那么将会增加存储压力。<br>唯一性：rowKey 必须具备明显的区别性。<br>业务性：举例来说：<br>假如我的查询条件比较多，而且不是针对列的条件，那么 rowKey 的设计就应该支持多条件查询。<br>如果我的查询要求是最近插入的数据优先，那么 rowKey 则可以采用叫上Long.Max-时间戳的方式，这样 rowKey 就是递减排列。<br>② 列族的设计：列族的设计需要看应用场景<br>优势：HBase 中数据时按列进行存储的，那么查询某一列族的某一列时就不需要全盘扫描，只需要扫描某一列族，减少了读 I&#x2F;O； 其实多列族设计对减少的作用不是很明显，适用于读多写少的场景<br>劣势：降低了写的 I&#x2F;O 性能。原因如下：数据写到 store 以后是先缓存在memstore 中，同一个 region 中存在多个列族则存在多个 store， 每个 store都一个 memstore，当其实 memstore 进行 flush 时，属于同一个 region 的store 中的 memstore 都会进行 flush，增加 I&#x2F;O 开销。</p>
<h4 id="九、region如何预建分区？"><a href="#九、region如何预建分区？" class="headerlink" title="九、region如何预建分区？"></a>九、region如何预建分区？</h4><p>预分区的目的主要是在创建表的时候指定分区数，提前规划表有多个分区，以及每个分区的区间范围，这样在存储的时候 rowkey 按照分区的区间存储，可以避免 region 热点问题。<br>通常有两种方案：<br>方案 1：shell 方法create ‘tb_splits’, {NAME &#x3D;&gt; ‘cf’,VERSIONS&#x3D;&gt; 3},{SPLITS &#x3D;&gt;[‘10’,’20’,’30’]}<br>方案 2：JAVA 程序控制<br>① 取样，先随机生成一定数量的 rowkey,将取样数据按升序排序放到一个集合里；<br>② 根据预分区的 region 个数，对整个集合平均分割，即是相关的 splitKeys；<br>③ HBaseAdmin.createTable(HTableDescriptortableDescriptor,byte[][]splitkeys)可以指定预分区的 splitKey， 即是指定region 间的 rowkey 临界值。</p>
<h4 id="十、HRegionServer-宕机如何处理？"><a href="#十、HRegionServer-宕机如何处理？" class="headerlink" title="十、HRegionServer 宕机如何处理？"></a>十、HRegionServer 宕机如何处理？</h4><p>1）ZooKeeper 会监控 HRegionServer 的上下线情况，当 ZK 发现某个HRegionServer 宕机之后会通知 HMaster 进行失效备援；<br>2）该 HRegionServer 会停止对外提供服务，就是它所负责的 region 暂时停止对外提供服务；<br>3）HMaster 会将该 HRegionServer 所负责的 region 转移到其他HRegionServer 上，并且会对 HRegionServer 上存在 memstore 中还未持久化到磁盘中的数据进行恢复；<br>4）这个恢复的工作是由 WAL 重播来完成，这个过程如下：<br>① wal 实际上就是一个文件，存在&#x2F;hbase&#x2F;WAL&#x2F;对应 RegionServer 路径下。<br>② 宕机发生时，读取该 RegionServer 所对应的路径下的 wal 文件，然后根据不同的 region 切分成不同的临时文件 recover.edits。<br>③ 当 region 被分配到新的 RegionServer 中，RegionServer 读取 region时会进行是否存在 recover.edits，如果有则进行恢复。</p>
<h4 id="十一、habse读写流程？"><a href="#十一、habse读写流程？" class="headerlink" title="十一、habse读写流程？"></a>十一、habse读写流程？</h4><p>读：<br>① HRegionServer 保存着 meta 表以及表数据，要访问表数据，首先 Client先去访问 zookeeper，从 zookeeper 里面获取 meta 表所在的位置信息， 即找到这个 meta 表在哪个 HRegionServer 上保存着。<br>② 接着 Client 通过刚才获取到的 HRegionServer 的 IP 来访问 Meta 表所在的 HRegionServer，从而读取到 Meta，进而获取到 Meta 表中存放的元数据。<br>③ Client 通过元数据中存储的信息，访问对应的 HRegionServer，然后扫描所在 HRegionServer 的 Memstore 和 Storefile 来查询数据。<br>④ 最后 HRegionServer 把查询到的数据响应给 Client。<br>写：<br>① Client 先访问 zookeeper，找到 Meta 表，并获取 Meta 表元数据。<br>② 确定当前将要写入的数据所对应的 HRegion 和 HRegionServer 服务器。<br>③ Client 向该 HRegionServer 服务器发起写入数据请求，然后HRegionServer 收到请求并响应。<br>④ Client 先把数据写入到 HLog，以防止数据丢失。<br>⑤ 然后将数据写入到 Memstore。<br>⑥ 如果 HLog 和 Memstore 均写入成功，则这条数据写入成功。<br>⑦ 如果 Memstore 达到阈值，会把 Memstore 中的数据 flush 到 Storefile中。<br>⑧ 当 Storefile 越来越多，会触发 Compact 合并操作，把过多的 Storefile合并成一个大的 Storefile。<br>⑨ 当 Storefile 越来越大，Region 也会越来越大，达到阈值后，会触发 Split操作，将 Region 一分为二。</p>
<h4 id="十二、habse的内部机制是什么？"><a href="#十二、habse的内部机制是什么？" class="headerlink" title="十二、habse的内部机制是什么？"></a>十二、habse的内部机制是什么？</h4><p>Hbase 是一个能适应联机业务的数据库系统<br>物理存储：hbase 的持久化数据是将数据存储在 HDFS 上。<br>存储管理：一个表是划分为很多 region 的，这些 region 分布式地存放在很多 regionserver 上 Region 内部还可以划分为 store， store 内部有<br>memstore 和 storefile。<br>版本管理：hbase 中的数据更新本质上是不断追加新的版本，通过 compact操作来做版本间的文件合并 Region 的 split。<br>集群管理：ZooKeeper + HMaster + HRegionServer。</p>
<h4 id="十三、Hbase-中的-memstore-是用来做什么的？"><a href="#十三、Hbase-中的-memstore-是用来做什么的？" class="headerlink" title="十三、Hbase 中的 memstore 是用来做什么的？"></a>十三、Hbase 中的 memstore 是用来做什么的？</h4><p>hbase 为了保证随机读取的性能，所以 hfile 里面的 rowkey 是有序的。当客户端的请求在到达 regionserver 之后，为了保证写入 rowkey 的有序性， 所以不能将数据立刻写入到 hfile 中，而是将每个变更操作保存在内存中，也就是memstore 中。memstore 能够很方便的支持操作的随机插入， 并保证所有的操作在内存中是有序的。当 memstore 达到一定的量之后，会将 memstore里面的数据 flush 到 hfile 中，这样能充分利用 hadoop 写入大文件的性能优势， 提高写入性能。<br>由于 memstore 是存放在内存中，如果 regionserver 因为某种原因死了，会导致内存中数据丢失。所有为了保证数据不丢失， hbase 将更新操作在写入memstore 之前会写入到一个 write ahead log(WAL)中。WAL 文件是追加、顺序写入的，WAL 每个 regionserver 只有一个， 同一个 regionserver 上所有 region 写入同一个的 WAL 文件。这样当某个 regionserver 失败时，可以通过 WAL 文件，将所有的操作顺序重新加载到 memstore 中。</p>
<h4 id="十四、HBase-在进行模型设计时重点在什么地方？一张表中定义多少个Column-Family-最合适？为什么？"><a href="#十四、HBase-在进行模型设计时重点在什么地方？一张表中定义多少个Column-Family-最合适？为什么？" class="headerlink" title="十四、HBase 在进行模型设计时重点在什么地方？一张表中定义多少个Column Family 最合适？为什么？"></a>十四、HBase 在进行模型设计时重点在什么地方？一张表中定义多少个Column Family 最合适？为什么？</h4><p>Column Family 的个数具体看表的数据，一般来说划分标准是根据数据访问频度，如一张表里有些列访问相对频繁，而另一些列访问很少， 这时可以把这张表划分成两个列族，分开存储，提高访问效率。</p>
<h4 id="十五、如何提高-HBase-客户端的读写性能？请举例"><a href="#十五、如何提高-HBase-客户端的读写性能？请举例" class="headerlink" title="十五、如何提高 HBase 客户端的读写性能？请举例"></a>十五、如何提高 HBase 客户端的读写性能？请举例</h4><p>① 开启 bloomfilter 过滤器，开启 bloomfilter 比没开启要快 3、4 倍<br>② Hbase 对于内存有特别的需求，在硬件允许的情况下配足够多的内存给它<br>③ 通过修改 hbase-env.sh 中的 export HBASE_HEAPSIZE&#x3D;3000 #这里默认为 1000m<br>④ 增大 RPC 数量<br>通过修改 hbase-site.xml 中的 hbase.regionserver.handler.count 属性，可以适当的放大 RPC 数量，默认值为 10 有点小。</p>
<h4 id="十六、hbase集群安装注意事项？"><a href="#十六、hbase集群安装注意事项？" class="headerlink" title="十六、hbase集群安装注意事项？"></a>十六、hbase集群安装注意事项？</h4><p>① HBase 需要 HDFS 的支持，因此安装 HBase 前确保 Hadoop 集群安装完<br>成；<br>② HBase 需要 ZooKeeper 集群的支持，因此安装 HBase 前确保ZooKeeper 集群安装完成；<br>③ 注意 HBase 与 Hadoop 的版本兼容性；<br>④ 注意 hbase-env.sh 配置文件和 hbase-site.xml 配置文件的正确配置；<br>⑤ 注意 regionservers 配置文件的修改；<br>⑥ 注意集群中的各个节点的时间必须同步，否则启动 HBase 集群将会报错。</p>
<h4 id="十七、直接将时间戳作为行健，在写入单个-region-时候会发生热点问题，为什么呢？"><a href="#十七、直接将时间戳作为行健，在写入单个-region-时候会发生热点问题，为什么呢？" class="headerlink" title="十七、直接将时间戳作为行健，在写入单个 region 时候会发生热点问题，为什么呢？"></a>十七、直接将时间戳作为行健，在写入单个 region 时候会发生热点问题，为什么呢？</h4><p>region 中的 rowkey 是有序存储，若时间比较集中。就会存储到一个 region中，这样一个 region 的数据变多，其它的 region 数据很少，加载数据就会很慢， 直到 region 分裂，此问题才会得到缓解。</p>
<h4 id="十八、如何解决-HBase-中-region-太小和-region-太大带来的冲突？"><a href="#十八、如何解决-HBase-中-region-太小和-region-太大带来的冲突？" class="headerlink" title="十八、如何解决 HBase 中 region 太小和 region 太大带来的冲突？"></a>十八、如何解决 HBase 中 region 太小和 region 太大带来的冲突？</h4><p>Region 过大会发生多次 compaction，将数据读一遍并重写一遍到 hdfs 上，占用 io，region 过小会造成多次 split，region 会下线，影响访问服务， 最佳的解决方法是调整 hbase.hregion. max.filesize 为 256m。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/403dd0d9.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/403dd0d9.html" class="post-title-link" itemprop="url">大数据面试-hive</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-11 21:28:49" itemprop="dateCreated datePublished" datetime="2022-04-11T21:28:49+08:00">2022-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="一、hive表关联查询，如何解决数据倾斜问题？"><a href="#一、hive表关联查询，如何解决数据倾斜问题？" class="headerlink" title="一、hive表关联查询，如何解决数据倾斜问题？"></a>一、hive表关联查询，如何解决数据倾斜问题？</h4><p>1）倾斜原因：map 输出数据按 key Hash 的分配到 reduce 中，由于 key 分布不均匀、业务数据本身的特、建表时考虑不周、等原因造成的 reduce 上的数据量差异过大。<br>（1）key 分布不均匀;<br>（2）业务数据本身的特性;<br>（3）建表时考虑不周;<br>（4）某些 SQL 语句本身就有数据倾斜;<br>如何避免：对于 key 为空产生的数据倾斜，可以对其赋予一个随机值。<br>2）解决方案<br>（1）参数调节：<br>hive.map.aggr &#x3D; true<br>hive.groupby.skewindata&#x3D;true<br>有数据倾斜的时候进行负载均衡，当选项设定位 true,生成的查询计划会有两个 MR Job。第一个 MR Job 中，Map 的输出结果集合会随机分布到 Reduce中，每个 Reduce 做部分聚合操作，并输出结果，这样处理的结果是相同的<br>Group By Key 有可能被分发到不同的 Reduce 中，从而达到负载均衡的目的；第二个 MR Job 再根据预处理的数据结果按照 Group By Key 分布到 Reduce中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成最终的聚合操作。<br>（2）SQL 语句调节：<br>① 选用 join key 分布最均匀的表作为驱动表。做好列裁剪和 filter 操作，以达到两表做 join 的时候，数据量相对变小的效果。<br>② 大小表 Join：<br>使用 map join 让小的维度表（1000 条以下的记录条数）先进内存。在map 端完成 reduce。<br>③ 大表 Join 大表：<br>把空值的 key 变成一个字符串加上随机数，把倾斜的数据分到不同的reduce 上，由于 null 值关联不上，处理后并不影响最终结果。<br>④ count distinct 大量相同特殊值:<br>count distinct 时，将值为空的情况单独处理，如果是计算 count distinct，可以不用处理，直接过滤，在最后结果中加 1。如果还有其他计算，需要进行group by，可以先将值为空的记录单独处理，再和其他计算结果进行 union。</p>
<h4 id="二、hive的HSQL转换为MapReduce的过程？"><a href="#二、hive的HSQL转换为MapReduce的过程？" class="headerlink" title="二、hive的HSQL转换为MapReduce的过程？"></a>二、hive的HSQL转换为MapReduce的过程？</h4><p>HiveSQL -&gt;AST(抽象语法树) -&gt; QB(查询块) -&gt;OperatorTree（操作树）-&gt;优化后的操作树-&gt;mapreduce 任务树-&gt;优化后的 mapreduce 任务树<br>过程描述如下：<br>SQL Parser：Antlr 定义 SQL 的语法规则，完成 SQL 词法，语法解析，将SQL 转化为抽象语法树 AST Tree；<br>Semantic Analyzer：遍历 AST Tree，抽象出查询的基本组成单元<br>QueryBlock；<br>Logical plan：遍历 QueryBlock，翻译为执行操作树 OperatorTree；</p>
<p>Logical plan optimizer: 逻辑层优化器进行 OperatorTree 变换，合并不必要的 ReduceSinkOperator，减少 shuffle 数据量；<br>Physical plan：遍历 OperatorTree，翻译为 MapReduce 任务；<br>Logical plan optimizer：物理层优化器进行 MapReduce 任务的变换，生成最终的执行计划。</p>
<h4 id="三、hive与底层数据库交互原理？"><a href="#三、hive与底层数据库交互原理？" class="headerlink" title="三、hive与底层数据库交互原理？"></a>三、hive与底层数据库交互原理？</h4><p>由于 Hive 的元数据可能要面临不断地更新、修改和读取操作，所以它显然不适合使用 Hadoop 文件系统进行存储。目前 Hive 将元数据存储在 RDBMS 中，比如存储在 MySQL、Derby 中。元数据信息包括：存在的表、表的列、权限和更多的其他信息。</p>
<h4 id="四、hive的两张表关联，使用MapReduce怎么实现？"><a href="#四、hive的两张表关联，使用MapReduce怎么实现？" class="headerlink" title="四、hive的两张表关联，使用MapReduce怎么实现？"></a>四、hive的两张表关联，使用MapReduce怎么实现？</h4><p>如果其中有一张表为小表，直接使用 map 端 join 的方式（map 端加载小表）进行聚合。<br>如果两张都是大表，那么采用联合 key，联合 key 的第一个组成部分是 joinon 中的公共字段，第二部分是一个 flag，0 代表表 A，1 代表表 B，由此让Reduce 区分客户信息和订单信息；在 Mapper 中同时处理两张表的信息，将join on 公共字段相同的数据划分到同一个分区中，进而传递到一个 Reduce中，然后在 Reduce 中实现聚合。</p>
<h4 id="五、hive的特点？"><a href="#五、hive的特点？" class="headerlink" title="五、hive的特点？"></a>五、hive的特点？</h4><p>hive 是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的 sql 查询功能，可以将 sql 语句转换为MapReduce 任务进行运行。其优点是学习成本低，可以通过类 SQL 语句快速实现简单的 MapReduce 统计，不必开发专门的 MapReduce 应用，十分适合数据仓库的统计分析，但是 Hive 不支持实时查询。</p>
<h4 id="六、hive中的Sort-By，Order-By，Cluster-By，Distrbute-By各代表什么？"><a href="#六、hive中的Sort-By，Order-By，Cluster-By，Distrbute-By各代表什么？" class="headerlink" title="六、hive中的Sort By，Order By，Cluster By，Distrbute By各代表什么？"></a>六、hive中的Sort By，Order By，Cluster By，Distrbute By各代表什么？</h4><p>order by：会对输入做全局排序，因此只有一个 reducer（多个 reducer 无法保证全局有序）。只有一个 reducer，会导致当输入规模较大时，需要较长的计算时间。<br>sort by：不是全局排序，其在数据进入 reducer 前完成排序。<br>distribute by：按照指定的字段对数据进行划分输出到不同的 reduce 中。<br>cluster by：除了具有 distribute by 的功能外还兼具 sort by 的功能。</p>
<h4 id="七、写出hive中split、coalesce及collect-list函数的用法？"><a href="#七、写出hive中split、coalesce及collect-list函数的用法？" class="headerlink" title="七、写出hive中split、coalesce及collect_list函数的用法？"></a>七、写出hive中split、coalesce及collect_list函数的用法？</h4><p>split 将字符串转化为数组，即：split(‘a,b,c,d’ , ‘,’) &#x3D;&#x3D;&gt; [“a”,”b”,”c”,”d”]。<br>coalesce(T v1, T v2, …) 返回参数中的第一个非空值；如果所有值都为 NULL，那么返回 NULL。<br>collect_list 列出该字段所有的值，不去重 &#x3D;&gt; select collect_list(id) from table。</p>
<h4 id="八、Hive-有哪些方式保存元数据，各有哪些特点？"><a href="#八、Hive-有哪些方式保存元数据，各有哪些特点？" class="headerlink" title="八、Hive 有哪些方式保存元数据，各有哪些特点？"></a>八、Hive 有哪些方式保存元数据，各有哪些特点？</h4><p>Hive 支持三种不同的元存储服务器，分别为：内嵌式元存储服务器、本地元存储服务器、远程元存储服务器，每种存储方式使用不同的配置参数。</p>
<p>内嵌式元存储主要用于单元测试，在该模式下每次只有一个进程可以连接到元存储，Derby 是内嵌式元存储的默认数据库。</p>
<p>在本地模式下，每个 Hive 客户端都会打开到数据存储的连接并在该连接上请求 SQL 查询。<br>在远程模式下，所有的 Hive 客户端都将打开一个到元数据服务器的连接，该服务器依次查询元数据，元数据服务器和客户端之间使用 Thrift 协议通信。</p>
<h4 id="九、hive内部表和外部表的区别？"><a href="#九、hive内部表和外部表的区别？" class="headerlink" title="九、hive内部表和外部表的区别？"></a>九、hive内部表和外部表的区别？</h4><p>创建表时：创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。<br>删除表时：在删除表的时候，内部表的元数据和数据会被一起删除， 而外部表只删除元数据，不删除数据。这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。</p>
<h4 id="十、hive中的压缩格式TextFile、SequenceFile、RCFile、ORCFile的区别？"><a href="#十、hive中的压缩格式TextFile、SequenceFile、RCFile、ORCFile的区别？" class="headerlink" title="十、hive中的压缩格式TextFile、SequenceFile、RCFile、ORCFile的区别？"></a>十、hive中的压缩格式TextFile、SequenceFile、RCFile、ORCFile的区别？</h4><p>1、TextFile<br>默认格式，存储方式为行存储，数据不做压缩，磁盘开销大，数据解析开销大。可结合 Gzip、Bzip2 使用(系统自动检查，执行查询时自动解压)，但使用这种方式，压缩后的文件不支持 split，Hive 不会对数据进行切分，从而无法对数据进行并行操作。并且在反序列化过程中，必须逐个字符判断是不是分隔符和行结束符，因此反序列化开销会比 SequenceFile 高几十倍。<br>2、SequenceFile<br>SequenceFile 是 Hadoop API 提供的一种二进制文件支持，存储方式为行存储，其具有使用方便、可分割、可压缩的特点。<br>SequenceFile 支持三种压缩选择：NONE，RECORD，BLOCK。Record 压缩率低，一般建议使用 BLOCK 压缩。优势是文件和 hadoop api 中的 MapFile 是相互兼容的<br>3、RCFile<br>存储方式：数据按行分块，每块按列存储。结合了行存储和列存储的优点：<br>首先，RCFile 保证同一行的数据位于同一节点，因此元组重构的开销很低；<br>其次，像列存储一样，RCFile 能够利用列维度的数据压缩，并且能跳过不必要的列读取；<br>4、ORCFile<br>存储方式：数据按行分块 每块按照列存储。<br>压缩快、快速列存取。<br>效率比 rcfile 高，是 rcfile 的改良版本。<br>总结：相比 TEXTFILE 和 SEQUENCEFILE，RCFILE 由于列式存储方式，数据加载时性能消耗较大，但是具有较好的压缩比和查询响应。数据仓库的特点是一次写入、多次读取，因此，整体来看，RCFILE 相比其余两种格式具有较明显的优势。</p>
<h4 id="十一、所有的hive任务都会有MapReduce的执行吗？"><a href="#十一、所有的hive任务都会有MapReduce的执行吗？" class="headerlink" title="十一、所有的hive任务都会有MapReduce的执行吗？"></a>十一、所有的hive任务都会有MapReduce的执行吗？</h4><p>不是，从 Hive0.10.0 版本开始，对于简单的不需要聚合的类似 SELECT from LIMIT n 语句，不需要起 MapReduce job，直接通过 Fetch task 获取数据。</p>
<h4 id="十二、Hive-的函数：UDF、UDAF、UDTF-的区别？"><a href="#十二、Hive-的函数：UDF、UDAF、UDTF-的区别？" class="headerlink" title="十二、Hive 的函数：UDF、UDAF、UDTF 的区别？"></a>十二、Hive 的函数：UDF、UDAF、UDTF 的区别？</h4><p>UDF：单行进入，单行输出<br>UDAF：多行进入，单行输出<br>UDTF：单行输入，多行输出</p>
<h4 id="十三、hive的桶表？"><a href="#十三、hive的桶表？" class="headerlink" title="十三、hive的桶表？"></a>十三、hive的桶表？</h4><p>桶表是对数据进行哈希取值，然后放到不同文件中存储。<br>数据加载到桶表时，会对字段取 hash 值，然后与桶的数量取模。把数据放到对应的文件中。物理上，每个桶就是表(或分区）目录里的一个文件，一个作业产生的桶(输出文件)和 reduce 任务个数相同。<br>桶表专门用于抽样查询，是很专业性的，不是日常用来存储数据的表，需要抽样查询时，才创建和使用桶表。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/d1e68f18.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/d1e68f18.html" class="post-title-link" itemprop="url">大数据面试-spark</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-10 14:57:03" itemprop="dateCreated datePublished" datetime="2022-04-10T14:57:03+08:00">2022-04-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="一、spark如何保证宕机迅速恢复？"><a href="#一、spark如何保证宕机迅速恢复？" class="headerlink" title="一、spark如何保证宕机迅速恢复？"></a>一、spark如何保证宕机迅速恢复？</h4><p>适当增加 spark standby master编写 shell 脚本，定期检测 master 状态，出现宕机后对 master 进行重启操作。</p>
<h4 id="二、spark-streaming以及基本工作原理？"><a href="#二、spark-streaming以及基本工作原理？" class="headerlink" title="二、spark streaming以及基本工作原理？"></a>二、spark streaming以及基本工作原理？</h4><p>Spark streaming 是 spark core API 的一种扩展，可以用于进行大规模、高吞吐量、容错的实时数据流的处理。<br>它支持从多种数据源读取数据，比如 Kafka、Flume、Twitter 和 TCP Socket，并且能够使用算子比如 map、reduce、join 和 window 等来处理数据，处理后的数据可以保存到文件系统、数据库等存储中。<br>Spark streaming 内部的基本工作原理是：接受实时输入数据流，然后将数据拆分成batch，比如每收集一秒的数据封装成一个 batch，然后将每个 batch 交给 spark 的计算引擎进行处理，最后会生产处一个结果数据流，其中的数据也是一个一个的batch 组成的。</p>
<h4 id="三、spark有哪些组件？"><a href="#三、spark有哪些组件？" class="headerlink" title="三、spark有哪些组件？"></a>三、spark有哪些组件？</h4><p>master：管理集群和节点，不参与计算。</p>
<p>worker：计算节点，进程本身不参与计算，和 master 汇报。</p>
<p>Driver：运行程序的 main 方法，创建 spark context 对象。</p>
<p>spark context：控制整个 application 的生命周期，包括 dagsheduler 和 task scheduler等组件。</p>
<p>client：用户提交程序的入口。</p>
<h4 id="四、spark工作机制？"><a href="#四、spark工作机制？" class="headerlink" title="四、spark工作机制？"></a>四、spark工作机制？</h4><p>用户在 client 端提交作业后，会由 Driver 运行 main 方法并创建 spark context 上下文。执行 add 算子，形成 dag图输入 dagscheduler，按照 add 之间的依赖关系划分stage 输入 task scheduler。task scheduler 会将 stage 划分为 task set 分发到各个节点的 executor 中执行。</p>
<h4 id="五、spark主备切换机制原理？"><a href="#五、spark主备切换机制原理？" class="headerlink" title="五、spark主备切换机制原理？"></a>五、spark主备切换机制原理？</h4><p>Master 实际上可以配置两个，Spark 原生的 standalone 模式是支持 Master 主备切换的。当 Active Master 节点挂掉以后，我们可以将 Standby Master 切换为 ActiveMaster。<br>Spark Master 主备切换可以基于两种机制，一种是基于文件系统的，一种是基于ZooKeeper 的。基于文件系统的主备切换机制，需要在 Active Master 挂掉之后手动切换到 StandbyMaster 上；而基于 Zookeeper 的主备切换机制，可以实现自动切换 Master。</p>
<h4 id="六、spark有几种部署模式，每种模式特点？"><a href="#六、spark有几种部署模式，每种模式特点？" class="headerlink" title="六、spark有几种部署模式，每种模式特点？"></a>六、spark有几种部署模式，每种模式特点？</h4><p>1）本地模式<br>Spark 不一定非要跑在 hadoop 集群，可以在本地，起多个线程的方式来指定。将 Spark 应用以多线程的方式直接运行在本地，一般都是为了方便调试，<br>本地模式分三类<br>local：只启动一个 executor<br>local[k]:启动 k 个 executor<br>local[*]：启动跟 cpu 数目相同的 executor<br>2）standalone 模式<br>分布式部署集群，自带完整的服务，资源管理和任务监控是 Spark 自己监控，这个模式也是其他模式的基础。<br>3）Spark on yarn 模式<br>分布式部署集群，资源和任务监控交给 yarn 管理，但是目前仅支持粗粒度资源分配方式，包含 cluster 和 client 运行模式，cluster 适合生产，driver 运行在集群子节点，具有容错功能，client 适合调试，dirver 运行在客户端。<br>4）Spark On Mesos 模式。<br>官方推荐这种模式（当然，原因之一是血缘关系）。正是由于 Spark 开发之初就考虑到支持 Mesos，因此，目前而言，Spark 运行在 Mesos 上会比运行在 YARN 上更加灵活，更加自然。用户可选择两种调度模式之一运行自己的应用程序：<br>（1）粗粒度模式（Coarse-grained Mode）：每个应用程序的运行环境由一个 Dirver 和若干个 Executor 组成，其中，每个 Executor 占用若干资源，内部可运行多个 Task（对应多少个“slot”）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。<br>（2）细粒度模式（Fine-grained Mode）：鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos 还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。</p>
<h4 id="七、Spark-为什么比-mapreduce-快？"><a href="#七、Spark-为什么比-mapreduce-快？" class="headerlink" title="七、Spark 为什么比 mapreduce 快？"></a>七、Spark 为什么比 mapreduce 快？</h4><p>1）基于内存计算，减少低效的磁盘交互；<br>2）高效的调度算法，基于 DAG；<br>3）容错机制 Linage，精华部分就是 DAG 和 Lingae</p>
<h4 id="八、简单说一下-hadoop-和-spark-的-shuffle-相同和差异？"><a href="#八、简单说一下-hadoop-和-spark-的-shuffle-相同和差异？" class="headerlink" title="八、简单说一下 hadoop 和 spark 的 shuffle 相同和差异？"></a>八、简单说一下 hadoop 和 spark 的 shuffle 相同和差异？</h4><p>1）从 high-level 的角度来看，两者并没有大的差别。 都是将 mapper（Spark 里是 ShuffleMapTask）的输出进行 partition，不同的 partition 送到不同的 reducer（Spark 里 reducer 可能是下一个 stage 里的ShuffleMapTask，也可能是 ResultTask）。Reducer 以内存作缓冲区，边shuffle 边 aggregate 数据，等到数据 aggregate 好以后进行 reduce()（Spark 里可能是后续的一系列操作）。<br>2）从 low-level 的角度来看，两者差别不小。 Hadoop MapReduce 是sort-based，进入 combine() 和 reduce() 的 records 必须先 sort。这样的好处在于 combine&#x2F;reduce() 可以处理大规模的数据，因为其输入数据可以通过外排得到（mapper 对每段数据先做排序，reducer 的 shuffle 对排好序的每段数据做归并）。目前的 Spark 默认选择的是 hash-based，通常使用HashMap 来对 shuffle 来的数据进行 aggregate，不会对数据进行提前排序。<br>如果用户需要经过排序的数据，那么需要自己调用类似 sortByKey() 的操作；<br>如果你是 Spark 1.1 的用户，可以将 spark.shuffle.manager 设置为 sort，则会对数据进行排序。在 Spark 1.2 中，sort 将作为默认的 Shuffle 实现。<br>3）从实现角度来看，两者也有不少差别。 Hadoop MapReduce 将处理流程划分出明显的几个阶段：map(), spill, merge, shuffle, sort, reduce() 等。<br>每个阶段各司其职，可以按照过程式的编程思想来逐一实现每个阶段的功能。在 Spark 中，没有这样功能明确的阶段，只有不同的 stage 和一系列的transformation()，所以 spill, merge, aggregate 等操作需要蕴含在<br>transformation() 中。<br>如果我们将 map 端划分数据、持久化数据的过程称为 shuffle write，而将reducer 读入数据、aggregate 数据的过程称为 shuffle read。那么在 Spark中，问题就变为怎么在 job 的逻辑或者物理执行图中加入 shuffle write 和<br>shuffle read 的处理逻辑？以及两个处理逻辑应该怎么高效实现？Shuffle write 由于不要求数据有序，shuffle write 的任务很简单：将数据partition 好，并持久化。之所以要持久化，一方面是要减少内存存储空间压力，另一方面也是为了 fault-tolerance。</p>
<h4 id="九、spark-工作机制"><a href="#九、spark-工作机制" class="headerlink" title="九、spark 工作机制"></a>九、spark 工作机制</h4><p>① 构建 Application 的运行环境，Driver 创建一个 SparkContext；</p>
<p>② SparkContext 向资源管理器（Standalone、Mesos、Yarn）申请Executor 资源，资源管理器启动 StandaloneExecutorbackend（Executor）<br>③ Executor 向 SparkContext 申请 Task</p>
<p> ④ SparkContext 将应用程序分发给Executor </p>
<p>⑤ SparkContext 就建成 DAG 图，DAGScheduler 将 DAG 图解析成 Stage，每个 Stage 有多个 task，形成 taskset 发送给 task Scheduler，由task Scheduler 将 Task 发送给 Executor 运行 </p>
<p>⑥ Task 在 Executor 上运行，运行完释放所有资源</p>
<h4 id="十、spark-的优化怎么做？"><a href="#十、spark-的优化怎么做？" class="headerlink" title="十、spark 的优化怎么做？"></a>十、spark 的优化怎么做？</h4><p>spark 调优比较复杂，但是大体可以分为三个方面来进行<br>1）平台层面的调优：防止不必要的 jar 包分发，提高数据的本地性，选择高效的存储格式如 parquet<br>2）应用程序层面的调优：过滤操作符的优化降低过多小任务，降低单条记录的资源开销，处理数据倾斜，复用 RDD 进行缓存，作业并行化执行等等<br>3）JVM 层面的调优：设置合适的资源量，设置合理的 JVM，启用高效的序列化方法如 kyro，增大 off head 内存等等</p>
<h4 id="十一、数据本地性是在哪个环节确定的？"><a href="#十一、数据本地性是在哪个环节确定的？" class="headerlink" title="十一、数据本地性是在哪个环节确定的？"></a>十一、数据本地性是在哪个环节确定的？</h4><p>具体的 task 运行在那他机器上，dag 划分 stage 的时候确定的</p>
<h4 id="十二、RDD-的弹性表现在哪几点？"><a href="#十二、RDD-的弹性表现在哪几点？" class="headerlink" title="十二、RDD 的弹性表现在哪几点？"></a>十二、RDD 的弹性表现在哪几点？</h4><p>1）自动的进行内存和磁盘的存储切换；</p>
<p>2）基于 Lineage 的高效容错；<br>3）task 如果失败会自动进行特定次数的重试；<br>4）stage 如果失败会自动进行特定次数的重试，而且只会计算失败的分片；<br>5）checkpoint 和 persist，数据计算之后持久化缓存；<br>6）数据调度弹性，DAG TASK 调度和资源无关；<br>7）数据分片的高度弹性。</p>
<h4 id="十三、RDD-有哪些缺陷？"><a href="#十三、RDD-有哪些缺陷？" class="headerlink" title="十三、RDD 有哪些缺陷？"></a>十三、RDD 有哪些缺陷？</h4><p>1）不支持细粒度的写和更新操作（如网络爬虫），spark 写数据是粗粒度的。所谓粗粒度，就是批量写入数据，为了提高效率。但是读数据是细粒度的也就是说可以一条条的读。<br>2）不支持增量迭代计算，Flink 支持</p>
<h4 id="十四、Spark-的-shuffle-过程？"><a href="#十四、Spark-的-shuffle-过程？" class="headerlink" title="十四、Spark 的 shuffle 过程？"></a>十四、Spark 的 shuffle 过程？</h4><p>从下面三点去展开<br>1）shuffle 过程的划分<br>2）shuffle 的中间结果如何存储<br>3）shuffle 的数据如何拉取过来</p>
<h4 id="十五、Spark-的数据本地性有哪几种？"><a href="#十五、Spark-的数据本地性有哪几种？" class="headerlink" title="十五、Spark 的数据本地性有哪几种？"></a>十五、Spark 的数据本地性有哪几种？</h4><p>Spark 中的数据本地性有三种：<br>1）PROCESS_LOCAL 是指读取缓存在本地节点的数据<br>2）NODE_LOCAL 是指读取本地节点硬盘数据<br>3）ANY 是指读取非本地节点数据<br>通常读取数据 PROCESS_LOCAL&gt;NODE_LOCAL&gt;ANY，尽量使数据以PROCESS_LOCAL 或 NODE_LOCAL 方式读取。其中 PROCESS_LOCAL 还和cache 有关，如果 RDD 经常用的话将该 RDD cache 到内存中，注意，由于cache 是 lazy 的，所以必须通过一个 action 的触发，才能真正的将该 RDD cache 到内存中。</p>
<h4 id="十六、Spark-为什么要持久化，一般什么场景下要进行-persist-操作？"><a href="#十六、Spark-为什么要持久化，一般什么场景下要进行-persist-操作？" class="headerlink" title="十六、Spark 为什么要持久化，一般什么场景下要进行 persist 操作？"></a>十六、Spark 为什么要持久化，一般什么场景下要进行 persist 操作？</h4><p>为什么要进行持久化？<br>spark 所有复杂一点的算法都会有 persist 身影，spark 默认数据放在内存，<br>spark 很多内容都是放在内存的，非常适合高速迭代，1000 个步骤只有第一个输入数据，中间不产生临时数据，但分布式系统风险很高，所以容易出错，就要容错，rdd 出错或者分片可以根据血统算出来，如果没有对父 rdd 进行persist 或者 cache 的化，就需要重头做。 以下场景会使用 persist<br>1）某个步骤计算非常耗时，需要进行 persist 持久化<br>2）计算链条非常长，重新恢复要算很多步骤，很好使，persist<br>3）checkpoint 所在的 rdd 要持久化 persist。checkpoint 前，要持久化，写个 rdd.cache 或者 rdd.persist，将结果保存起来，再写 checkpoint 操作，这样执行起来会非常快，不需要重新计算 rdd 链条了。checkpoint 之前一定会进行 persist。<br>4）shuffle 之后要 persist，shuffle 要进性网络传输，风险很大，数据丢失重来，恢复代价很大<br>5）shuffle 之前进行 persist，框架默认将数据持久化到磁盘，这个是框架自动做的。</p>
<h4 id="十七、join操作优化经验？"><a href="#十七、join操作优化经验？" class="headerlink" title="十七、join操作优化经验？"></a>十七、join操作优化经验？</h4><p>join 其实常见的就分为两类： map-side join 和 reduce-side join。当大表和小表 join 时，用 map-side join 能显著提高效率。将多份数据进行关联是数据处理过程中非常普遍的用法，不过在分布式计算系统中，这个问题往往会变的非常麻烦，因为框架提供的 join 操作一般会将所有数据根据 key 发送到所有的 reduce 分区中去，也就是 shuffle 的过程。造成大量的网络以及磁盘 IO消耗，运行效率极其低下，这个过程一般被称为 reduce-side-join。如果其中有张表较小的话，我们则可以自己实现在 map 端实现数据关联，跳过大量数据进行 shuffle 的过程，运行时间得到大量缩短，根据不同数据可能会有几倍到数十倍的性能提升。<br>ps：这个题目面试中非常非常大概率见到，务必搜索相关资料掌握，这里抛砖引玉。</p>
<h4 id="十八、YARN执行一个任务的过程"><a href="#十八、YARN执行一个任务的过程" class="headerlink" title="十八、YARN执行一个任务的过程"></a>十八、YARN执行一个任务的过程</h4><p>1）客户端 client 向 ResouceManager 提交 Application，ResouceManager 接受 Application 并根据集群资源状况选取一个 node 来启动 Application 的任务调度器 driver（ApplicationMaster）。<br>2）ResouceManager 找到那个 node，命令其该 node 上的 nodeManager来启动一个新的 JVM 进程运行程序的 driver（ApplicationMaster）部分，driver（ApplicationMaster）启动时会首先向 ResourceManager 注册，说明由自己来负责当前程序的运行。<br>3）driver（ApplicationMaster）开始下载相关 jar 包等各种资源，基于下载的 jar 等信息决定向 ResourceManager 申请具体的资源内容。<br>4）ResouceManager 接受到 driver（ApplicationMaster）提出的申请后，会最大化的满足 资源分配请求，并发送资源的元数据信息给 driver（ApplicationMaster）。<br>5）driver（ApplicationMaster）收到发过来的资源元数据信息后会根据元数据信息发指令给具体机器上的 NodeManager，让其启动具体的 container。<br>6）NodeManager 收到 driver 发来的指令，启动 container，container 启动后必须向 driver（ApplicationMaster）注册。<br>7）driver（ApplicationMaster）收到 container 的注册，开始进行任务的调度和计算，直到 任务完成。<br>NODE：如果 ResourceManager 第一次没有能够满足 driver（ApplicationMaster）的资源请求 ，后续发现有空闲的资源，会主动向driver（ApplicationMaster）发送可用资源的元数据信息以提供更多的资源用于当前程序的运行。</p>
<h4 id="十九、spark-on-yarn-模式有哪些优点"><a href="#十九、spark-on-yarn-模式有哪些优点" class="headerlink" title="十九、spark on yarn 模式有哪些优点"></a>十九、spark on yarn 模式有哪些优点</h4><p>1）与其他计算框架共享集群资源（Spark 框架与 MapReduce 框架同时运行，如果不用 Yarn 进行资源分配，MapReduce 分到的内存资源会很少，效率低下）；资源按需分配，进而提高集群资源利用等。<br>2）相较于 Spark 自带的 Standalone 模式，Yarn 的资源分配更加细致。<br>3）Application 部署简化，例如 Spark，Storm 等多种框架的应用由客户端提交后，由 Yarn 负责资源的管理和调度，利用 Container 作为资源隔离的单位，以它为单位去使用内存,cpu 等。<br>4）Yarn 通过队列的方式，管理同时运行在 Yarn 集群中的多个服务，可根据不同类型的应用程序负载情况，调整对应的资源使用量，实现资源弹性管理。</p>
<h4 id="二十、如何理解container？"><a href="#二十、如何理解container？" class="headerlink" title="二十、如何理解container？"></a>二十、如何理解container？</h4><p>1）Container 作为资源分配和调度的基本单位，其中封装了的资源如内存，CPU，磁盘，网络带宽等。 目前 yarn 仅仅封装内存和 CPU<br>2）Container 由 ApplicationMaster 向 ResourceManager 申请的，由ResouceManager 中的资源调度器异步分配给 ApplicationMaster<br>3）Container 的运行是由 ApplicationMaster 向资源所在的 NodeManager发起的，Container 运行时需提供内部执行的任务命令</p>
<h4 id="二十一、spark使用parquet文件存储格式能带来什么好处？"><a href="#二十一、spark使用parquet文件存储格式能带来什么好处？" class="headerlink" title="二十一、spark使用parquet文件存储格式能带来什么好处？"></a>二十一、spark使用parquet文件存储格式能带来什么好处？</h4><p>1）如果说 HDFS 是大数据时代分布式文件系统首选标准，那么 parquet 则是整个大数据时代文件存储格式实时首选标准。<br>2）速度更快：从使用 spark sql 操作普通文件 CSV 和 parquet 文件速度对比上看，绝大多数情况会比使用 csv 等普通文件速度提升 10 倍左右，在一些普通文件系统无法在 spark 上成功运行的情况下，使用 parquet 很多时候可以成功运行。<br>3）parquet 的压缩技术非常稳定出色，在 spark sql 中对压缩技术的处理可能无法正常的完成工作（例如会导致 lost task，lost executor）但是此时如果使用 parquet 就可以正常的完成。<br>4）极大的减少磁盘 I&#x2F;o,通常情况下能够减少 75%的存储空间，由此可以极大的减少 spark sql 处理数据的时候的数据输入内容，尤其是在 spark1.6x 中有个下推过滤器在一些情况下可以极大的减少磁盘的 IO 和内存的占用，（下推过滤器）。<br>5）spark 1.6x parquet 方式极大的提升了扫描的吞吐量，极大提高了数据的查找速度 spark1.6 和 spark1.5x 相比而言，提升了大约 1 倍的速度，在spark1.6X 中，操作 parquet 时候 cpu 也进行了极大的优化，有效的降低了<br>cpu 消耗。<br>6）采用 parquet 可以极大的优化 spark 的调度和执行。我们测试 spark 如果用 parquet 可以有效的减少 stage 的执行消耗，同时可以优化执行路径。</p>
<h4 id="二十二、-parition和block有什么关联关系"><a href="#二十二、-parition和block有什么关联关系" class="headerlink" title="二十二、 parition和block有什么关联关系"></a>二十二、 parition和block有什么关联关系</h4><p>1）hdfs 中的 block 是分布式存储的最小单元，等分，可设置冗余，这样设计有一部分磁盘空间的浪费，但是整齐的 block 大小，便于快速找到、读取对应的内容；<br>2）Spark 中的 partion 是弹性分布式数据集 RDD 的最小单元，RDD 是由分布在各个节点上的 partion 组成的。partion 是指的 spark 在计算过程中，生成的数据在计算空间内最小单元，同一份数据（RDD）的 partion 大小不一，数量不定，是根据 application 里的算子和最初读入的数据分块数量决定；<br>3）block 位于存储空间、partion 位于计算空间，block 的大小是固定的、partion 大小是不固定的，是从 2 个不同的角度去看数据。</p>
<h4 id="二十三、spark应用程序的执行过程是什么？"><a href="#二十三、spark应用程序的执行过程是什么？" class="headerlink" title="二十三、spark应用程序的执行过程是什么？"></a>二十三、spark应用程序的执行过程是什么？</h4><p>1）构建 Spark Application 的运行环境（启动 SparkContext），SparkContext 向资源管理器（可以是 Standalone、Mesos 或 YARN）注册并申请运行 Executor 资源；<br>2）资源管理器分配 Executor 资源并启动 StandaloneExecutorBackend，Executor 运行情况将随着心跳发送到资源管理器上；<br>3）SparkContext 构建成 DAG 图，将 DAG 图分解成 Stage，并把 Taskset发送给 Task Scheduler。Executor 向 SparkContext 申请 Task，TaskScheduler 将 Task 发放给 Executor 运行同时 SparkContext 将应用程序代码发放给 Executor；<br>4）Task 在 Executor 上运行，运行完毕释放所有资源。</p>
<h4 id="二十四、不需要排序的hash-shuffle一定比需要排序的sort-shuffle快吗？"><a href="#二十四、不需要排序的hash-shuffle一定比需要排序的sort-shuffle快吗？" class="headerlink" title="二十四、不需要排序的hash shuffle一定比需要排序的sort shuffle快吗？"></a>二十四、不需要排序的hash shuffle一定比需要排序的sort shuffle快吗？</h4><p>不一定，当数据规模小，Hash shuffle 快于 Sorted Shuffle 数据规模大的时候；当数据量大，sorted Shuffle 会比 Hash shuffle 快很多，因为数量大的有很多小文件，不均匀，甚至出现数据倾斜，消耗内存大，1.x 之前 spark 使用hash，适合处理中小规模，1.x 之后，增加了 Sorted shuffle，Spark 更能胜任大规模处理了。</p>
<h4 id="二十五、Sort-based-shuffle-的缺陷"><a href="#二十五、Sort-based-shuffle-的缺陷" class="headerlink" title="二十五、Sort-based shuffle 的缺陷?"></a>二十五、Sort-based shuffle 的缺陷?</h4><p>1）如果 mapper 中 task 的数量过大，依旧会产生很多小文件，此时在shuffle 传递数据的过程中 reducer 段，reduce 会需要同时大量的记录进行反序列化，导致大量的内存消耗和 GC 的巨大负担，造成系统缓慢甚至崩溃。<br>2）如果需要在分片内也进行排序，此时需要进行 mapper 段和 reducer 段的两次排序。</p>
<h4 id="二十六、spark-storage-memoryFraction参数的含义，如何调优？"><a href="#二十六、spark-storage-memoryFraction参数的含义，如何调优？" class="headerlink" title="二十六、spark.storage.memoryFraction参数的含义，如何调优？"></a>二十六、spark.storage.memoryFraction参数的含义，如何调优？</h4><p>1）用于设置 RDD 持久化数据在 Executor 内存中能占的比例，默认是 0.6,，默认 Executor 60%的内存，可以用来保存持久化的 RDD 数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘；<br>2）如果持久化操作比较多，可以提高 spark.storage.memoryFraction 参数，使得更多的持久化数据保存在内存中，提高数据的读取性能，如果 shuffle 的操作比较多，有很多的数据读写操作到 JVM 中，那么应该调小一点，节约出更多的内存给 JVM，避免过多的 JVM gc 发生。在 web ui 中观察如果发现 gc时间很长，可以设置 spark.storage.memoryFraction 更小一点。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/8b4d7328.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/8b4d7328.html" class="post-title-link" itemprop="url">大数据面试-flink</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-09 21:43:39" itemprop="dateCreated datePublished" datetime="2022-04-09T21:43:39+08:00">2022-04-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="一、flink-checkpoint-与spark-Flink-有什么区别或者优势？"><a href="#一、flink-checkpoint-与spark-Flink-有什么区别或者优势？" class="headerlink" title="一、flink checkpoint 与spark Flink 有什么区别或者优势？"></a>一、flink checkpoint 与spark Flink 有什么区别或者优势？</h4><p>spark streaming 的 checkpoint 仅仅是针对 driver 的故障恢复做了数据和元数据的checkpoint。而 flink 的 checkpoint 机制 要复杂了很多，它采用的是轻量级的分布式快照，实现了每个算子的快照，及流动中的数据的快照。</p>
<h4 id="二、Flink中的Time有哪几种？"><a href="#二、Flink中的Time有哪几种？" class="headerlink" title="二、Flink中的Time有哪几种？"></a>二、Flink中的Time有哪几种？</h4><p>在 flink 中被划分为事件时间，提取时间，处理时间三种。<br>如果以 EventTime 为基准来定义时间窗口那将形成 EventTimeWindow,要求消息本身就应该携带 EventTime。如果以 IngesingtTime 为基准来定义时间窗口那将形成IngestingTimeWindow,以 source 的 systemTime 为准。如果以 ProcessingTime基准来定义时间窗口那将形成 ProcessingTimeWindow，以 operator 的systemTime 为准。</p>
<h4 id="三、对于迟到数据是怎么处理的？"><a href="#三、对于迟到数据是怎么处理的？" class="headerlink" title="三、对于迟到数据是怎么处理的？"></a>三、对于迟到数据是怎么处理的？</h4><p>Flink 中 WaterMark 和 Window 机制解决了流式数据的乱序问题，对于因为延迟而顺序有误的数据，可以根据 eventTime 进行业务处理，对于延迟的数据 Flink 也有自己的解决办法，主要的办法是给定一个允许延迟的时间，在该时间范围内仍可以接受处理延迟数据。</p>
<p>设置允许延迟的时间是通过 allowedLateness(lateness: Time)设置<br>保存延迟数据则是通过 sideOutputLateData(outputTag: OutputTag[T])保存<br>获取延迟数据是通过 DataStream.getSideOutput(tag: OutputTag[X])获取</p>
<h4 id="四、Flink的运行必须依赖Hadoop组件吗？"><a href="#四、Flink的运行必须依赖Hadoop组件吗？" class="headerlink" title="四、Flink的运行必须依赖Hadoop组件吗？"></a>四、Flink的运行必须依赖Hadoop组件吗？</h4><p>Flink 可以完全独立于 Hadoop，在不依赖 Hadoop 组件下运行。但是做为大数据的基础设施，Hadoop 体系是任何大数据框架都绕不过去的。Flink 可以集成众多Hadooop 组件，例如 Yarn、Hbase、HDFS 等等。例如，Flink 可以和 Yarn 集成做资源调度，也可以读写 HDFS，或者利用 HDFS 做检查点。</p>
<h4 id="五、flink集群有哪些角色什么作用？"><a href="#五、flink集群有哪些角色什么作用？" class="headerlink" title="五、flink集群有哪些角色什么作用？"></a>五、flink集群有哪些角色什么作用？</h4><p>JobManager 处理器：<br>也称之为 Master，用于协调分布式执行，它们用来调度 task，协调检查点，协调失败时恢复等。Flink 运行时至少存在一个 master 处理器，如果配置高可用模式则会存在多个 master 处理器，它们其中有一个是 leader，而其他的都是 standby。<br>TaskManager 处理器：<br>也称之为 Worker，用于执行一个 dataflow 的 task(或者特殊的 subtask)、数据缓冲和 data stream 的交换，Flink 运行时至少会存在一个 worker 处理器。<br>Clint 客户端：<br>Client 是 Flink 程序提交的客户端，当用户提交一个 Flink 程序时，会首先创建一个Client，该 Client 首先会对用户提交的 Flink 程序进行预处理，并提交到 Flink 集群中处理，所以 Client 需要从用户提交的 Flink 程序配置中获取 JobManager 的地址，并建立到 JobManager 的连接，将 Flink Job 提交给 JobManager。</p>
<h4 id="六、flink资源管理中Task-Solt的概念"><a href="#六、flink资源管理中Task-Solt的概念" class="headerlink" title="六、flink资源管理中Task Solt的概念"></a>六、flink资源管理中Task Solt的概念</h4><p>在 Flink 中每个 TaskManager 是一个 JVM 的进程, 可以在不同的线程中执行一个或多个子任务。<br>为了控制一个 worker 能接收多少个 task。worker 通过 task slot（任务槽）来进行控制（一个 worker 至少有一个 task slot）。</p>
<h4 id="七、Flink的重启策略"><a href="#七、Flink的重启策略" class="headerlink" title="七、Flink的重启策略"></a>七、Flink的重启策略</h4><p>Flink 支持不同的重启策略，这些重启策略控制着 job 失败后如何重启：</p>
<h5 id="固定延迟重启策略"><a href="#固定延迟重启策略" class="headerlink" title="固定延迟重启策略"></a>固定延迟重启策略</h5><p>固定延迟重启策略会尝试一个给定的次数来重启 Job，如果超过了最大的重启次数，Job 最终将失败。在连续的两次重启尝试之间，重启策略会等待一个固定的时间。</p>
<h5 id="失败率重启策略"><a href="#失败率重启策略" class="headerlink" title="失败率重启策略"></a>失败率重启策略</h5><p>失败率重启策略在 Job 失败后会重启，但是超过失败率后，Job 会最终被认定失败。在两个连续的重启尝试之间，重启策略会等待一个固定的时间。</p>
<h5 id="无重启策略"><a href="#无重启策略" class="headerlink" title="无重启策略"></a>无重启策略</h5><p>Job 直接失败，不会尝试进行重启。</p>
<h4 id="八、Flink如何保证Exactly-once语义的"><a href="#八、Flink如何保证Exactly-once语义的" class="headerlink" title="八、Flink如何保证Exactly-once语义的"></a>八、Flink如何保证Exactly-once语义的</h4><p>Flink 通过实现两阶段提交和状态保存来实现端到端的一致性语义。分为以下几个步骤：<br>开始事务（beginTransaction）创建一个临时文件夹，来写把数据写入到这个文件夹里面<br>预提交（preCommit）将内存中缓存的数据写入文件并关闭<br>正式提交（commit）将之前写完的临时文件放入目标目录下。这代表着最终的数据会有一些延迟<br>丢弃（abort）丢弃临时文件<br>若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。</p>
<h4 id="九、如果下级存储不支持事务，flink怎么保证exactly-once"><a href="#九、如果下级存储不支持事务，flink怎么保证exactly-once" class="headerlink" title="九、如果下级存储不支持事务，flink怎么保证exactly-once"></a>九、如果下级存储不支持事务，flink怎么保证exactly-once</h4><p>端到端的 exactly-once 对 sink 要求比较高，具体实现主要有幂等写入和事务性写入两种方式。<br>幂等写入的场景依赖于业务逻辑，更常见的是用事务性写入。而事务性写入又有预写日志（WAL）和两阶段提交（2PC）两种方式。<br>如果外部系统不支持事务，那么可以用预写日志的方式，把结果数据先当成状态保存，然后在收到 checkpoint 完成的通知时，一次性写入 sink 系统。</p>
<h4 id="十、flink如何处理反压"><a href="#十、flink如何处理反压" class="headerlink" title="十、flink如何处理反压"></a>十、flink如何处理反压</h4><p>Flink 内部是基于 producer-consumer 模型来进行消息传递的，Flink 的反压设计也是基于这个模型。Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。下游消费者消费变慢，上游就会受到阻塞。</p>
<h4 id="十一、flink中的状态存储"><a href="#十一、flink中的状态存储" class="headerlink" title="十一、flink中的状态存储"></a>十一、flink中的状态存储</h4><p>Flink 在做计算的过程中经常需要存储中间状态，来避免数据丢失和状态恢复。选择的状态存储策略不同，会影响状态持久化如何和 checkpoint 交互。Flink 提供了三种状态存储方式：MemoryStateBackend、FsStateBackend、RocksDBStateBackend。</p>
<h4 id="十二、flink是如何支持流批一体的"><a href="#十二、flink是如何支持流批一体的" class="headerlink" title="十二、flink是如何支持流批一体的"></a>十二、flink是如何支持流批一体的</h4><p>可以简单说：Flink 的开发者认为批处理是流处理的一种特殊情况。批处理是有限的流处理。Flink 使用一个引擎支持了 DataSet API 和 DataStream API。如果知道flink底层原理，可以展开详细说说。</p>
<h4 id="十三、flink的内存管理是如何做的"><a href="#十三、flink的内存管理是如何做的" class="headerlink" title="十三、flink的内存管理是如何做的"></a>十三、flink的内存管理是如何做的</h4><p>Flink 并不是将大量对象存在堆上，而是将对象都序列化到一个预分配的内存块上。此外，Flink 大量的使用了堆外内存。如果需要处理的数据超出了内存限制，则会将部分数据存储到硬盘上。Flink 为了直接操作二进制数据实现了自己的序列化框架。</p>
<h4 id="十四、flinkCEP编程中当状态没有到达的时候会将数据保存在哪里"><a href="#十四、flinkCEP编程中当状态没有到达的时候会将数据保存在哪里" class="headerlink" title="十四、flinkCEP编程中当状态没有到达的时候会将数据保存在哪里"></a>十四、flinkCEP编程中当状态没有到达的时候会将数据保存在哪里</h4><p>在流式处理中，CEP 当然是要支持 EventTime 的，那么相对应的也要支持数据的迟到现象，也就是 watermark 的处理逻辑。CEP 对未匹配成功的事件序列的处理，和迟到数据是类似的。在 Flink CEP 的处理逻辑中，状态没有满足的和迟到的数据，都会存储在一个 Map 数据结构中，也就是说，如果我们限定判断事件序列的时长为 5 分钟，那么内存中就会存储 5 分钟的数据，这在我看来，也是对内存的极大损伤之一。</p>
<h4 id="十五、flink的运行架构"><a href="#十五、flink的运行架构" class="headerlink" title="十五、flink的运行架构"></a>十五、flink的运行架构</h4><p>当 Flink 集群启动后，首先会启动一个 JobManger 和一个或多个的TaskManager。由 Client 提交任务给JobManager，JobManager 再调度任务到各个 TaskManager 去执行，然后 TaskManager 将心跳和统计信息汇报给 JobManager。TaskManager 之间以流的形式进行数据的传输。上述三者均为独立的 JVM 进程。<br>l  Client 为提交 Job 的客户端，可以是运行在任何机器上（与 JobManager环境连通即可）。提交 Job 后，Client 可以结束进程（Streaming 的任务），也可以不结束并等待结果返回。<br>l  JobManager 主要负责调度 Job 并协调 Task 做 checkpoint，职责上很像 Storm 的 Nimbus。从 Client 处接收到 Job 和 JAR 包等资源后，会生成优化后的执行计划，并以 Task 的单元调度到各个 TaskManager 去执行。<br>l  TaskManager 在启动的时候就设置好了槽位数（Slot），每个 slot 能启动一个 Task，Task 为线程。从 JobManager 处接收需要部署的 Task，部署启动后，与自己的上游建立 Netty 连接，接收数据并处理。</p>
<h4 id="十六、flink的作业执行流程"><a href="#十六、flink的作业执行流程" class="headerlink" title="十六、flink的作业执行流程"></a>十六、flink的作业执行流程</h4><p>以 yarn 模式 Per-job 方式为例概述作业提交执行流程当执行 executor() 之后,会首先在本地 client 中将代码转化为可以提交的JobGraph</p>
<ol>
<li>如果提交为 Per-Job 模式,则首先需要启动 AM, client 会首先向资源系统申请资源, 在 yarn 下即为申请 container 开启 AM, 如果是 Session 模式的话则不需要这个步骤</li>
<li>Yarn 分配资源, 开启 AM</li>
<li>Client 将 Job 提交给 Dispatcher</li>
<li>Dispatcher 会开启一个新的 JobManager 线程</li>
<li>JM 向 Flink 自己的 Resourcemanager 申请 slot 资源来执行任务</li>
<li>RM 向 Yarn 申请资源来启动 TaskManger (Session 模式跳过此步)</li>
<li>Yarn 分配 Container 来启动 taskManger (Session 模式跳过此步)</li>
<li>Flink 的 RM 向 TM 申请 slot 资源来启动 task</li>
<li>TM 将待分配的 slot 提供给 JM</li>
<li>JM 提交 task, TM 会启动新的线程来执行任务,开始启动后就可以通过shuffle 模块进行 task 之间的数据交换</li>
</ol>
<h4 id="十七、flink中event-time和processtime的区别"><a href="#十七、flink中event-time和processtime的区别" class="headerlink" title="十七、flink中event time和processtime的区别"></a>十七、flink中event time和processtime的区别</h4><p>Flink 中有三种时间概念,分别是 Processing Time、Event Time 和 Ingestion Time<br>•  Processing Time<br>Processing Time 是指事件被处理时机器的系统时间。<br>当流程序在 Processing Time 上运行时，所有基于时间的操作(如时间窗口)将使用当时机器的系统时间。每小时 Processing Time 窗口将包括在系统时钟指示整个小时之间到达特定操作的所有事件<br>•  Event Time<br>Event Time 是事件发生的时间，一般就是数据本身携带的时间。这个时间通常是在事件到达 Flink 之前就确定的，并且可以从每个事件中获取到事件时间戳。在 EventTime 中，时间取决于数据，而跟其他没什么关系。Event Time 程序必须指定如何生成 Event Time 水印，这是表示 Event Time 进度的机制<br>•  Ingestion Time<br>Ingestion Time 是事件进入 Flink 的时间。 在源操作处，每个事件将源的当前时间作为时间戳，并且基于时间的操作（如时间窗口）会利用这个时间戳。<br>Ingestion Time 在概念上位于 Event Time 和 Processing Time 之间。 与Processing Time 相比，它稍微贵一些，但结果更可预测。因为 Ingestion Time 使用稳定的时间戳（在源处分配一次），所以对事件的不同窗口操作将引用相同的时间戳，而在 Processing Time 中，每个窗口操作符可以将事件分配给不同的窗口（基于机器系统时间和到达延迟）<br>与 Event Time 相比，Ingestion Time 程序无法处理任何无序事件或延迟数据，但程序不必指定如何生成水印。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/932578fc.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/932578fc.html" class="post-title-link" itemprop="url">大数据面试-Flume</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-07 22:12:00" itemprop="dateCreated datePublished" datetime="2022-04-07T22:12:00+08:00">2022-04-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="一、Flume使用场景"><a href="#一、Flume使用场景" class="headerlink" title="一、Flume使用场景"></a>一、Flume使用场景</h4><p>线上数据一般主要是落地（存储到磁盘）或者通过 socket 传输给另外一个系统，这种情况下，你很难推动线上应用或服务去修改接口，实现直接向 kafka里写数据，这时候你可能就需要 flume 这样的系统帮你去做传输。</p>
<h4 id="二、Flume丢包问题"><a href="#二、Flume丢包问题" class="headerlink" title="二、Flume丢包问题"></a>二、Flume丢包问题</h4><p>单机 upd 的 flume source 的配置，100+M&#x2F;s 数据量，10w qps flume 就开始大量丢包，因此很多公司在搭建系统时，抛弃了 Flume，自己研发传输系统，但是往往会参考 Flume 的 Source-Channel-Sink 模式。一些公司在 Flume 工作过程中，会对业务日志进行监控，例如 Flume agent中有多少条日志，Flume 到 Kafka 后有多少条日志等等，如果数据丢失保持在1%左右是没有问题的，当数据丢失达到 5%左右时就必须采取相应措施。</p>
<h4 id="三、Flume与KAFKA的选取"><a href="#三、Flume与KAFKA的选取" class="headerlink" title="三、Flume与KAFKA的选取"></a>三、Flume与KAFKA的选取</h4><p>采集层主要可以使用 Flume、Kafka 两种技术。</p>
<p>Flume：Flume 是管道流方式，提供了很多的默认实现，让用户通过参数部署，及扩展 API。<br>Kafka：Kafka 是一个可持久化的分布式的消息队列。<br>Kafka 是一个非常通用的系统。你可以有许多生产者和很多的消费者共享多个主题 Topics。相比之下，Flume 是一个专用工具被设计为旨在往 HDFS，HBase 发送数据。它对 HDFS 有特殊的优化，并且集成了 Hadoop 的安全特性。所以，Cloudera 建议如果数据被多个系统消费的话，使用 kafka；如果数据被设计给 Hadoop 使用，使用 Flume。<br>正如你们所知 Flume 内置很多的 source 和 sink 组件。然而，Kafka 明显有一个更小的生产消费者生态系统，并且 Kafka 的社区支持不好。希望将来这种情况会得到改善，但是目前：使用 Kafka 意味着你准备好了编写你自己的生产者和消费者代码。如果已经存在的 Flume Sources 和 Sinks 满足你的需求，并且你更喜欢不需要任何开发的系统，请使用 Flume。<br>Flume 可以使用拦截器实时处理数据。这些对数据屏蔽或者过量是很有用的。<br>Kafka 需要外部的流处理系统才能做到。<br>Kafka 和 Flume 都是可靠的系统，通过适当的配置能保证零数据丢失。然而，Flume 不支持副本事件。于是，如果 Flume 代理的一个节点奔溃了，即使使用了可靠的文件管道方式，你也将丢失这些事件直到你恢复这些磁盘。如果你需要一个高可靠性的管道，那么使用 Kafka 是个更好的选择。<br>Flume 和 Kafka 可以很好地结合起来使用。如果你的设计需要从 Kafka 到Hadoop 的流数据，使用 Flume 代理并配置 Kafka 的 Source 读取数据也是可行的：你没有必要实现自己的消费者。你可以直接利用 Flume 与 HDFS 及HBase 的结合的所有好处。你可以使用 Cloudera Manager 对消费者的监控，并且你甚至可以添加拦截器进行一些流处理。</p>
<h4 id="四、数据怎么采集到KAFKA，实现方式？"><a href="#四、数据怎么采集到KAFKA，实现方式？" class="headerlink" title="四、数据怎么采集到KAFKA，实现方式？"></a>四、数据怎么采集到KAFKA，实现方式？</h4><p>使用官方提供的 flumeKafka 插件，插件的实现方式是自定义了 flume 的sink，将数据从 channle 中取出，通过 kafka 的 producer 写入到 kafka 中，可以自定义分区等。</p>
<h4 id="五、Flume管道内存，flume宕机了数据丢失怎么解决？"><a href="#五、Flume管道内存，flume宕机了数据丢失怎么解决？" class="headerlink" title="五、Flume管道内存，flume宕机了数据丢失怎么解决？"></a>五、Flume管道内存，flume宕机了数据丢失怎么解决？</h4><p>1）Flume 的 channel 分为很多种，可以将数据写入到文件。<br>2）防止非首个 agent 宕机的方法数可以做集群或者主备。</p>
<h4 id="六、flume配置方式，flume集群"><a href="#六、flume配置方式，flume集群" class="headerlink" title="六、flume配置方式，flume集群"></a>六、flume配置方式，flume集群</h4><p>Flume 的配置围绕着 source、channel、sink 叙述，flume 的集群是做在agent 上的，而非机器上。</p>
<h4 id="七、flume不采集nginx日志，通过log4j采集日志，优缺点是什么？"><a href="#七、flume不采集nginx日志，通过log4j采集日志，优缺点是什么？" class="headerlink" title="七、flume不采集nginx日志，通过log4j采集日志，优缺点是什么？"></a>七、flume不采集nginx日志，通过log4j采集日志，优缺点是什么？</h4><p>优点：Nginx 的日志格式是固定的，但是缺少 sessionid，通过 logger4j 采集的日志是带有 sessionid 的，而 session 可以通过 redis 共享，保证了集群日志中的同一 session 落到不同的 tomcat 时，sessionId 还是一样的，而且logger4j 的方式比较稳定，不会宕机。</p>
<p>缺点：不够灵活，logger4j 的方式和项目结合过于紧密，而 flume 的方式比较灵活，拔插式比较好，不会影响项目性能。</p>
<h4 id="八、flume-和-kafka-采集日志区别，采集日志时中间停了，怎么记录之前的日志？"><a href="#八、flume-和-kafka-采集日志区别，采集日志时中间停了，怎么记录之前的日志？" class="headerlink" title="八、flume 和 kafka 采集日志区别，采集日志时中间停了，怎么记录之前的日志？"></a>八、flume 和 kafka 采集日志区别，采集日志时中间停了，怎么记录之前的日志？</h4><p>Flume 采集日志是通过流的方式直接将日志收集到存储层，而 kafka 是将缓存在 kafka 集群，待后期可以采集到存储层。<br>Flume 采集中间停了，可以采用文件的方式记录之前的日志，而 kafka 是采用 offset 的方式记录之前的日志。</p>
<p>九、flume有哪些组件，具体是做什么的？</p>
<p><img src="/Echo/posts/932578fc/image-20220408151914983.png" alt="image-20220408151914983"></p>
<p>1）source：用于采集数据，Source 是产生数据流的地方，同时 Source 会将产生的数据流传输到 Channel，这个有点类似于 Java IO 部分的 Channel。<br>2）channel：用于桥接 Sources 和 Sinks，类似于一个队列。<br>3）sink：从 Channel 收集数据，将数据写到目标源(可以是下一个 Source，也可以是 HDFS 或者 HBase)。<br>PS：要熟悉 source、channel、sink 的类型</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/e01df792.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/e01df792.html" class="post-title-link" itemprop="url">大数据面试-KAFKA</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-07 19:34:53" itemprop="dateCreated datePublished" datetime="2022-04-07T19:34:53+08:00">2022-04-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="一、为什么使用KAFKA？"><a href="#一、为什么使用KAFKA？" class="headerlink" title="一、为什么使用KAFKA？"></a>一、为什么使用KAFKA？</h4><ul>
<li>缓冲和削峰：上游数据时有突发流量，下游可能扛不住，或者下游没有足够多的机器来保证冗余，kafka 在中间可以起到一个缓冲的作用，把消息暂存在 kafka 中，下游服务就可以按照自己的节奏进行慢慢处理。</li>
<li>解耦和扩展性：项目开始的时候，并不能确定具体需求。消息队列可以作为一个接口层，解耦重要的业务流程。只需要遵守约定，针对数据编程即可获取扩展能力。</li>
<li>冗余：可以采用一对多的方式，一个生产者发布消息，可以被多个订阅 topic 的服务消费到，供多个毫无关联的业务使用。</li>
<li>健壮性：消息队列可以堆积请求，所以消费端业务即使短时间死掉，也不会影响主要业务的正常进行。</li>
<li>异步通信：很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</li>
</ul>
<h4 id="二、KAKFA消费过的消息如何再消费？"><a href="#二、KAKFA消费过的消息如何再消费？" class="headerlink" title="二、KAKFA消费过的消息如何再消费？"></a>二、KAKFA消费过的消息如何再消费？</h4><p>kafka 消费消息的 offset 是定义在 zookeeper 中的， 如果想重复消费 kafka 的消息，可以在 redis 中自己记录 offset 的 checkpoint 点（n 个），当想重复消费消息时，通过读取 redis 中的 checkpoint 点进行 zookeeper 的 offset 重设，这样就可以达到重复消费消息的目的。</p>
<h4 id="三、KAFKA的数据是存放在磁盘上还是内存上，为什么速度会快？"><a href="#三、KAFKA的数据是存放在磁盘上还是内存上，为什么速度会快？" class="headerlink" title="三、KAFKA的数据是存放在磁盘上还是内存上，为什么速度会快？"></a>三、KAFKA的数据是存放在磁盘上还是内存上，为什么速度会快？</h4><p>kafka 使用的是磁盘存储。<br>速度快的原因是：</p>
<ul>
<li>顺序写入：因为硬盘是机械结构，每次读写都会寻址-&gt;写入，其中寻址是一个“机械动作”，它是耗时的。所以硬盘 “讨厌”随机 I&#x2F;O， 喜欢顺序 I&#x2F;O。为了提高读写硬盘的速度，Kafka 就是使用顺序 I&#x2F;O。</li>
<li>Memory Mapped Files（内存映射文件）：64位操作系统中一般可以表示 20G 的数据文件，它的工作原理是直接利用操作系统的Page 来实现文件到物理内存的直接映射。完成映射之后你对物理内存的操作会被同步到硬盘上。</li>
<li>Kafka 高效文件存储设计： Kafka 把 topic 中一个 parition 大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。通过索引信息可以快速定位message 和确定 response 的 大 小。通过 index 元数据全部映射到 memory（内存映射文件），可以避免 segment file 的 IO 磁盘操作。通过索引文件稀疏存储，可以大幅降低index 文件元数据占用空间大小。</li>
</ul>
<h4 id="四、KAFKA数据怎么保障不丢失？"><a href="#四、KAFKA数据怎么保障不丢失？" class="headerlink" title="四、KAFKA数据怎么保障不丢失？"></a>四、KAFKA数据怎么保障不丢失？</h4><p>分三个点说，一个是生产者端，一个消费者端，一个 broker 端。</p>
<h5 id="生产者数据的不丢失"><a href="#生产者数据的不丢失" class="headerlink" title="生产者数据的不丢失"></a>生产者数据的不丢失</h5><p>kafka 的 ack 机制：在 kafka 发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常的能够被收到，其中状态有 0，1，-1。<br>如果是同步模式：<br>ack 设置为 0，风险很大，一般不建议设置为 0。即使设置为 1，也会随着 leader 宕机丢失数据。所以如果要严格保证生产端数据不丢失，可设置为-1。<br>如果是异步模式：<br>也会考虑 ack 的状态，除此之外，异步模式下的有个 buffer，通过 buffer 来进行控制数据的发送，有两个值来进行控制，时间阈值与消息的数量阈值，如果 buffer 满了数据还没有发送出去，有个选项是配置是否立即清空 buffer。可以设置为-1，永久阻塞，也就数据不再生产。异步模式下，即使设置为-1。也可能因为程序员的不科学操作，操作数据丢失，比如 kill -9，但这是特别的例外情况。</p>
<p>ack&#x3D;0：producer 不等待 broker 同步完成的确认，继续发送下一条(批)信息。<br>ack&#x3D;1（默认）：producer 要等待 leader 成功收到数据并得到确认，才发送下一条message。<br>ack&#x3D;-1：producer 得到 follwer 确认，才发送下一条数据。</p>
<h5 id="消费者数据的不丢失"><a href="#消费者数据的不丢失" class="headerlink" title="消费者数据的不丢失"></a>消费者数据的不丢失</h5><p>通过 offset commit 来保证数据的不丢失，kafka 自己记录了每次消费的 offset 数值，下次继续消费的时候，会接着上次的 offset 进行消费。而 offset 的信息在 kafka0.8 版本之前保存在 zookeeper 中，在 0.8 版本之后保存到topic 中，即使消费者在运行过程中挂掉了，再次启动的时候会找到 offset 的值，找到之前消费消息的位置，接着消费，由于 offset 的信息写入的时候并不是每条消息消费完成后都写入的，所以这种情况有可能会造成重复消费，但是不会丢失消息。<br>唯一例外的情况是，我们在程序中给原本做不同功能的两个 consumer 组设KafkaSpoutConfig.bulider.setGroupid 的时候设置成了一样的 groupid，这种情况会导致这两个组共享同一份数据，就会产生组 A 消费 partition1，partition2 中的消息，组 B 消费 partition3 的消息，这样每个组消费的消息都会丢失，都是不完整的。为了保证每个组都独享一份消息数据，groupid 一定不要重复才行。</p>
<h5 id="kafka-集群中的-broker-的数据不丢失"><a href="#kafka-集群中的-broker-的数据不丢失" class="headerlink" title="kafka 集群中的 broker 的数据不丢失"></a>kafka 集群中的 broker 的数据不丢失</h5><p>每个 broker 中的 partition 我们一般都会设置有 replication（副本）的个数，生产者写入的时候首先根据分发策略（有 partition 按 partition，有 key 按 key，都没有轮询）写入到 leader 中，follower（副本）再跟 leader 同步数据，这样有了备份，也可以保证消息数据的不丢失。</p>
<h4 id="五、采集数据为什么选择-kafka？"><a href="#五、采集数据为什么选择-kafka？" class="headerlink" title="五、采集数据为什么选择 kafka？"></a>五、采集数据为什么选择 kafka？</h4><p>采集层 主要可以使用 Flume, Kafka 等技术。<br>Flume：Flume 是管道流方式，提供了很多的默认实现，让用户通过参数部署，及扩展 API.<br>Kafka：Kafka 是一个可持久化的分布式的消息队列。 Kafka 是一个非常通用的系统。可以有许多生产者和很多的消费者共享多个主题 Topics。相比之下,Flume 是一个专用工具被设计为旨在往 HDFS，HBase 发送数据。它对<br>HDFS 有特殊的优化，并且集成了 Hadoop 的安全特性。所以，Cloudera 建议如果数据被多个系统消费的话，使用 kafka；如果数据被设计给Hadoop 使用，使用 Flume。</p>
<h4 id="kafka-重启是否会导致数据丢失？"><a href="#kafka-重启是否会导致数据丢失？" class="headerlink" title="kafka 重启是否会导致数据丢失？"></a>kafka 重启是否会导致数据丢失？</h4><p>kafka 是将数据写到磁盘的，一般数据不会丢失。但是在重启 kafka 过程中，如果有消费者消费消息，那么 kafka 如果来不及提交 offset，可能会造成数据的不准确（丢失或者重复消费）。</p>
<h4 id="kafka-宕机了如何解决？"><a href="#kafka-宕机了如何解决？" class="headerlink" title="kafka 宕机了如何解决？"></a>kafka 宕机了如何解决？</h4><p>先考虑业务是否受到影响</p>
<p>kafka 宕机了，首先我们考虑的问题应该是所提供的服务是否因为宕机的机器而受到影响，如果服务提供没问题，如果实现做好了集群的容灾机制，那么这块就不用担心了。<br>节点排错与恢复<br>想要恢复集群的节点，主要的步骤就是通过日志分析来查看节点宕机的原因，从而解决，重新恢复节点。</p>
<h4 id="六、为什么-Kafka-不支持读写分离？"><a href="#六、为什么-Kafka-不支持读写分离？" class="headerlink" title="六、为什么 Kafka 不支持读写分离？"></a>六、为什么 Kafka 不支持读写分离？</h4><p>在 Kafka 中，生产者写入消息、消费者读取消息的操作都是与 leader 副本进行交互的，从 而实现的是一种主写主读的生产消费模型。<br>Kafka 并不支持主写从读，因为主写从读有 2 个很明显的缺点:</p>
<ul>
<li><p>数据一致性问题：数据从主节点转到从节点必然会有一个延时的时间窗口，这个时间窗口会导致主从节点之间的数据不一致。某一时刻，在主节点和从节点中 A 数据的值都为 X， 之后将主节点中 A 的值修改为 Y，那么在这个变更通知到从节点之前，应用读取从节点中的 A 数据的值并不为最新的 Y，由此便产生了数据不一致的问题。</p>
</li>
<li><p>延时问题：类似 Redis 这种组件，数据从写入主节点到同步至从节点中的过程需要经历 网络→主节点内存→网络→从节点内存 这几个阶段，整个过程会耗费一定的时间。而在Kafka 中，主从同步会比 Redis 更加耗时，它需要经历 网络→主节点内存→主节点磁盘→网络→从节 点内存→从节点磁盘 这几个阶段。对延时敏感的应用而言，主写从读的功能并不太适用。</p>
</li>
</ul>
<p>而 kafka 的主写主读的优点就很多了：<br>可以简化代码的实现逻辑，减少出错的可能; 将负载粒度细化均摊，与主写从读相比，不仅负载效能更好，而且对用户可控;没有延时的影响;在副本稳定的情况下，不会出现数据不一致的情况。</p>
<h4 id="七、kafka-数据分区和消费者的关系？"><a href="#七、kafka-数据分区和消费者的关系？" class="headerlink" title="七、kafka 数据分区和消费者的关系？"></a>七、kafka 数据分区和消费者的关系？</h4><p>每个分区只能由同一个消费组内的一个消费者(consumer)来消费，可以由不同的消费组的消费者来消费，同组的消费者则起到并发的效果。</p>
<h4 id="八、kafka-的数据-offset-读取流程"><a href="#八、kafka-的数据-offset-读取流程" class="headerlink" title="八、kafka 的数据 offset 读取流程"></a>八、kafka 的数据 offset 读取流程</h4><p>连接 ZK 集群，从 ZK 中拿到对应 topic 的 partition 信息和 partition 的 Leader 的相关信息连接到对应 Leader 对应的 brokerconsumer 将⾃自自⼰己己保存的 offset 发送给LeaderLeader 根据 offset 等信息定位到 segment（索引⽂文文件和⽇日日志⽂文文件）根据索引⽂文文件中的内容，定位到⽇日日志⽂文文件中该偏移量量对应的开始位置读取相应长长度的数据并返回给 consumer。</p>
<h4 id="九、kafka-内部如何保证顺序，结合外部组件如何保证消费者的顺序？"><a href="#九、kafka-内部如何保证顺序，结合外部组件如何保证消费者的顺序？" class="headerlink" title="九、kafka 内部如何保证顺序，结合外部组件如何保证消费者的顺序？"></a>九、kafka 内部如何保证顺序，结合外部组件如何保证消费者的顺序？</h4><p>kafka 只能保证 partition 内是有序的，但是 partition 间的有序是没办法的。爱奇艺的搜索架构，是从业务上把需要有序的打到同⼀一个 partition。</p>
<h4 id="十、Kafka-消息数据积压，Kafka-消费能力不足怎么处理？"><a href="#十、Kafka-消息数据积压，Kafka-消费能力不足怎么处理？" class="headerlink" title="十、Kafka 消息数据积压，Kafka 消费能力不足怎么处理？"></a>十、Kafka 消息数据积压，Kafka 消费能力不足怎么处理？</h4><p>如果是 Kafka 消费能力不足，则可以考虑增加 Topic 的分区数，并且同时提升消费组的消费者数量，消费者数&#x3D;分区数。（两者缺一不可）如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据&#x2F;处理时间&lt;生产速度），使处理的数据小于生产的数据，也会造成数据积压。</p>
<h4 id="十一、Kafka-单条日志传输大小"><a href="#十一、Kafka-单条日志传输大小" class="headerlink" title="十一、Kafka 单条日志传输大小"></a>十一、Kafka 单条日志传输大小</h4><p>kafka 对于消息体的大小默认为单条最大值是 1M 但是在我们应用场景中, 常常会出现一条消息大于 1M，如果不对 kafka 进行配置。则会出现生产者无法将消息推送到kafka 或消费者无法去消费 kafka 里面的数据, 这时我们就要对 kafka 进行以下配置：<br>server.properties<br>1replica.fetch.max.bytes: 1048576 broker 可复制的消息的最大字节数, 默认为 1M<br>2message.max.bytes: 1000012 kafka 会接收单个消息 size 的最大限制， 默认为1M 左右<br>注意：message.max.bytes 必须小于等于 replica.fetch.max.bytes，否则就会导致 replica 之间数据同步失败。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/c066093e.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/c066093e.html" class="post-title-link" itemprop="url">大数据面试-HDFS</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-04-06 13:24:06" itemprop="dateCreated datePublished" datetime="2022-04-06T13:24:06+08:00">2022-04-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="一、HDFS读写流程"><a href="#一、HDFS读写流程" class="headerlink" title="一、HDFS读写流程"></a>一、HDFS读写流程</h4><h5 id="①HDFS写流程"><a href="#①HDFS写流程" class="headerlink" title="①HDFS写流程"></a>①HDFS写流程</h5><p>1）client 客户端发送上传请求，通过 RPC 与 namenode 建立通信，namenode 检查该用户是否有上传权限，以及上传的文件是否在 hdfs 对应的目录下重名，如果这两者有任意一个不满足，则直接报错，如果两者都满足，则返回给客户端一个可以上传的信息。</p>
<p>2）client 根据文件的大小进行切分，默认 128M 一块，切分完成之后给namenode 发送请求第一个 block 块上传到哪些服务器上。</p>
<p>3）namenode 收到请求之后，根据网络拓扑和机架感知以及副本机制进行文件分配，返回可用的 DataNode 的地址</p>
<p>4）客户端收到地址之后与服务器地址列表中的一个节点如 A 进行通信，本质上就是 RPC 调用，建立 pipeline，A 收到请求后会继续调用 B，B 在调用 C，将整个 pipeline 建立完成，逐级返回 client。</p>
<p>5）client 开始向 A 上发送第一个 block（先从磁盘读取数据然后放到本地内存缓存），以 packet（数据包，64kb）为单位，A 收到一个 packet 就会发送给B，然后 B 发送给 C，A 每传完一个 packet 就会放入一个应答队列等待应答</p>
<p>6）数据被分割成一个个的 packet 数据包在 pipeline 上依次传输，在pipeline 反向传输中，逐个发送 ack（命令正确应答），最终由 pipeline 中第一个 DataNode 节点 A 将 pipelineack 发送给 Client。</p>
<p>7）当一个 block 传输完成之后, Client 再次请求 NameNode 上传第二个block ，namenode 重新选择三台 DataNode 给 client</p>
<h5 id="②HDFS读流程"><a href="#②HDFS读流程" class="headerlink" title="②HDFS读流程"></a>②HDFS读流程</h5><p>1）client 向 namenode 发送 RPC 请求。请求文件 block 的位置<br>2）namenode 收到请求之后会检查用户权限以及是否有这个文件，如果都符合，则会视情况返回部分或全部的 block 列表，对于每个 block，NameNode都会返回含有该 block 副本的 DataNode 地址； 这些返回的 DN 地址，会按照集群拓扑结构得出 DataNode 与客户端的距离，然后进行排序，排序两个规则：网络拓扑结构中距离 Client近的排靠前；心跳机制中超时汇报的 DN 状态为 STALE，这样的排靠后<br>3）Client 选取排序靠前的 DataNode 来读取 block，如果客户端本身就是DataNode,那么将从本地直接获取数据(短路读取特性)<br>4）底层上本质是建立 Socket Stream（FSDataInputStream），重复的调用父类 DataInputStream 的 read 方法，直到这个块上的数据读取完毕<br>5）当读完列表的 block 后，若文件读取还没有结束，客户端会继续向NameNode 获取下一批的 block 列表<br>6）读取完一个 block 都会进行 checksum 验证，如果读取 DataNode 时出现错误，客户端会通知 NameNode，然后再从下一个拥有该 block 副本的DataNode 继续读<br>7）read 方法是并行的读取 block 信息，不是一块一块的读取；NameNode只是返回 Client 请求包含块的 DataNode 地址，并不是返回请求块的数据<br>8） 最终读取来所有的 block 会合并成一个完整的最终文件</p>
<h4 id="二、HDFS-在读取文件的时候-如果其中一个块突然损坏了怎么办"><a href="#二、HDFS-在读取文件的时候-如果其中一个块突然损坏了怎么办" class="headerlink" title="二、HDFS 在读取文件的时候,如果其中一个块突然损坏了怎么办"></a>二、HDFS 在读取文件的时候,如果其中一个块突然损坏了怎么办</h4><p>客户端读取完 DataNode 上的块之后会进行 checksum 验证，也就是把客户端读取到本地的块与 HDFS 上的原始块进行校验，如果发现校验结果不一致，客户端会通知NameNode，然后再从下一个拥有该 block 副本的 DataNode 继续读。</p>
<h4 id="三、HDFS-在上传文件的时候-如果其中一个-DataNode-突然挂掉了怎么办"><a href="#三、HDFS-在上传文件的时候-如果其中一个-DataNode-突然挂掉了怎么办" class="headerlink" title="三、HDFS 在上传文件的时候,如果其中一个 DataNode 突然挂掉了怎么办"></a>三、HDFS 在上传文件的时候,如果其中一个 DataNode 突然挂掉了怎么办</h4><p>客户端上传文件时与 DataNode 建立 pipeline 管道，管道正向是客户端向DataNode 发送的数据包，管道反向是 DataNode 向客户端发送 ack 确认，也就是正确接收到数据包之后发送一个已确认接收到的应答，当 DataNode 突然挂掉了，客户端接收不到这个 DataNode 发送的 ack 确认，客户端会通知 NameNode，NameNode 检查该块的副本与规定的不符，NameNode 会通知 DataNode 去复制副本，并将挂掉的 DataNode 作下线处理，不再让它参与文件上传与下载。</p>
<h4 id="四、HDFS-的组织架构"><a href="#四、HDFS-的组织架构" class="headerlink" title="四、HDFS 的组织架构"></a>四、HDFS 的组织架构</h4><p>1）Client：客户端<br>（1）切分文件。文件上传 HDFS 的时候，Client 将文件切分成一个一个的 Block，然后进行存储<br>（2）与 NameNode 交互，获取文件的位置信息<br>（3）与 DataNode 交互，读取或者写入数据<br>（4）Client 提供一些命令来管理 HDFS，比如启动关闭 HDFS、访问 HDFS 目录及内容等<br>2）NameNode：名称节点，也称主节点，存储数据的元数据信息，不存储具体的数据<br>（1）管理 HDFS 的名称空间<br>（2）管理数据块（Block）映射信息<br>（3）配置副本策略<br>（4）处理客户端读写请求<br>3）DataNode：数据节点，也称从节点。NameNode 下达命令，DataNode 执行实际的操作<br>（1）存储实际的数据块<br>（2）执行数据块的读&#x2F;写操作<br>4）Secondary NameNode：并非 NameNode 的热备。当 NameNode 挂掉的时候，它并不能马上替换NameNode 并提供服务<br>（1）辅助 NameNode，分担其工作量<br>（2）定期合并 Fsimage 和 Edits，并推送给 NameNode<br>（3）在紧急情况下，可辅助恢复 NameNode</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/6baa0397.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/6baa0397.html" class="post-title-link" itemprop="url">Kubernetes--master、node</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-15 16:02:30" itemprop="dateCreated datePublished" datetime="2022-03-15T16:02:30+08:00">2022-03-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h4><p> Kubernetes里的Master指的是集群控制节点，在每个Kubernetes集群里都需要有一个Master来负责整个集群的管理和控制，基本上Kubernetes的所有控制命令都发给它，它负责具体的执行过程，我们后面执行的所有命令基本都是在Master上运行的。Master通常会占据一个独立的服务器（高可用部署建议用3台服务器），主要原因是它太重要了，是整个集群的“首脑”，如果它宕机或者不可用，那么对集群内容器应用的管理都将失效。<br>在Master上运行着以下关键进程。</p>
<ul>
<li>Kubernetes API Server（kube-apiserver）：提供了HTTP Rest接口的关键服务进程，是Kubernetes里所有资源的增、删、改、查等操作的唯一入口，也是集群控制的入口进程。</li>
<li>Kubernetes Controller Manager（kube-controller-manager）：Kubernetes里所有资源对象的自动化控制中心，可以将其理解为资源对象的“大总管”。</li>
<li>Kubernetes Scheduler（kube-scheduler）：负责资源调度（Pod调度）的进程，相当于公交公司的“调度室”。另外，在Master上通常还需要部署etcd服务，因为Kubernetes里的所有资源对象的数据都被保存在etcd中。</li>
</ul>
<h4 id="Node"><a href="#Node" class="headerlink" title="Node"></a>Node</h4><p>除了Master，Kubernetes集群中的其他机器被称为Node，在较早的版本中也被称为Minion。与Master一样，Node可以是一台物理主机，也可以是一台虚拟机。Node是Kubernetes集群中的工作负载节点，每个Node都会被Master分配一些工作负载（Docker容器），当某个Node宕机时，其上的工作负载会被Master自动转移到其他节点上。<br>在每个Node上都运行着以下关键进程。</p>
<ul>
<li>kubelet：负责Pod对应的容器的创建、启停等任务，同时与Master密切协作，实现集群管理的基本功能</li>
<li>kube-proxy：实现Kubernetes Service的通信与负载均衡机制的重要组件。</li>
<li>Docker Engine（docker）：Docker引擎，负责本机的容器创建和管理工作。</li>
</ul>
<p>Node可以在运行期间动态增加到Kubernetes集群中，前提是在这个节点上已经正确安装、配置和启动了上述关键进程，在默认情况下kubelet会向Master注册自己，这也是Kubernetes推荐的Node管理方式。一旦Node被纳入集群管理范围，kubelet进程就会定时向Master汇报自身的情报，例如操作系统、Docker版本、机器的CPU和内存情况，以及当前有哪些Pod在运行等，这样Master就可以获知每个Node的资源使用情况，并实现高效均衡的资源调度策略。而某个Node在超过指定时间不上报信息时，会被Master判定为“失联”，Node的状态被标记为不可用<br>（Not Ready），随后Master会触发“工作负载大转移”的自动流程。</p>
<p>可以通过kubectl get nodes查看集群中有多少个node，然后可以通过kubectl describe node <node_ name>来查看某个node的具体信息。describe展示node的关键信息如下：</node_></p>
<ul>
<li>Node的基本信息：名称、标签、创建时间等。</li>
<li>Node当前的运行状态：Node启动后会做一系列的自检工作，比如磁盘空间是否不足（DiskPressure）、内存是否不足（MemoryPressure）、网络是否正常（NetworkUnavailable）、PID资源是否充（PIDPressure）。在一切正常时设置Node为Ready状态（Ready&#x3D;True），该状态表示Node处于健康状态，Master将可以在其上调度新的任务了（如启动Pod）。</li>
<li>Node的主机地址与主机名。</li>
<li>Node上的资源数量：描述Node可用的系统资源，包括CPU、内存数量、最大可调度Pod数量等。</li>
<li>Node可分配的资源量：描述Node当前可用于分配的资源量。</li>
<li>主机系统信息：包括主机ID、系统UUID、Linux  kernel版本号、操作系统类型与版本、Docker版本号、kubelet与kube-proxy的版本号等。</li>
<li>当前运行的Pod列表概要信息。</li>
<li>已分配的资源使用概要信息，例如资源申请的最低、最大允许使用量占系统总量的百分比。</li>
<li>Node相关的Event信息。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/posts/82ff0530.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小缺の域">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/posts/82ff0530.html" class="post-title-link" itemprop="url">成为高效的测试主管</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-01 22:42:40" itemprop="dateCreated datePublished" datetime="2022-03-01T22:42:40+08:00">2022-03-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E6%B5%8B%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">测试</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>如何成为高效的测试主管，打造一个更快乐、更成功的测试团队</p>
<h4 id="技能1-具备业务知识和技术技能"><a href="#技能1-具备业务知识和技术技能" class="headerlink" title="技能1  具备业务知识和技术技能"></a>技能1  具备业务知识和技术技能</h4><ul>
<li><p>一个组织通常会提出其业务目标，这些目标从更高级别的管理层一直转化为每个团队和个人。测试主管必须对项目路线图、总体组织目标、利益干系人和客户需求有良好的控制。在任何给定的时刻，他们必须能够提供任何测试团队成员所需的指导，以帮助他们了解他&#x2F;她正在扮演什么角色，以符合项目的成功，并且必须使他们能够看到更大的图景。</p>
</li>
<li><p>大多数情况下，测试人员发现测试主管可能无法完全理解他们在测试时面临的技术问题。测试主管必须具备所需的技能，以便能够使用任何工具，环境，系统等指导测试人员，并提供解决方案以克服他们可能面临的任何问题。在关键时刻，他们还必须自己承担一些工作，以减轻团队的负担。</p>
</li>
<li><p>业务本质上是非常动态的，很多时候，新的测试项目可能会在发布结束时添加。有时，已经测试过的项目可能会取消范围。在这两种情况下，测试主管必须指导测试人员，使他们能够客观地查看范围变化。测试线索的这种能力能够在技术上和其他方面指导团队，这将有助于团队成员依赖测试线索。</p>
</li>
</ul>
<h4 id="技能2-工作量估算和有效分配工作"><a href="#技能2-工作量估算和有效分配工作" class="headerlink" title="技能2 工作量估算和有效分配工作"></a>技能2 工作量估算和有效分配工作</h4><ul>
<li><p>当需求文档浮出水面时，测试主管和他的测试人员团队将编写测试计划，该计划将定义范围，硬件，软件，要测试的功能，计划等。在此基础上，对所需工作量进行规模估计，并进行适当的工作分配。</p>
</li>
<li><p>在测试团队中，有一些资深人士和一些初级人士。必须通过评估每个测试人员的利益来进行仔细的评估。任务必须使他们获得的工作不仅要让他们兴奋，还要建立在他们现有的知识库之上。</p>
</li>
<li><p>测试团队中的另一个常见问题是工作负载平衡。繁重的工作量是测试团队的重要组成部分，不断推动您的团队加班可能会导致饱和。如果潜在客户检测到可能存在繁重的工作负载，必须由更少的资源来覆盖，则必须尽早制定适当的缓解计划。在某些不可避免的情况下，必须随时向团队发布这是不可预见的情况，并且非常感谢他们愿意扩展。</p>
</li>
<li><p>其次，即使具有丰富经验的高级测试人员可以涵盖各种各样的行项目，但向他们施加更多的工作和责任肯定会阻止他们完成测试目标的兴趣。承担一些经过计算的风险，并将具有挑战性的物品分配给初级会员。他们渴望了解和成长，这可能有助于发展团队。</p>
</li>
</ul>
<h4 id="技能3-尽量不要过度提交"><a href="#技能3-尽量不要过度提交" class="headerlink" title="技能3 尽量不要过度提交"></a>技能3 尽量不要过度提交</h4><ul>
<li>通常，测试领导者，为了突出团队的技能，通过过度投入来给团队带来压力。现在，过度承诺可能意味着一个广泛的领域。</li>
</ul>
<p>例：如果在测试团队开始测试时测试范围发生了变化，并且认为测试内容增加。在这种情况下，当测试主管被要求提供有关尺寸和完成所需时间的输入时，往往会过度承诺他们可以花费更长的时间&#x2F;周末，并在相同的持续时间内”挤压”测试，而不会影响质量。这不仅设定了一个永久的期望，即测试团队将始终扩展自己，而且还迫使他们做出很多个人牺牲。</p>
<ul>
<li><p>在某些其他时候，过度投入可能意味着在发现缺陷&#x2F;逃避方面对测试团队设定不合理的期望。了解测试人员是人类，容易出错的基本事实至关重要。因此，设置过度不切实际的目标，即可以忽略不计&#x2F;没有缺陷逃逸是令人沮丧的，因为测试人员往往会对测试团队之外可能发现的任何缺陷负责。</p>
</li>
<li><p>过度投入会导致倦怠。在前一种情况下，测试范围发生变化，请与管理层进行相应的测试计划协商。在后一种情况下，要明白生活中没有什么是没有错误的，设定这样的目标只有在理论上听起来很棒。</p>
</li>
</ul>
<h4 id="技能4-各级沟通，人际交往能力"><a href="#技能4-各级沟通，人际交往能力" class="headerlink" title="技能4 各级沟通，人际交往能力"></a>技能4 各级沟通，人际交往能力</h4><p>无论是通过电子邮件，电话还是人际关系层面的沟通都应该是清单上的第一项，但就像它所说 - 将最好的留到最后。让我们来看看这如何影响几乎所有的技术和非技术方面。</p>
<p><strong>了解如何提出异议：</strong></p>
<p>作为测试主管，你是管理层和测试团队之间的接口。实际上没有”格式”可以与任何一方意见相左，但是当情况需要时，必须这样做。当然，有办法做到这一点。当涉及到测试人员时，您需要采取更敏感或更柔和的方法。</p>
<p>说到管理，你可能必须让他们看到你的想法的价值，而不是他们的事实信息。</p>
<p><strong>谈判技巧</strong>:</p>
<p>测试项目总是有一系列挑战，如环境问题，管理对测试进度的关注，管理层和各个团队之间对目标的理解不同，团队成员内部以及团队成员与管理层之间的人际关系问题&#x2F;冲突。在这种时候，测试领导者很难通过这些挑战看到光明。</p>
<p>有时高层不是很容易打交道，因此重要的是要以一种让另一方觉得他们的意见得到了考虑的方式进行谈判。同样，领导必须能够推动冲突的解决，其中双方都认为中间立场是他们可以同意的。</p>
<p><strong>鼓励与开发协作</strong>:</p>
<p>通常，当开发团队拒绝限制的缺陷时，测试人员会感到沮丧。虽然他们每个人都来自他们来自哪里，但这往往会导致测试和开发之间的”我们vs他们”的态度。测试负责人应推动测试团队与开发建立健康和协作的关系。</p>
<p><strong>将看到的两个好处：</strong></p>
<ul>
<li>测试人员可以更好地了解该功能的背景及其局限性和</li>
<li>开发人员了解最终用户如何看待代码。</li>
</ul>
<p><strong>向上级管理层报告和电子邮件通信：</strong></p>
<p>测试主管的很大一部分时间用于准备状态报告并向管理层报告进度。领导者是管理团队看到测试团队努力的窗口，因此他必须能够以清晰易懂的方式报告信息。</p>
<p>报告必须非常清楚地突出测试人员的成就，以使管理层能够立即意识到这一点。它还应该描述测试团队面临的问题，团队已经尝试或将要尝试的一系列事情，以解决这个问题，并且在超出他们控制范围的情况下，清楚地说明这一点 - 要求管理层指导解决。</p>
<p>即使测试团队的进度达不到标准，领导也必须能够向管理层灌输信心，即测试团队正在以最佳质量执行以满足最后期限。</p>
<p><strong>团队会议：</strong></p>
<p>毋庸置疑，测试负责人必须推动内部会议。这些会议将使他能够了解每个测试人员的任务，他当前的进展以及阻碍他进步的问题。牵头人应讨论与根本原因接近的问题，并就如何克服这些问题提出建议&#x2F;方法。</p>
<p>这个论坛也可以用来向团队成员传递赞赏或赞美，鼓励他们表现得更好，激励他人。偶尔发一封电子邮件来感谢他们的贡献，这是一个非常好的主意，可以让测试人员保持动力，让他们表现出色！</p>
<p>团队会议还可以使测试负责人确保测试人员在测试基础架构、项目清晰度、开发支持良好的缺陷周转时间等方面拥有他们所需要的东西。</p>
<p>团队会议形成了一个很好的平台来举行头脑风暴会议，其输出可以导致创新，流程改进，以执行日常工作。</p>
<p>除了技术方面，团队会议还使测试负责人能够与记者建立健康的关系。反过来，这也可以证明是他的一种学习，通过定期询问如何更好地管理的反馈。口头禅很简单：你成长，我成长！</p>
<p><strong>提供空间：</strong></p>
<p>特别是测试团队主要由不同的人员组成，每个人员都有自己的工作风格。大多数测试主管经常犯一个错误，即试图在团队中强制实施统一的文化，而这种文化在过去可能对他很有效。基本规则是让人们做自己的事情，除非它严重阻碍了项目进度。</p>
<p>在关键的里程碑日期 - 如果要求测试团队必须工作到很晚，周末才能满足时间表，给他们空间和自由，以他们希望的方式工作，这是最重要的。为每个人提供备份，以便让人们在需要的时候休息一下是可以的。</p>
<p>还要向他们保证，一旦达到最后期限，他们可以花一些时间充电。</p>
<p>特别是在一个成熟的测试团队中，几乎所有资源都有相当多的经验和可信度，强迫某些管理文化会导致公开的分歧和争论。了解团队在技术上所做的工作，提出有价值的建议，并让他们采取实现里程碑所需的东西。</p>
<p>不要时不时地出现在他们的办公桌前要求更新状态。这给这个人带来了很大的压力，如果他那天无法克服某个特定问题，就会有一种失败&#x2F;怨恨的感觉。</p>
<p>在命令中做第二个:</p>
<p>任何领导者的首要目标必须是创造火炬手;即创造其他领导者。事实上，这是优秀领导者最独特的品质之一。对于初级成员来说，虽然敏锐地回顾他们正在做的事情很重要，但如果他们被允许承认自己的角色，这对他们来说将是无价的学习。</p>
<p><strong>例如，</strong>如果他们在测试时遇到问题，使他们能够进行研究，跟进开发并推动其独立完成，除非有必要进行干预。这将有助于他们的成长。</p>
<p>与高级成员一起 - 让他们参与关键决策活动。他们的经验可以被证明是一种资产，所以要好好利用它。确保他们被投射为自己的领导者，将你自己的部分责任委托给他们。通过制作一个伙伴系统来授权他们指导初级成员，这将平等地帮助两个成员。</p>
<p><strong>电子邮件通信：</strong></p>
<p>这可能应该是这里几乎所有项目的子弹，也是企业领域任何个人的必备品质，更不用说领导者了。无论是准备报告，演讲，审查过程，传递赞赏等，拥有良好的沟通技巧对于有效表达自己至关重要。</p>
<h4 id="技能5-个人品质"><a href="#技能5-个人品质" class="headerlink" title="技能5 个人品质"></a>技能5 个人品质</h4><p>归根结底，测试人员是有感情的人。如果你的团队想发挥出他们最好的一面，并因为你的影响力而进一步扩大自己——那就把它看作是你最大的胜利。</p>
<ul>
<li>直截了当是成为优秀领导者的标志性标志。您的团队将能够依靠您分享哪些信息，并使您更容易接近他们。</li>
<li>对你的职位没有自我问题。如果你犯了一个错误，请毫无问题地为此道歉！</li>
<li>始终与团队分享您的荣誉，因为毕竟，只有您的团队闪耀，您才会发光。</li>
<li>尝试使用”我们的”，”我们”，”我们”而不是我，你，他或她。灌输一种相互主人翁意识。</li>
<li>表现出对工作的热情。为了让团队对自己的工作充满热情并与之相关，责任在于测试线索，以辐射这种能量。</li>
<li>即使在工作中也能享受自己。虽然大多数情况下都有团队活动和有趣的活动计划，但没有规定乐趣必须限制在某一天。我们一起度过了一天中的大部分时间都，事情压力很大。一起喝茶，共进午餐，庆祝生日，计划一些即兴活动。这将在很大程度上有助于加强人际关系。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/Echo/archives/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/Echo/archives/page/6/">6</a><a class="extend next" rel="next" href="/Echo/archives/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2020 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">丑牛</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/Echo/js/comments.js"></script><script src="/Echo/js/utils.js"></script><script src="/Echo/js/motion.js"></script><script src="/Echo/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/Echo/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"hugfeature","repo":"myBlogTalk","client_id":"f4b1fae431a4943a75f3","client_secret":"2b6995c484ff0a0a920d65ac7fd5bb1bf13fb2f2","admin_user":null,"distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":"zh-CN","js":{"url":"https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js","integrity":"sha256-Pmj85ojLaPOWwRtlMJwmezB/Qg8BzvJp5eTzvXaYAfA="},"path_md5":"62e7a0c6414fa96529635da1af7c9879"}</script>
<script src="/Echo/js/third-party/comments/gitalk.js"></script>

</body>
</html>
