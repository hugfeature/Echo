<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/Echo/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/Echo/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/Echo/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/Echo/images/logo.svg" color="#222">

<link rel="stylesheet" href="/Echo/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"hugfeature.github.io","root":"/Echo/","images":"/Echo/images","scheme":"Gemini","darkmode":false,"version":"8.8.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":true,"nav":{"gitalk":{"order":-2}}},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/Echo/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/Echo/js/config.js"></script>
<meta name="description" content="曾经梦想仗剑走天涯!因为遇见她，所以回了家！">
<meta property="og:type" content="website">
<meta property="og:title" content="青春召唤师">
<meta property="og:url" content="https://hugfeature.github.io/Echo/archives/index.html">
<meta property="og:site_name" content="青春召唤师">
<meta property="og:description" content="曾经梦想仗剑走天涯!因为遇见她，所以回了家！">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="丑牛">
<meta property="article:tag" content="程序员，springboot，测试，springcloud，成长，java">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://hugfeature.github.io/Echo/archives/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"archives/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>青春召唤师</title>
  




  <noscript>
    <link rel="stylesheet" href="/Echo/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/Echo/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">青春召唤师</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Stay hungry, Stay foolish</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/Echo/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/Echo/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-categories"><a href="/Echo/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-commonweal"><a href="/Echo/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>公益 404</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">丑牛</p>
  <div class="site-description" itemprop="description">曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！</div>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/hugfeature" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2022/01/19/kubekey%E5%AE%89%E8%A3%85K8S%E9%9B%86%E7%BE%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2022/01/19/kubekey%E5%AE%89%E8%A3%85K8S%E9%9B%86%E7%BE%A4/" class="post-title-link" itemprop="url">kubekey安装K8S集群</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-19 21:09:33" itemprop="dateCreated datePublished" datetime="2022-01-19T21:09:33+08:00">2022-01-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/" itemprop="url" rel="index"><span itemprop="name">环境安装</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="一-K8S1-20-x的重要更新"><a href="#一-K8S1-20-x的重要更新" class="headerlink" title="一.K8S1.20.x的重要更新"></a>一.K8S1.20.x的重要更新</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、Kubectl debug 设置一个临时容器</span><br><span class="line">2、Sidecar </span><br><span class="line">3、Volume：更改目录权限，fsGroup</span><br><span class="line">4、ConfigMap和Secret</span><br><span class="line"></span><br><span class="line">K8S官网：https://kubernetes.io/docs/setup/</span><br><span class="line">最新版高可用安装：https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/</span><br></pre></td></tr></table></figure>

<h2 id="二-K8S1-20-x的安装"><a href="#二-K8S1-20-x的安装" class="headerlink" title="二.K8S1.20.x的安装"></a>二.K8S1.20.x的安装</h2><h2 id="2-1-集群规划"><a href="#2-1-集群规划" class="headerlink" title="2.1 集群规划"></a>2.1 集群规划</h2><table>
<thead>
<tr>
<th align="center">主机名</th>
<th align="center">IP地址</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">k8s-worker6</td>
<td align="center">X.X.X.X</td>
<td align="center">master节点</td>
</tr>
<tr>
<td align="center">k8s-worker7</td>
<td align="center">X.X.X.X</td>
<td align="center">worker01节点</td>
</tr>
<tr>
<td align="center">k8s-worker8</td>
<td align="center">X.X.X.X</td>
<td align="center">worker02节点</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看Centos版本</span></span><br><span class="line">cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.9.2009 (Core)</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#https://www.cnblogs.com/liucx/</span></span></span><br></pre></td></tr></table></figure>

<h2 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> master节点</span></span><br><span class="line">hostnamectl set-hostname k8s-worker6</span><br><span class="line"><span class="meta">#</span><span class="bash">node1节点</span></span><br><span class="line">hostnamectl set-hostname k8s-worker7</span><br><span class="line"><span class="meta">#</span><span class="bash">node2节点</span></span><br><span class="line">hostnamectl set-hostname k8s-worker8</span><br></pre></td></tr></table></figure>

<h2 id="所有节点配置hosts，修改-etc-hosts如下："><a href="#所有节点配置hosts，修改-etc-hosts如下：" class="headerlink" title="所有节点配置hosts，修改/etc/hosts如下："></a><strong>所有节点配置hosts，修改/etc/hosts如下：</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">所有节点配置hosts，修改/etc/hosts如下：</span><br><span class="line"></span><br><span class="line">cat /etc/hosts </span><br><span class="line"></span><br><span class="line">::1    localhost	localhost.localdomain	localhost6	localhost6.localdomain6</span><br><span class="line">127.0.0.1 localhost  localhost</span><br><span class="line"></span><br><span class="line">X.X.X.X k8s-worker8  k8s-worker8</span><br><span class="line">X.X.X.X k8s-worker6  k8s-worker6</span><br><span class="line">X.X.X.X k8s-worker7  k8s-worker7</span><br></pre></td></tr></table></figure>

<h2 id="2-2-更新配置-（所有节点全部安装）"><a href="#2-2-更新配置-（所有节点全部安装）" class="headerlink" title="2.2 更新配置 （所有节点全部安装）"></a>2.2 <strong>更新配置 （所有节点全部安装）</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点安装</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Centos 7安装yum源如下：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更改为国内阿里yum源</span></span><br><span class="line">[root@k8s-worker6 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">[root@k8s-worker6 ~]# yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">[root@k8s-worker6 ~]# yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">[root@k8s-worker6 ~]# cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line">[root@k8s-worker6 ~]# sed -i -e &#x27;/mirrors.cloud.aliyuncs.com/d&#x27; -e &#x27;/mirrors.aliyuncs.com/d&#x27; /etc/yum.repos.d/CentOS-Base.repo</span><br></pre></td></tr></table></figure>

<h2 id="安装必备工具"><a href="#安装必备工具" class="headerlink" title="安装必备工具"></a>安装必备工具</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y</span><br></pre></td></tr></table></figure>

<h2 id="所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下："><a href="#所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下：" class="headerlink" title="所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下："></a>所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# systemctl disable --now firewalld </span><br><span class="line">[root@k8s-worker6 ~]# systemctl disable --now dnsmasq</span><br><span class="line">[root@k8s-worker6 ~]# systemctl disable --now NetworkManager</span><br><span class="line"></span><br><span class="line">[root@k8s-worker6 ~]# setenforce 0</span><br><span class="line">[root@k8s-worker6 ~]# sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/sysconfig/selinux</span><br><span class="line">[root@k8s-worker6 ~]# sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<h2 id="关闭swap分区（所有节点）"><a href="#关闭swap分区（所有节点）" class="headerlink" title="关闭swap分区（所有节点）"></a>关闭swap分区（所有节点）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">[root@k8s-worker6 ~]# sed -ri &#x27;/^[^#]*swap/s@^@#@&#x27; /etc/fstab</span><br></pre></td></tr></table></figure>

<h2 id="时钟同步"><a href="#时钟同步" class="headerlink" title="时钟同步"></a>时钟同步</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装同步时钟ntpdate</span></span><br><span class="line">[root@k8s-worker6 ~]# rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm</span><br><span class="line">[root@k8s-worker6 ~]# yum install ntpdate -y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有节点同步时间。时间同步配置如下：</span></span><br><span class="line">[root@k8s-worker6 ~]# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">[root@k8s-worker6 ~]# echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezone</span><br><span class="line">[root@k8s-worker6 ~]# ntpdate time2.aliyun.com</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 加入到crontab,每5分钟同步一次</span></span><br><span class="line">[root@k8s-worker6 ~]# crontab -e</span><br><span class="line">*/5 * * * * ntpdate time2.aliyun.com</span><br></pre></td></tr></table></figure>

<h2 id="配置limit"><a href="#配置limit" class="headerlink" title="配置limit"></a>配置limit</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# ulimit -SHn 65535</span><br><span class="line">[root@k8s-worker6 ~]# vim /etc/security/limits.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 末尾添加如下内容</span></span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* soft memlock unlimited</span><br><span class="line">* hard memlock unlimite</span><br></pre></td></tr></table></figure>

<h2 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Master01节点免密钥登录其他节点：</span></span><br><span class="line">[root@k8s-worker6 ~]# ssh-keygen -t rsa</span><br><span class="line">[root@k8s-worker6 ~]# ssh-copy-id -i root@X.X.X.X</span><br><span class="line">[root@k8s-worker6 ~]# ssh-copy-id -i root@X.X.X.X</span><br></pre></td></tr></table></figure>

<h2 id="所有节点升级重启"><a href="#所有节点升级重启" class="headerlink" title="所有节点升级重启"></a>所有节点升级重启</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# yum update -y  &amp;&amp; reboot </span><br></pre></td></tr></table></figure>

<h2 id="2-3-Linux内核升级（所有节点）"><a href="#2-3-Linux内核升级（所有节点）" class="headerlink" title="2.3 Linux内核升级（所有节点）"></a>2.3 Linux内核升级（所有节点）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CentOS7 需要升级内核至4.18+  https://www.kernel.org/ 和 https://elrepo.org/linux/kernel/el7/x86_64/</span><br><span class="line">CentOS 7 dnf可能无法安装内核</span><br><span class="line">[root@k8s-worker6 ~]# dnf --disablerepo=\* --enablerepo=elrepo -y install kernel-ml kernel-ml-devel</span><br><span class="line">[root@k8s-worker6 ~]# grubby --default-kernel</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用如下指令查看内核版本</span></span><br><span class="line">[root@k8s-worker6 ~]# uname -a</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用如下指令安装最新内核</span></span><br><span class="line"><span class="meta">#</span><span class="bash">导入ELRepo软件仓库的公共秘钥</span></span><br><span class="line">[root@k8s-worker6 ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line"><span class="meta">#</span><span class="bash">安装ELRepo软件仓库的yum源</span></span><br><span class="line">[root@k8s-worker6 ~]# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看最新版内核</span></span><br><span class="line">[root@k8s-worker6 ~]# yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装最新版内核</span></span><br><span class="line">[root@k8s-worker6 ~]# yum --enablerepo=elrepo-kernel install kernel-ml kernel-ml-devel –y</span><br><span class="line">[root@k8s-worker6 ~]# reboot</span><br><span class="line"><span class="meta">#</span><span class="bash"> 更改内核顺序</span></span><br><span class="line">[root@k8s-worker6 ~]# grub2-set-default  0 &amp;&amp; grub2-mkconfig -o /etc/grub2.cfg &amp;&amp; grubby --args=&quot;user_namespace.enable=1&quot; --update-kernel=&quot;$(grubby --default-kernel)&quot; &amp;&amp; reboot</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开机查看内核</span></span><br><span class="line">[root@k8s-worker6 ~]# uname -a</span><br></pre></td></tr></table></figure>

<h2 id="安装ipvsadm"><a href="#安装ipvsadm" class="headerlink" title="安装ipvsadm"></a>安装ipvsadm</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点安装ipvsadm</span></span><br><span class="line">[root@k8s-worker6 ~]# yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有节点配置ipvs模块，在内核4.19+版本nf_conntrack_ipv4已经改为nf_conntrack。</span></span><br><span class="line">[root@k8s-worker6 ~]# vim /etc/modules-load.d/ipvs.conf</span><br><span class="line">[root@k8s-worker6 ~]# systemctl enable --now systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<p>![img](D:/GitLab_item/zz-study-notes/5.Cloud Native/images/k8s-zl/4.jpg)</p>
<h2 id="开启一些k8s集群中必须的内核参数，所有节点配置k8s内核："><a href="#开启一些k8s集群中必须的内核参数，所有节点配置k8s内核：" class="headerlink" title="开启一些k8s集群中必须的内核参数，所有节点配置k8s内核："></a>开启一些k8s集群中必须的内核参数，所有节点配置k8s内核：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> k8s内核装载并应用</span></span><br><span class="line">[root@k8s-worker6 ~]# sysctl --system</span><br></pre></td></tr></table></figure>

<h1 id="三-所有节点K8S基本组件安装"><a href="#三-所有节点K8S基本组件安装" class="headerlink" title="三.所有节点K8S基本组件安装"></a>三.<strong>所有节点K8S基本组件安装</strong></h1><h2 id="3-1-安装docker-ce"><a href="#3-1-安装docker-ce" class="headerlink" title="3.1 安装docker-ce"></a>3.1 安装docker-ce</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# wget https://download.docker.com/linux/centos/7/x86_64/edge/Packages/containerd.io-1.2.13-3.2.el7.x86_64.rpm</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装docker-ce 19.03版本</span></span><br><span class="line">[root@k8s-worker8 ~]# yum install -y docker-ce-cli-19.03.8-3.el7.x86_64 docker-ce-19.03.8-3.el7.x86_64</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看安装的docker版本</span></span><br><span class="line">[root@k8s-worker8 ~]# rpm -qa|grep </span><br></pre></td></tr></table></figure>

<blockquote>
<h2 id="kubeadm不改如下字段，kubelet无法启动温馨提示：由于新版kubelet建议使用systemd，所以可以把docker的CgroupDriver改成systemd。（重要）"><a href="#kubeadm不改如下字段，kubelet无法启动温馨提示：由于新版kubelet建议使用systemd，所以可以把docker的CgroupDriver改成systemd。（重要）" class="headerlink" title="kubeadm不改如下字段，kubelet无法启动温馨提示：由于新版kubelet建议使用systemd，所以可以把docker的CgroupDriver改成systemd。（重要）"></a>kubeadm不改如下字段，kubelet无法启动温馨提示：由于新版kubelet建议使用systemd，所以可以把docker的CgroupDriver改成systemd。（重要）</h2></blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启</span></span><br><span class="line">[root@k8s-worker8 ~]# systemctl restart docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看docekr配置文件，主要看Cgroup Driver: systemd</span></span><br><span class="line">[root@k8s-worker7 ~]# docker info</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">启动docker</span></span><br><span class="line">[root@k8s-worker8 ~]# service docker start</span><br><span class="line">[root@k8s-worker8 ~]# chkconfig docker on</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点设置开机启动docker</span></span><br><span class="line">[root@k8s-worker8 ~]# systemctl daemon-reload &amp;&amp; systemctl enable --now docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看Docker的状态</span></span><br><span class="line">[root@k8s-worker8 ~]# systemctl status docker</span><br></pre></td></tr></table></figure>

<h2 id="3-2-kubekey安装K8S集群"><a href="#3-2-kubekey安装K8S集群" class="headerlink" title="3.2 kubekey安装K8S集群"></a>3.2 kubekey安装K8S集群</h2><h3 id="3-2-1-下载KubeKey"><a href="#3-2-1-下载KubeKey" class="headerlink" title="3.2.1 下载KubeKey"></a>3.2.1 下载KubeKey</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 首先运行以下命令以确保从正确的区域下载 KubeKey。</span></span><br><span class="line">export KKZONE=cn</span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行以下命令下载 KubeKey：</span></span><br><span class="line">curl -sfL https://get-kk.kubesphere.io | VERSION=v1.1.1 sh -</span><br><span class="line">chmod +x kk</span><br></pre></td></tr></table></figure>

<p>kubekey安装的K8S集群版本和KubeSpherev3.1.1，请参阅下表支持的Kubenetes版本。</p>
<table>
<thead>
<tr>
<th align="center">KubeSphere 版本</th>
<th>支持的 Kubernetes 版本</th>
</tr>
</thead>
<tbody><tr>
<td align="center">v3.1.1</td>
<td>v1.17.0, v1.17.4, v1.17.5, v1.17.6, v1.17.7, v1.17.8, v1.17.9, v1.18.3, v1.18.5, v1.18.6, v1.18.8, v1.19.0, v1.19.0 19.8、v1.19.9、v1.20.4、v1.20.6</td>
</tr>
</tbody></table>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  您还可以运行如下命令以查看 KubeKey 可以安装的所有受支持的 Kubernetes 版本。</span></span><br><span class="line">[root@k8s-worker6 yaml]<span class="comment"># ./kk version --show-supported-k8s</span></span><br><span class="line"><span class="comment"># 使用 KubeKey 可以安装的 Kubernetes 版本与 KubeSphere v3.0.0 支持的 Kubernetes 版本不同。如果您想在现有的 Kubernetes 集群上安装 KubeSphere v3.1.1，您的 Kubernetes 版本必须是 v1.17.x、v1.18.x、v1.19.x 或 v1.20.x。</span></span><br></pre></td></tr></table></figure>

<h3 id="3-2-2-创建Kubernetes多节点集群"><a href="#3-2-2-创建Kubernetes多节点集群" class="headerlink" title="3.2.2 创建Kubernetes多节点集群"></a>3.2.2 创建Kubernetes多节点集群</h3><p>首先创建示例配置文件，执行如下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 yaml]# ./kk create config --with-kubernetes 1.20.6 --with-kubesphere 3.1.1 -f config-sample.yaml</span><br></pre></td></tr></table></figure>

<p>下面为一个示例的config-sample.yaml文件：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">kubekey.kubesphere.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Cluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">sample</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">hosts:</span></span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-worker6</span>, <span class="attr">address:</span> <span class="string">IP</span>, <span class="attr">internalAddress:</span> <span class="string">IP</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">passWord</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-worker7</span>, <span class="attr">address:</span> <span class="string">IP</span>, <span class="attr">internalAddress:</span> <span class="string">IP</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">passWord</span>&#125;</span><br><span class="line">  <span class="bullet">-</span> &#123;<span class="attr">name:</span> <span class="string">k8s-worker8</span>, <span class="attr">address:</span> <span class="string">IP</span>, <span class="attr">internalAddress:</span> <span class="string">IP</span>, <span class="attr">user:</span> <span class="string">root</span>, <span class="attr">password:</span> <span class="string">passWord</span>&#125;</span><br><span class="line">  <span class="attr">roleGroups:</span></span><br><span class="line">    <span class="attr">etcd:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-worker6</span></span><br><span class="line">    <span class="attr">master:</span> </span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-worker6</span></span><br><span class="line">    <span class="attr">worker:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-worker7</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">k8s-worker8</span></span><br><span class="line">  <span class="attr">controlPlaneEndpoint:</span></span><br><span class="line">    <span class="attr">domain:</span> <span class="string">lb.kubesphere.local</span></span><br><span class="line">    <span class="attr">address:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6443</span></span><br><span class="line">  <span class="attr">kubernetes:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v1.20.4</span></span><br><span class="line">    <span class="attr">imageRepo:</span> <span class="string">kubesphere</span></span><br><span class="line">    <span class="attr">clusterName:</span> <span class="string">cluster.local</span></span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">plugin:</span> <span class="string">calico</span></span><br><span class="line">    <span class="attr">kubePodsCIDR:</span> <span class="number">10.233</span><span class="number">.64</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">    <span class="attr">kubeServiceCIDR:</span> <span class="number">10.233</span><span class="number">.0</span><span class="number">.0</span><span class="string">/18</span></span><br><span class="line">  <span class="attr">registry:</span></span><br><span class="line">    <span class="attr">registryMirrors:</span> []</span><br><span class="line">    <span class="attr">insecureRegistries:</span> []</span><br><span class="line">  <span class="attr">addons:</span> []</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">installer.kubesphere.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterConfiguration</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">ks-installer</span></span><br><span class="line">  <span class="attr">namespace:</span> <span class="string">kubesphere-system</span></span><br><span class="line">  <span class="attr">labels:</span></span><br><span class="line">    <span class="attr">version:</span> <span class="string">v3.1.1</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="attr">persistence:</span></span><br><span class="line">    <span class="attr">storageClass:</span> <span class="string">&quot;&quot;</span>       </span><br><span class="line">  <span class="attr">authentication:</span></span><br><span class="line">    <span class="attr">jwtSecret:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">zone:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">  <span class="attr">local_registry:</span> <span class="string">&quot;&quot;</span>        </span><br><span class="line">  <span class="attr">etcd:</span></span><br><span class="line">    <span class="attr">monitoring:</span> <span class="literal">false</span>      </span><br><span class="line">    <span class="attr">endpointIps:</span> <span class="string">localhost</span>  </span><br><span class="line">    <span class="attr">port:</span> <span class="number">2379</span>             </span><br><span class="line">    <span class="attr">tlsEnable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">common:</span></span><br><span class="line">    <span class="attr">redis:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">redisVolumSize:</span> <span class="string">2Gi</span> </span><br><span class="line">    <span class="attr">openldap:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">openldapVolumeSize:</span> <span class="string">2Gi</span>  </span><br><span class="line">    <span class="attr">minioVolumeSize:</span> <span class="string">20Gi</span></span><br><span class="line">    <span class="attr">monitoring:</span></span><br><span class="line">      <span class="attr">endpoint:</span> <span class="string">http://prometheus-operated.kubesphere-monitoring-system.svc:9090</span></span><br><span class="line">    <span class="attr">es:</span>  </span><br><span class="line">      <span class="attr">elasticsearchMasterVolumeSize:</span> <span class="string">4Gi</span>   </span><br><span class="line">      <span class="attr">elasticsearchDataVolumeSize:</span> <span class="string">20Gi</span>   </span><br><span class="line">      <span class="attr">logMaxAge:</span> <span class="number">7</span>          </span><br><span class="line">      <span class="attr">elkPrefix:</span> <span class="string">logstash</span></span><br><span class="line">      <span class="attr">basicAuth:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">        <span class="attr">username:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="attr">password:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">      <span class="attr">externalElasticsearchUrl:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">      <span class="attr">externalElasticsearchPort:</span> <span class="string">&quot;&quot;</span>  </span><br><span class="line">  <span class="attr">console:</span></span><br><span class="line">    <span class="attr">enableMultiLogin:</span> <span class="literal">true</span> </span><br><span class="line">    <span class="attr">port:</span> <span class="number">30880</span></span><br><span class="line">  <span class="attr">alerting:</span>       </span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># thanosruler:</span></span><br><span class="line">    <span class="comment">#   replicas: 1</span></span><br><span class="line">    <span class="comment">#   resources: &#123;&#125;</span></span><br><span class="line">  <span class="attr">auditing:</span>    </span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">  <span class="attr">devops:</span>           </span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">jenkinsMemoryLim:</span> <span class="string">2Gi</span>     </span><br><span class="line">    <span class="attr">jenkinsMemoryReq:</span> <span class="string">1500Mi</span> </span><br><span class="line">    <span class="attr">jenkinsVolumeSize:</span> <span class="string">8Gi</span>   </span><br><span class="line">    <span class="attr">jenkinsJavaOpts_Xms:</span> <span class="string">512m</span>  </span><br><span class="line">    <span class="attr">jenkinsJavaOpts_Xmx:</span> <span class="string">512m</span></span><br><span class="line">    <span class="attr">jenkinsJavaOpts_MaxRAM:</span> <span class="string">2g</span></span><br><span class="line">  <span class="attr">events:</span>          </span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">ruler:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">logging:</span>         </span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">logsidecar:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">replicas:</span> <span class="number">2</span></span><br><span class="line">  <span class="attr">metrics_server:</span>             </span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">monitoring:</span></span><br><span class="line">    <span class="attr">storageClass:</span> <span class="string">&quot;&quot;</span></span><br><span class="line">    <span class="attr">prometheusMemoryRequest:</span> <span class="string">400Mi</span>  </span><br><span class="line">    <span class="attr">prometheusVolumeSize:</span> <span class="string">20Gi</span>  </span><br><span class="line">  <span class="attr">multicluster:</span></span><br><span class="line">    <span class="attr">clusterRole:</span> <span class="string">none</span> </span><br><span class="line">  <span class="attr">network:</span></span><br><span class="line">    <span class="attr">networkpolicy:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">false</span></span><br><span class="line">    <span class="attr">ippool:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">none</span></span><br><span class="line">    <span class="attr">topology:</span></span><br><span class="line">      <span class="attr">type:</span> <span class="string">none</span></span><br><span class="line">  <span class="attr">openpitrix:</span></span><br><span class="line">    <span class="attr">store:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">servicemesh:</span>    </span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span>  </span><br><span class="line">  <span class="attr">kubeedge:</span></span><br><span class="line">    <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">cloudCore:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span> &#123;<span class="attr">&quot;node-role.kubernetes.io/worker&quot;:</span> <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">      <span class="attr">tolerations:</span> []</span><br><span class="line">      <span class="attr">cloudhubPort:</span> <span class="string">&quot;10000&quot;</span></span><br><span class="line">      <span class="attr">cloudhubQuicPort:</span> <span class="string">&quot;10001&quot;</span></span><br><span class="line">      <span class="attr">cloudhubHttpsPort:</span> <span class="string">&quot;10002&quot;</span></span><br><span class="line">      <span class="attr">cloudstreamPort:</span> <span class="string">&quot;10003&quot;</span></span><br><span class="line">      <span class="attr">tunnelPort:</span> <span class="string">&quot;10004&quot;</span></span><br><span class="line">      <span class="attr">cloudHub:</span></span><br><span class="line">        <span class="attr">advertiseAddress:</span> </span><br><span class="line">          <span class="bullet">-</span> <span class="string">&quot;&quot;</span>           </span><br><span class="line">        <span class="attr">nodeLimit:</span> <span class="string">&quot;100&quot;</span></span><br><span class="line">      <span class="attr">service:</span></span><br><span class="line">        <span class="attr">cloudhubNodePort:</span> <span class="string">&quot;30000&quot;</span></span><br><span class="line">        <span class="attr">cloudhubQuicNodePort:</span> <span class="string">&quot;30001&quot;</span></span><br><span class="line">        <span class="attr">cloudhubHttpsNodePort:</span> <span class="string">&quot;30002&quot;</span></span><br><span class="line">        <span class="attr">cloudstreamNodePort:</span> <span class="string">&quot;30003&quot;</span></span><br><span class="line">        <span class="attr">tunnelNodePort:</span> <span class="string">&quot;30004&quot;</span></span><br><span class="line">    <span class="attr">edgeWatcher:</span></span><br><span class="line">      <span class="attr">nodeSelector:</span> &#123;<span class="attr">&quot;node-role.kubernetes.io/worker&quot;:</span> <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">      <span class="attr">tolerations:</span> []</span><br><span class="line">      <span class="attr">edgeWatcherAgent:</span></span><br><span class="line">        <span class="attr">nodeSelector:</span> &#123;<span class="attr">&quot;node-role.kubernetes.io/worker&quot;:</span> <span class="string">&quot;&quot;</span>&#125;</span><br><span class="line">        <span class="attr">tolerations:</span> []</span><br></pre></td></tr></table></figure>

<p>使用如下命令创建集群：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# ./kk create cluster -f config-sample.yaml</span><br></pre></td></tr></table></figure>

<h3 id="3-2-3-验证安装"><a href="#3-2-3-验证安装" class="headerlink" title="3.2.3 验证安装"></a>3.2.3 验证安装</h3><p>安装完成后，可以看到如下内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"><span class="comment">###              Welcome to KubeSphere!           ###</span></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"></span><br><span class="line">Console: http://192.168.0.2:30880</span><br><span class="line">Account: admin</span><br><span class="line">Password: P@88w0rd</span><br><span class="line"></span><br><span class="line">NOTES：</span><br><span class="line">  1. After you <span class="built_in">log</span> into the console, please check the</span><br><span class="line">     monitoring status of service components <span class="keyword">in</span></span><br><span class="line">     the <span class="string">&quot;Cluster Management&quot;</span>. If any service is not</span><br><span class="line">     ready, please <span class="built_in">wait</span> patiently until all components</span><br><span class="line">     are up and running.</span><br><span class="line">  2. Please change the default password after login.</span><br><span class="line"></span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line">https://kubesphere.io             20xx-xx-xx xx:xx:xx</span><br><span class="line"><span class="comment">#####################################################</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>现在，您将能够使用<code>&lt;NodeIP&gt;:30880</code>默认帐户和密码 ( <code>admin/P@88w0rd</code>)访问 KubeSphere 的 Web 控制台。</p>
<h3 id="3-2-4-查看集群状态"><a href="#3-2-4-查看集群状态" class="headerlink" title="3.2.4 查看集群状态"></a>3.2.4 查看集群状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 yaml]# kubectl get nodes</span><br></pre></td></tr></table></figure>

<h3 id="3-2-5-查看cs状态"><a href="#3-2-5-查看cs状态" class="headerlink" title="3.2.5 查看cs状态"></a>3.2.5 <strong>查看cs状态</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# kubectl get cs</span><br></pre></td></tr></table></figure>

<p>如若为status为unhealthy，则执行下述操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# vi /etc/kubernetes/manifests/kube-scheduler.yaml</span><br><span class="line">[root@k8s-worker6 ~]# vi /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 将两个文件中的- --port=0这一行注释掉</span></span></span><br></pre></td></tr></table></figure>

<h2 id="3-3-安装flannel插件-Master节点-Kubesphere已经安装calico作为网络插件-（此步骤不用执行）"><a href="#3-3-安装flannel插件-Master节点-Kubesphere已经安装calico作为网络插件-（此步骤不用执行）" class="headerlink" title="3.3 安装flannel插件(Master节点)(Kubesphere已经安装calico作为网络插件)（此步骤不用执行）"></a>3.3 <strong>安装flannel插件(Master节点)</strong>(Kubesphere已经安装calico作为网络插件)（此步骤不用执行）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# curl -o kube-flannel.yml https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>

<p>如果显示超时，直接复制下述文件，下面为kube-flannel.yml文件的具体内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: psp.flannel.unprivileged</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default</span><br><span class="line">    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default</span><br><span class="line">    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default</span><br><span class="line">spec:</span><br><span class="line">  privileged: <span class="literal">false</span></span><br><span class="line">  volumes:</span><br><span class="line">  - configMap</span><br><span class="line">  - secret</span><br><span class="line">  - emptyDir</span><br><span class="line">  - hostPath</span><br><span class="line">  allowedHostPaths:</span><br><span class="line">  - pathPrefix: <span class="string">&quot;/etc/cni/net.d&quot;</span></span><br><span class="line">  - pathPrefix: <span class="string">&quot;/etc/kube-flannel&quot;</span></span><br><span class="line">  - pathPrefix: <span class="string">&quot;/run/flannel&quot;</span></span><br><span class="line">  readOnlyRootFilesystem: <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Users and groups</span></span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  <span class="comment"># Privilege Escalation</span></span><br><span class="line">  allowPrivilegeEscalation: <span class="literal">false</span></span><br><span class="line">  defaultAllowPrivilegeEscalation: <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Capabilities</span></span><br><span class="line">  allowedCapabilities: [<span class="string">&#x27;NET_ADMIN&#x27;</span>, <span class="string">&#x27;NET_RAW&#x27;</span>]</span><br><span class="line">  defaultAddCapabilities: []</span><br><span class="line">  requiredDropCapabilities: []</span><br><span class="line">  <span class="comment"># Host namespaces</span></span><br><span class="line">  hostPID: <span class="literal">false</span></span><br><span class="line">  hostIPC: <span class="literal">false</span></span><br><span class="line">  hostNetwork: <span class="literal">true</span></span><br><span class="line">  hostPorts:</span><br><span class="line">  - min: 0</span><br><span class="line">    max: 65535</span><br><span class="line">  <span class="comment"># SELinux</span></span><br><span class="line">  seLinux:</span><br><span class="line">    <span class="comment"># SELinux is unused in CaaSP</span></span><br><span class="line">    rule: <span class="string">&#x27;RunAsAny&#x27;</span></span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [<span class="string">&#x27;extensions&#x27;</span>]</span><br><span class="line">  resources: [<span class="string">&#x27;podsecuritypolicies&#x27;</span>]</span><br><span class="line">  verbs: [<span class="string">&#x27;use&#x27;</span>]</span><br><span class="line">  resourceNames: [<span class="string">&#x27;psp.flannel.unprivileged&#x27;</span>]</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">&quot;&quot;</span></span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">&quot;&quot;</span></span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">&quot;&quot;</span></span><br><span class="line">  resources:</span><br><span class="line">  - nodes/status</span><br><span class="line">  verbs:</span><br><span class="line">  - patch</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: flannel</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-cfg</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">data:</span><br><span class="line">  cni-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;name&quot;</span>: <span class="string">&quot;cbr0&quot;</span>,</span><br><span class="line">      <span class="string">&quot;cniVersion&quot;</span>: <span class="string">&quot;0.3.1&quot;</span>,</span><br><span class="line">      <span class="string">&quot;plugins&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">&quot;type&quot;</span>: <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">          <span class="string">&quot;delegate&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;hairpinMode&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="string">&quot;isDefaultGateway&quot;</span>: <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">&quot;type&quot;</span>: <span class="string">&quot;portmap&quot;</span>,</span><br><span class="line">          <span class="string">&quot;capabilities&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;portMappings&quot;</span>: <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;Network&quot;</span>: <span class="string">&quot;10.244.0.0/16&quot;</span>,</span><br><span class="line">      <span class="string">&quot;Backend&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Type&quot;</span>: <span class="string">&quot;vxlan&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: flannel</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      affinity:</span><br><span class="line">        nodeAffinity:</span><br><span class="line">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">            nodeSelectorTerms:</span><br><span class="line">            - matchExpressions:</span><br><span class="line">              - key: kubernetes.io/os</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                - linux</span><br><span class="line">      hostNetwork: <span class="literal">true</span></span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: quay.io/coreos/flannel:v0.14.0</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - /etc/kube-flannel/cni-conf.json</span><br><span class="line">        - /etc/cni/net.d/10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: /etc/cni/net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: /etc/kube-flannel/</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io/coreos/flannel:v0.14.0</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - /opt/bin/flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: <span class="string">&quot;100m&quot;</span></span><br><span class="line">            memory: <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          limits:</span><br><span class="line">            cpu: <span class="string">&quot;100m&quot;</span></span><br><span class="line">            memory: <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: <span class="literal">false</span></span><br><span class="line">          capabilities:</span><br><span class="line">            add: [<span class="string">&quot;NET_ADMIN&quot;</span>, <span class="string">&quot;NET_RAW&quot;</span>]</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: /run/flannel</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: /etc/kube-flannel/</span><br><span class="line">      volumes:</span><br><span class="line">      - name: run</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /run/flannel</span><br><span class="line">      - name: cni</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/cni/net.d</span><br><span class="line">      - name: flannel-cfg</span><br><span class="line">        configMap:</span><br><span class="line">          name: kube-flannel-cfg</span><br></pre></td></tr></table></figure>

<h3 id="使用kubectl安装flannel插件"><a href="#使用kubectl安装flannel插件" class="headerlink" title="使用kubectl安装flannel插件"></a>使用kubectl安装flannel插件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装flannel插件</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl apply -f kube-flannel.yml</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次查看node状态，此时应该全为Ready状态</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl get nodes</span><br></pre></td></tr></table></figure>

<h3 id="4-4-1部署flannel网络插件时发现flannel-pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr"><a href="#4-4-1部署flannel网络插件时发现flannel-pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr" class="headerlink" title="4.4.1部署flannel网络插件时发现flannel pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr"></a>4.4.1<strong>部署flannel网络插件时发现flannel pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看pods运行状态</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl get pods --all-namespaces</span><br><span class="line"><span class="meta">#</span><span class="bash"> 针对失败的pods通过日志查找原因</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl logs kube-flannel-ds-2qhdt -n kube-system</span><br></pre></td></tr></table></figure>

<p>解决方法如下,master节点修改/etc/kubernetes/manifests/kube-controller-manager.yaml文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# vim /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line">增加参数：</span><br><span class="line">--allocate-node-cidrs=true</span><br><span class="line">--cluster-cidr=10.244.0.0/16</span><br><span class="line">重启kubelet</span><br><span class="line">[root@k8s-worker6 ~]# systemctl restart kubelet</span><br><span class="line">[root@k8s-worker6 yaml]# kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure>

<h2 id="4-5-Master节点添加自动补全脚本到系统"><a href="#4-5-Master节点添加自动补全脚本到系统" class="headerlink" title="4.5 Master节点添加自动补全脚本到系统"></a>4.5 Master节点添加自动补全脚本到系统</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# yum install -y bash-completion</span><br><span class="line">[root@k8s-worker6 ~]# source /usr/share/bash-completion/bash_completion</span><br><span class="line">[root@k8s-worker6 ~]# source &lt;(kubectl completion bash)</span><br><span class="line">[root@k8s-worker6 ~]# echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2022/01/18/kubeadm%E5%AE%89%E8%A3%85K8S%EF%BC%88V1-22%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2022/01/18/kubeadm%E5%AE%89%E8%A3%85K8S%EF%BC%88V1-22%EF%BC%89/" class="post-title-link" itemprop="url">kubeadm安装K8S（V1.22）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-18 21:15:24" itemprop="dateCreated datePublished" datetime="2022-01-18T21:15:24+08:00">2022-01-18</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/" itemprop="url" rel="index"><span itemprop="name">环境安装</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="一-K8S1-20-x的重要更新"><a href="#一-K8S1-20-x的重要更新" class="headerlink" title="一.K8S1.20.x的重要更新"></a>一.K8S1.20.x的重要更新</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、Kubectl debug 设置一个临时容器</span><br><span class="line">2、Sidecar </span><br><span class="line">3、Volume：更改目录权限，fsGroup</span><br><span class="line">4、ConfigMap和Secret</span><br><span class="line"></span><br><span class="line">K8S官网：https://kubernetes.io/docs/setup/</span><br><span class="line">最新版高可用安装：https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/</span><br></pre></td></tr></table></figure>

<h2 id="二-K8S1-20-x的安装"><a href="#二-K8S1-20-x的安装" class="headerlink" title="二.K8S1.20.x的安装"></a>二.K8S1.20.x的安装</h2><h2 id="2-1-集群规划"><a href="#2-1-集群规划" class="headerlink" title="2.1 集群规划"></a>2.1 集群规划</h2><table>
<thead>
<tr>
<th align="center">主机名</th>
<th align="center">IP地址</th>
<th align="center">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="center">k8s-worker6</td>
<td align="center">X.X.X.X</td>
<td align="center">master节点</td>
</tr>
<tr>
<td align="center">k8s-worker7</td>
<td align="center">X.X.X.X</td>
<td align="center">worker01节点</td>
</tr>
<tr>
<td align="center">k8s-worker8</td>
<td align="center">X.X.X.X</td>
<td align="center">worker02节点</td>
</tr>
</tbody></table>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看Centos版本</span></span><br><span class="line">cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.9.2009 (Core)</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#https://www.cnblogs.com/liucx/</span></span></span><br></pre></td></tr></table></figure>

<h2 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> master节点</span></span><br><span class="line">hostnamectl set-hostname k8s-worker6</span><br><span class="line"><span class="meta">#</span><span class="bash">node1节点</span></span><br><span class="line">hostnamectl set-hostname k8s-worker7</span><br><span class="line"><span class="meta">#</span><span class="bash">node2节点</span></span><br><span class="line">hostnamectl set-hostname k8s-worker8</span><br></pre></td></tr></table></figure>

<h2 id="所有节点配置hosts，修改-etc-hosts如下："><a href="#所有节点配置hosts，修改-etc-hosts如下：" class="headerlink" title="所有节点配置hosts，修改/etc/hosts如下："></a><strong>所有节点配置hosts，修改/etc/hosts如下：</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">所有节点配置hosts，修改/etc/hosts如下：</span><br><span class="line"></span><br><span class="line">cat /etc/hosts </span><br><span class="line"></span><br><span class="line">::1    localhost	localhost.localdomain	localhost6	localhost6.localdomain6</span><br><span class="line">127.0.0.1 localhost  localhost</span><br><span class="line"></span><br><span class="line">X.X.X.X k8s-worker8  k8s-worker8</span><br><span class="line">X.X.X.X k8s-worker6  k8s-worker6</span><br><span class="line">X.X.X.X k8s-worker7  k8s-worker7</span><br></pre></td></tr></table></figure>

<h2 id="2-2-更新配置-（所有节点全部安装）"><a href="#2-2-更新配置-（所有节点全部安装）" class="headerlink" title="2.2 更新配置 （所有节点全部安装）"></a>2.2 <strong>更新配置 （所有节点全部安装）</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点安装</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Centos 7安装yum源如下：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 更改为国内阿里yum源</span></span><br><span class="line">[root@k8s-worker6 ~]# curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line">[root@k8s-worker6 ~]# yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line">[root@k8s-worker6 ~]# yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">[root@k8s-worker6 ~]# cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line">[root@k8s-worker6 ~]# sed -i -e &#x27;/mirrors.cloud.aliyuncs.com/d&#x27; -e &#x27;/mirrors.aliyuncs.com/d&#x27; /etc/yum.repos.d/CentOS-Base.repo</span><br></pre></td></tr></table></figure>

<h2 id="安装必备工具"><a href="#安装必备工具" class="headerlink" title="安装必备工具"></a>安装必备工具</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# yum install wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git -y</span><br></pre></td></tr></table></figure>

<h2 id="所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下："><a href="#所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下：" class="headerlink" title="所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下："></a>所有节点关闭防火墙、selinux、dnsmasq、swap。服务器配置如下：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# systemctl disable --now firewalld </span><br><span class="line">[root@k8s-worker6 ~]# systemctl disable --now dnsmasq</span><br><span class="line">[root@k8s-worker6 ~]# systemctl disable --now NetworkManager</span><br><span class="line"></span><br><span class="line">[root@k8s-worker6 ~]# setenforce 0</span><br><span class="line">[root@k8s-worker6 ~]# sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/sysconfig/selinux</span><br><span class="line">[root@k8s-worker6 ~]# sed -i &#x27;s#SELINUX=enforcing#SELINUX=disabled#g&#x27; /etc/selinux/config</span><br></pre></td></tr></table></figure>

<h2 id="关闭swap分区（所有节点）"><a href="#关闭swap分区（所有节点）" class="headerlink" title="关闭swap分区（所有节点）"></a>关闭swap分区（所有节点）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">[root@k8s-worker6 ~]# sed -ri &#x27;/^[^#]*swap/s@^@#@&#x27; /etc/fstab</span><br></pre></td></tr></table></figure>

<h2 id="时钟同步"><a href="#时钟同步" class="headerlink" title="时钟同步"></a>时钟同步</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装同步时钟ntpdate</span></span><br><span class="line">[root@k8s-worker6 ~]# rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm</span><br><span class="line">[root@k8s-worker6 ~]# yum install ntpdate -y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有节点同步时间。时间同步配置如下：</span></span><br><span class="line">[root@k8s-worker6 ~]# ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br><span class="line">[root@k8s-worker6 ~]# echo &#x27;Asia/Shanghai&#x27; &gt;/etc/timezone</span><br><span class="line">[root@k8s-worker6 ~]# ntpdate time2.aliyun.com</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 加入到crontab,每5分钟同步一次</span></span><br><span class="line">[root@k8s-worker6 ~]# crontab -e</span><br><span class="line">*/5 * * * * ntpdate time2.aliyun.com</span><br></pre></td></tr></table></figure>

<h2 id="配置limit"><a href="#配置limit" class="headerlink" title="配置limit"></a>配置limit</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# ulimit -SHn 65535</span><br><span class="line">[root@k8s-worker6 ~]# vim /etc/security/limits.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 末尾添加如下内容</span></span><br><span class="line">* soft nofile 655360</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 655350</span><br><span class="line">* hard nproc 655350</span><br><span class="line">* soft memlock unlimited</span><br><span class="line">* hard memlock unlimite</span><br></pre></td></tr></table></figure>

<h2 id="配置免密登录"><a href="#配置免密登录" class="headerlink" title="配置免密登录"></a>配置免密登录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Master01节点免密钥登录其他节点：</span></span><br><span class="line">[root@k8s-worker6 ~]# ssh-keygen -t rsa</span><br><span class="line">[root@k8s-worker6 ~]# ssh-copy-id -i root@172.26.119.239</span><br><span class="line">[root@k8s-worker6 ~]# ssh-copy-id -i root@172.26.119.240</span><br></pre></td></tr></table></figure>

<h2 id="所有节点升级重启"><a href="#所有节点升级重启" class="headerlink" title="所有节点升级重启"></a>所有节点升级重启</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# yum update -y  &amp;&amp; reboot </span><br></pre></td></tr></table></figure>

<h2 id="下载安装源码文件"><a href="#下载安装源码文件" class="headerlink" title="下载安装源码文件"></a>下载安装源码文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root/</span><br><span class="line">git clone https://github.com/dotbalo/k8s-ha-install.git     </span><br></pre></td></tr></table></figure>

<h2 id="2-3-Linux内核升级（所有节点）"><a href="#2-3-Linux内核升级（所有节点）" class="headerlink" title="2.3 Linux内核升级（所有节点）"></a>2.3 Linux内核升级（所有节点）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CentOS7 需要升级内核至4.18+  https://www.kernel.org/ 和 https://elrepo.org/linux/kernel/el7/x86_64/</span><br><span class="line">CentOS 7 dnf可能无法安装内核</span><br><span class="line">[root@k8s-worker6 ~]# dnf --disablerepo=\* --enablerepo=elrepo -y install kernel-ml kernel-ml-devel</span><br><span class="line">[root@k8s-worker6 ~]# grubby --default-kernel</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用如下指令查看内核版本</span></span><br><span class="line">[root@k8s-worker6 ~]# uname -a</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用如下指令安装最新内核</span></span><br><span class="line"><span class="meta">#</span><span class="bash">导入ELRepo软件仓库的公共秘钥</span></span><br><span class="line">[root@k8s-worker6 ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line"><span class="meta">#</span><span class="bash">安装ELRepo软件仓库的yum源</span></span><br><span class="line">[root@k8s-worker6 ~]# rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看最新版内核</span></span><br><span class="line">[root@k8s-worker6 ~]# yum --disablerepo=&quot;*&quot; --enablerepo=&quot;elrepo-kernel&quot; list available</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装最新版内核</span></span><br><span class="line">[root@k8s-worker6 ~]# yum --enablerepo=elrepo-kernel install kernel-ml kernel-ml-devel –y</span><br><span class="line">[root@k8s-worker6 ~]# reboot</span><br><span class="line"><span class="meta">#</span><span class="bash"> 更改内核顺序</span></span><br><span class="line">[root@k8s-worker6 ~]# grub2-set-default  0 &amp;&amp; grub2-mkconfig -o /etc/grub2.cfg &amp;&amp; grubby --args=&quot;user_namespace.enable=1&quot; --update-kernel=&quot;$(grubby --default-kernel)&quot; &amp;&amp; reboot</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开机查看内核</span></span><br><span class="line">[root@k8s-worker6 ~]# uname -a</span><br></pre></td></tr></table></figure>

<h2 id="安装ipvsadm"><a href="#安装ipvsadm" class="headerlink" title="安装ipvsadm"></a>安装ipvsadm</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点安装ipvsadm</span></span><br><span class="line">[root@k8s-worker6 ~]# yum install ipvsadm ipset sysstat conntrack libseccomp -y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有节点配置ipvs模块，在内核4.19+版本nf_conntrack_ipv4已经改为nf_conntrack。</span></span><br><span class="line">[root@k8s-worker6 ~]# vim /etc/modules-load.d/ipvs.conf</span><br><span class="line">[root@k8s-worker6 ~]# systemctl enable --now systemd-modules-load.service</span><br></pre></td></tr></table></figure>

<h2 id="开启一些k8s集群中必须的内核参数，所有节点配置k8s内核："><a href="#开启一些k8s集群中必须的内核参数，所有节点配置k8s内核：" class="headerlink" title="开启一些k8s集群中必须的内核参数，所有节点配置k8s内核："></a>开启一些k8s集群中必须的内核参数，所有节点配置k8s内核：</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line">vm.overcommit_memory=1</span><br><span class="line">vm.panic_on_oom=0</span><br><span class="line">fs.inotify.max_user_watches=89100</span><br><span class="line">fs.file-max=52706963</span><br><span class="line">fs.nr_open=52706963</span><br><span class="line">net.netfilter.nf_conntrack_max=2310720</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 3</span><br><span class="line">net.ipv4.tcp_keepalive_intvl =15</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 36000</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_max_orphans = 327680</span><br><span class="line">net.ipv4.tcp_orphan_retries = 3</span><br><span class="line">net.ipv4.tcp_syncookies = 1</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_conntrack_max = 65536</span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384</span><br><span class="line">net.ipv4.tcp_timestamps = 0</span><br><span class="line">net.core.somaxconn = 16384</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> k8s内核装载并应用</span></span><br><span class="line">[root@k8s-worker6 ~]# sysctl --system</span><br></pre></td></tr></table></figure>

<h1 id="三-所有节点K8S基本组件安装"><a href="#三-所有节点K8S基本组件安装" class="headerlink" title="三.所有节点K8S基本组件安装"></a>三.<strong>所有节点K8S基本组件安装</strong></h1><h2 id="3-1-安装docker-ce"><a href="#3-1-安装docker-ce" class="headerlink" title="3.1 安装docker-ce"></a>3.1 安装docker-ce</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# wget https://download.docker.com/linux/centos/7/x86_64/edge/Packages/containerd.io-1.2.13-3.2.el7.x86_64.rpm</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装docker-ce 19.03版本</span></span><br><span class="line">[root@k8s-worker8 ~]# yum install -y docker-ce-cli-19.03.8-3.el7.x86_64 docker-ce-19.03.8-3.el7.x86_64</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看安装的docker版本</span></span><br><span class="line">[root@k8s-worker8 ~]# rpm -qa|grep </span><br></pre></td></tr></table></figure>

<blockquote>
<p>温馨提示：由于新版kubelet建议使用systemd，所以可以把docker的CgroupDriver改成systemd。（重要）</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">&quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启</span></span><br><span class="line">[root@k8s-worker8 ~]# systemctl restart docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看docekr配置文件，主要看Cgroup Driver: systemd</span></span><br><span class="line">[root@k8s-worker7 ~]# docker info</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">启动docker</span></span><br><span class="line">[root@k8s-worker8 ~]# service docker start</span><br><span class="line">[root@k8s-worker8 ~]# chkconfig docker on</span><br></pre></td></tr></table></figure>

<h2 id="3-2安装k8s组件"><a href="#3-2安装k8s组件" class="headerlink" title="3.2安装k8s组件"></a>3.2安装k8s组件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点安装最新版的kubeadm，可以不执行</span></span><br><span class="line">[root@k8s-worker8 ~]# yum install kubeadm -y</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有节点安装指定的K8S组件</span></span><br><span class="line">[root@k8s-worker8 ~]# [root@k8s-worker8 ~]# yum install -y kubeadm-1.22.2-0.x86_64 kubectl-1.22.2-0.x86_64 kubelet-1.22.2-0.x86_64</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 所有节点设置开机启动docker</span></span><br><span class="line">[root@k8s-worker8 ~]# systemctl daemon-reload &amp;&amp; systemctl enable --now docker</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看Docker的状态</span></span><br><span class="line">[root@k8s-worker8 ~]# systemctl status docker</span><br></pre></td></tr></table></figure>

<h2 id="修改iptables相关参数"><a href="#修改iptables相关参数" class="headerlink" title="修改iptables相关参数"></a>修改iptables相关参数</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# vi /etc/sysctl.conf</span><br><span class="line"><span class="meta">#</span><span class="bash">在文件末尾加入右述字段:net.bridge.bridge-nf-call-ip6tables = 1</span></span><br><span class="line">                   net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">[root@k8s-worker8 ~]# sysctl -p</span><br></pre></td></tr></table></figure>

<h2 id="设置kubelet-开机自动启动"><a href="#设置kubelet-开机自动启动" class="headerlink" title="设置kubelet 开机自动启动"></a>设置kubelet 开机自动启动</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# systemctl daemon-reload</span><br><span class="line">[root@k8s-worker8 ~]# systemctl enable --now kubelet</span><br><span class="line">[root@k8s-worker8 ~]# systemctl enable kubelet</span><br></pre></td></tr></table></figure>

<h1 id="四-集群初始化"><a href="#四-集群初始化" class="headerlink" title="四.集群初始化"></a>四.集群初始化</h1><h2 id="4-1-master节点生成kubeadmin-config-yaml文件"><a href="#4-1-master节点生成kubeadmin-config-yaml文件" class="headerlink" title="4.1 master节点生成kubeadmin-config.yaml文件"></a>4.1 <strong>master节点生成kubeadmin-config.yaml文件</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# kubeadm config print init-defaults &gt; kubeadmin-config.yaml</span><br></pre></td></tr></table></figure>

<p>将生成的kubeadmin-config.yaml文件移动到/root/yaml/目录下，下面为未修改之前的yaml文件，将其中的四处部分修改为本机地址：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]<span class="comment"># mkdir -p yaml</span></span><br><span class="line">[root@k8s-worker6 ~]<span class="comment"># mv kubeadmin-config.yaml /root/yaml/</span></span><br><span class="line">[root@k8s-worker6 yaml]<span class="comment"># cat kubeadmin-config.yaml </span></span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">bootstrapTokens:</span><br><span class="line">- groups:</span><br><span class="line">  - system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">  token: abcdef.0123456789abcdef</span><br><span class="line">  ttl: 24h0m0s</span><br><span class="line">  usages:</span><br><span class="line">  - signing</span><br><span class="line">  - authentication</span><br><span class="line">kind: InitConfiguration</span><br><span class="line">localAPIEndpoint:</span><br><span class="line">  advertiseAddress: 1.2.3.4 <span class="comment">#该处修改为master节点ip地址</span></span><br><span class="line">  bindPort: 6443</span><br><span class="line">nodeRegistration:</span><br><span class="line">  criSocket: /var/run/dockershim.sock</span><br><span class="line">  imagePullPolicy: IfNotPresent</span><br><span class="line">  name: node  <span class="comment"># 该处修改为主机名称,如k8s-worker6</span></span><br><span class="line">  taints: null</span><br><span class="line">---</span><br><span class="line">apiServer:</span><br><span class="line">  timeoutForControlPlane: 4m0s</span><br><span class="line">apiVersion: kubeadm.k8s.io/v1beta3</span><br><span class="line">certificatesDir: /etc/kubernetes/pki</span><br><span class="line">clusterName: kubernetes</span><br><span class="line">controllerManager: &#123;&#125;</span><br><span class="line">dns: &#123;&#125;  <span class="comment"># 该处修改为:去掉大括号，修改如下：dns:</span></span><br><span class="line">         <span class="comment">#                                    type: CoreDNS</span></span><br><span class="line"></span><br><span class="line">etcd:</span><br><span class="line">  <span class="built_in">local</span>:</span><br><span class="line">    dataDir: /var/lib/etcd</span><br><span class="line">imageRepository: k8s.gcr.io </span><br><span class="line">kind: ClusterConfiguration</span><br><span class="line">kubernetesVersion: 1.22.0  <span class="comment">#修改为当前所装的K8S版本,1.22.2通过  kubelet --version 查看</span></span><br><span class="line">networking:</span><br><span class="line">  dnsDomain: cluster.local</span><br><span class="line">  serviceSubnet: 10.96.0.0/12</span><br><span class="line">scheduler: &#123;&#125;</span><br></pre></td></tr></table></figure>

<h2 id="所有节点拉取Kubeadm初始化需要的镜像"><a href="#所有节点拉取Kubeadm初始化需要的镜像" class="headerlink" title="所有节点拉取Kubeadm初始化需要的镜像"></a>所有节点拉取<strong>Kubeadm初始化需要的镜像</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 yaml]# kubeadm config images pull --config /root/yaml/kubeadm-config.yaml</span><br></pre></td></tr></table></figure>

<p>上述命令可能会提示连接超时，原因是谷歌的镜像仓库在国内无法访问，修改kubeadm-config.yaml中镜像仓库的地址：imageRepository为registry.cn-hangzhou.aliyuncs.com/google_containers，然后再次运行上述信息。</p>
<p>也可以采用如下方法拉取初始化需要的镜像：</p>
<h3 id="4-2-1-首先使用如下命令查看需要下载的镜像信息"><a href="#4-2-1-首先使用如下命令查看需要下载的镜像信息" class="headerlink" title="4.2.1 首先使用如下命令查看需要下载的镜像信息"></a>4.2.1 <strong>首先使用如下命令查看需要下载的镜像信息</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 yaml]# kubeadm config images list</span><br><span class="line">k8s.gcr.io/kube-apiserver:v1.22.2</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.22.2</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.22.2</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.22.2</span><br><span class="line">k8s.gcr.io/pause:3.5</span><br><span class="line">k8s.gcr.io/etcd:3.5.0-0</span><br><span class="line">k8s.gcr.io/coredns/coredns:v1.8.4</span><br></pre></td></tr></table></figure>

<h3 id="4-2-2-kubeadm初始化默认使用的镜像仓库是k8s-gcr-io，为了解决问题，我们可以使用国内云计算厂商都提供了kubernetes-的镜像服务。"><a href="#4-2-2-kubeadm初始化默认使用的镜像仓库是k8s-gcr-io，为了解决问题，我们可以使用国内云计算厂商都提供了kubernetes-的镜像服务。" class="headerlink" title="4.2.2 kubeadm初始化默认使用的镜像仓库是k8s.gcr.io，为了解决问题，我们可以使用国内云计算厂商都提供了kubernetes****的镜像服务。"></a>4.2.2 <strong>kubeadm<strong><strong>初始化默认使用的镜像仓库是</strong></strong>k8s.gcr.io<strong><strong>，为了解决问题，我们可以使用国内云计算厂商都提供了</strong></strong>kubernetes****的镜像服务。</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 yaml]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.22.2</span><br><span class="line">[root@k8s-worker6 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.22.2</span><br><span class="line">[root@k8s-worker6 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.22.2</span><br><span class="line">[root@k8s-worker6 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.22.2</span><br><span class="line">[root@k8s-worker6 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5</span><br><span class="line">[root@k8s-worker6 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.0-0</span><br><span class="line">[root@k8s-worker6 ~]# docker pull registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4</span><br></pre></td></tr></table></figure>

<h3 id="4-2-3-将下载后的镜像打上tag，来符合kudeadm-init初始化时候的要求。"><a href="#4-2-3-将下载后的镜像打上tag，来符合kudeadm-init初始化时候的要求。" class="headerlink" title="4.2.3 将下载后的镜像打上tag，来符合kudeadm init初始化时候的要求。"></a>4.2.3 <strong>将下载后的镜像打上tag，来符合kudeadm init初始化时候的要求。</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-apiserver:v1.22.2 k8s.gcr.io/kube-apiserver:v1.22.2</span><br><span class="line">[root@k8s-worker8 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-controller-manager:v1.22.2  k8s.gcr.io/kube-controller-manager:v1.22.2</span><br><span class="line">[root@k8s-worker8 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-scheduler:v1.22.2   k8s.gcr.io/kube-scheduler:v1.22.2</span><br><span class="line">[root@k8s-worker8 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/kube-proxy:v1.22.2   k8s.gcr.io/kube-proxy:v1.22.2</span><br><span class="line">[root@k8s-worker8 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/pause:3.5   k8s.gcr.io/pause:3.5</span><br><span class="line">[root@k8s-worker8 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/etcd:3.5.0-0   k8s.gcr.io/etcd:3.5.0-0</span><br><span class="line">[root@k8s-worker8 ~]# docker tag registry.cn-hangzhou.aliyuncs.com/google_containers/coredns:v1.8.4   k8s.gcr.io/coredns/coredns:v1.8.4</span><br></pre></td></tr></table></figure>

<h3 id="4-2-4-查看镜像信息"><a href="#4-2-4-查看镜像信息" class="headerlink" title="4.2.4 查看镜像信息"></a>4.2.4 查看镜像信息</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# docker images</span><br></pre></td></tr></table></figure>

<h2 id="4-3-Master节点kubeadm初始化"><a href="#4-3-Master节点kubeadm初始化" class="headerlink" title="4.3 Master节点kubeadm初始化"></a>4.3 <strong>Master节点kubeadm初始化</strong></h2><h3 id="4-3-1Master节点初始化"><a href="#4-3-1Master节点初始化" class="headerlink" title="4.3.1Master节点初始化"></a>4.3.1<strong>Master节点初始化</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 yaml]# kubeadm init --config /root/yaml/kubeadmin-config.yaml --upload-certs</span><br></pre></td></tr></table></figure>

<p>运行结果部分：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join masterIP:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:0a5d83cbe09bed069aa62a16e52c4f71beb1fec8b2fd63dd6365ab125e0315ff </span><br></pre></td></tr></table></figure>

<h3 id="4-3-2-Master节点配置环境变量，用于访问Kubernetes集群"><a href="#4-3-2-Master节点配置环境变量，用于访问Kubernetes集群" class="headerlink" title="4.3.2 Master节点配置环境变量，用于访问Kubernetes集群**"></a>4.3.2 Master节点配置环境变量，用于访问Kubernetes集群**</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# cat &lt;&lt;EOF &gt;&gt; /root/.bashrc</span><br><span class="line">export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">EOF</span><br><span class="line">[root@k8s-worker6 ~]# source /root/.bashrc</span><br></pre></td></tr></table></figure>

<h3 id="4-3-3-master节点执行"><a href="#4-3-3-master节点执行" class="headerlink" title="4.3.3 master节点执行"></a>4.3.3 <strong>master节点执行</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# mkdir -p $HOME/.kube</span><br><span class="line">[root@k8s-worker6 ~]# sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">[root@k8s-worker6 ~]# sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>

<h3 id="4-3-4-node节点加入集群"><a href="#4-3-4-node节点加入集群" class="headerlink" title="4.3.4 node节点加入集群"></a>4.3.4 <strong>node节点加入集群</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">在Node 节点执行，使用kubeadm join 注册Node节点到Matser</span></span><br><span class="line"><span class="meta">#</span><span class="bash">kubeadm join 的内容，在上面kubeadm init 已经生成好了</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重启kubelet</span></span><br><span class="line">[root@k8s-worker7 ~]# systemctl restart kubelet</span><br><span class="line">[root@k8s-worker7 ~]# systemctl status kubelet</span><br></pre></td></tr></table></figure>

<p>查看Kubelet的状态，如果不是running状态，查看日志查找原因</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# journalctl -xeu kubelet &gt; 1.txt</span><br><span class="line">[root@k8s-worker8 ~]# sz 1.txt</span><br></pre></td></tr></table></figure>

<p>查找失败原因并解决，常见的失败原因是因为kubelet cgroup driver: &quot;systemd&quot; is different from docker cgroup driver: &quot;cgroupfs\</p>
<p>解决方案如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker8 ~]# cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> &#123;<span class="string">&quot;exec-opts&quot;</span>: [<span class="string">&quot;native.cgroupdriver=systemd&quot;</span>]&#125;</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> EOF</span></span><br><span class="line">[root@k8s-worker8 ~]# systemctl restart docker</span><br><span class="line">[root@k8s-worker8 ~]# docker info</span><br><span class="line">[root@k8s-worker8 ~]# systemctl start kubelet</span><br><span class="line">[root@k8s-worker8 ~]# systemctl status kubelet</span><br></pre></td></tr></table></figure>

<p>如果kubelet的状态为running，则在各个worker节点上面执行初始化生成的kubeadm join 指令。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker7 ~]kubeadm join masterIP:6443 --token abcdef.0123456789abcdef \</span><br><span class="line">	--discovery-token-ca-cert-hash sha256:0a5d83cbe09bed069aa62a16e52c4f71beb1fec8b2fd63dd6365ab125e0315ff </span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>这个token24小时后会失效，如果后面有其他节点要加入的话，处理方法：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> kubeadm token create</span></span><br><span class="line">[root@k8s-master ~]# kubeadm token create</span><br><span class="line">0w3a92.ijgba9ia0e3scicg</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]# kubeadm token list</span><br><span class="line">TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION                                                EXTRA GROUPS</span><br><span class="line">0w3a92.ijgba9ia0e3scicg   23h       2019-09-08T22:02:40+08:00   authentication,signing   &lt;none&gt;                                                     system:bootstrappers:kubeadm:default-node-token</span><br><span class="line">t0ehj8.k4ef3gq0icr3etl0   22h       2019-09-08T20:58:34+08:00   authentication,signing   The default bootstrap token generated by &#x27;kubeadm init&#x27;.   system:bootstrappers:kubeadm:default-node-token</span><br><span class="line"></span><br><span class="line">[root@k8s-master ~]# openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | openssl dgst -sha256 -hex | sed &#x27;s/^.* //&#x27;</span><br><span class="line">ce07a7f5b259961884c55e3ff8784b1eda6f8b5931e6fa2ab0b30b6a4234c09a</span><br><span class="line"></span><br><span class="line">然后加入集群</span><br><span class="line">kubeadm join 172.26.119.238:6443 --token yhns57.4s3y2yll21ew8mta \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:ce07a7f5b259961884c55e3ff8784b1eda6f8b5931e6fa2ab0b30b6a4234c09a</span><br></pre></td></tr></table></figure>

<h3 id="4-3-5-查看集群状态"><a href="#4-3-5-查看集群状态" class="headerlink" title="4.3.5 查看集群状态"></a>4.3.5 查看集群状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 yaml]# kubectl get nodes</span><br></pre></td></tr></table></figure>

<h3 id="4-3-6-查看cs状态"><a href="#4-3-6-查看cs状态" class="headerlink" title="4.3.6 查看cs状态"></a>4.3.6 <strong>查看cs状态</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# kubectl get cs</span><br></pre></td></tr></table></figure>

<p>如若为status为unhealthy，则执行下述操作：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# vi /etc/kubernetes/manifests/kube-scheduler.yaml</span><br><span class="line">[root@k8s-worker6 ~]# vi /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 将两个文件中的- --port=0这一行注释掉</span></span></span><br></pre></td></tr></table></figure>

<h2 id="4-4-安装flannel插件-Master节点"><a href="#4-4-安装flannel插件-Master节点" class="headerlink" title="4.4 安装flannel插件(Master节点)"></a>4.4 <strong>安装flannel插件(Master节点)</strong></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# curl -o kube-flannel.yml https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure>

<p>如果显示超时，直接复制下述文件，下面为kube-flannel.yml文件的具体内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">apiVersion: policy/v1beta1</span><br><span class="line">kind: PodSecurityPolicy</span><br><span class="line">metadata:</span><br><span class="line">  name: psp.flannel.unprivileged</span><br><span class="line">  annotations:</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default</span><br><span class="line">    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default</span><br><span class="line">    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default</span><br><span class="line">    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default</span><br><span class="line">spec:</span><br><span class="line">  privileged: <span class="literal">false</span></span><br><span class="line">  volumes:</span><br><span class="line">  - configMap</span><br><span class="line">  - secret</span><br><span class="line">  - emptyDir</span><br><span class="line">  - hostPath</span><br><span class="line">  allowedHostPaths:</span><br><span class="line">  - pathPrefix: <span class="string">&quot;/etc/cni/net.d&quot;</span></span><br><span class="line">  - pathPrefix: <span class="string">&quot;/etc/kube-flannel&quot;</span></span><br><span class="line">  - pathPrefix: <span class="string">&quot;/run/flannel&quot;</span></span><br><span class="line">  readOnlyRootFilesystem: <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Users and groups</span></span><br><span class="line">  runAsUser:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  supplementalGroups:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  fsGroup:</span><br><span class="line">    rule: RunAsAny</span><br><span class="line">  <span class="comment"># Privilege Escalation</span></span><br><span class="line">  allowPrivilegeEscalation: <span class="literal">false</span></span><br><span class="line">  defaultAllowPrivilegeEscalation: <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Capabilities</span></span><br><span class="line">  allowedCapabilities: [<span class="string">&#x27;NET_ADMIN&#x27;</span>, <span class="string">&#x27;NET_RAW&#x27;</span>]</span><br><span class="line">  defaultAddCapabilities: []</span><br><span class="line">  requiredDropCapabilities: []</span><br><span class="line">  <span class="comment"># Host namespaces</span></span><br><span class="line">  hostPID: <span class="literal">false</span></span><br><span class="line">  hostIPC: <span class="literal">false</span></span><br><span class="line">  hostNetwork: <span class="literal">true</span></span><br><span class="line">  hostPorts:</span><br><span class="line">  - min: 0</span><br><span class="line">    max: 65535</span><br><span class="line">  <span class="comment"># SELinux</span></span><br><span class="line">  seLinux:</span><br><span class="line">    <span class="comment"># SELinux is unused in CaaSP</span></span><br><span class="line">    rule: <span class="string">&#x27;RunAsAny&#x27;</span></span><br><span class="line">---</span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: [<span class="string">&#x27;extensions&#x27;</span>]</span><br><span class="line">  resources: [<span class="string">&#x27;podsecuritypolicies&#x27;</span>]</span><br><span class="line">  verbs: [<span class="string">&#x27;use&#x27;</span>]</span><br><span class="line">  resourceNames: [<span class="string">&#x27;psp.flannel.unprivileged&#x27;</span>]</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">&quot;&quot;</span></span><br><span class="line">  resources:</span><br><span class="line">  - pods</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">&quot;&quot;</span></span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - <span class="string">&quot;&quot;</span></span><br><span class="line">  resources:</span><br><span class="line">  - nodes/status</span><br><span class="line">  verbs:</span><br><span class="line">  - patch</span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: flannel</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: flannel</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">kind: ConfigMap</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-cfg</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">data:</span><br><span class="line">  cni-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;name&quot;</span>: <span class="string">&quot;cbr0&quot;</span>,</span><br><span class="line">      <span class="string">&quot;cniVersion&quot;</span>: <span class="string">&quot;0.3.1&quot;</span>,</span><br><span class="line">      <span class="string">&quot;plugins&quot;</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">&quot;type&quot;</span>: <span class="string">&quot;flannel&quot;</span>,</span><br><span class="line">          <span class="string">&quot;delegate&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;hairpinMode&quot;</span>: <span class="literal">true</span>,</span><br><span class="line">            <span class="string">&quot;isDefaultGateway&quot;</span>: <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="string">&quot;type&quot;</span>: <span class="string">&quot;portmap&quot;</span>,</span><br><span class="line">          <span class="string">&quot;capabilities&quot;</span>: &#123;</span><br><span class="line">            <span class="string">&quot;portMappings&quot;</span>: <span class="literal">true</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  net-conf.json: |</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="string">&quot;Network&quot;</span>: <span class="string">&quot;10.244.0.0/16&quot;</span>,</span><br><span class="line">      <span class="string">&quot;Backend&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;Type&quot;</span>: <span class="string">&quot;vxlan&quot;</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-flannel-ds</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    tier: node</span><br><span class="line">    app: flannel</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: flannel</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        tier: node</span><br><span class="line">        app: flannel</span><br><span class="line">    spec:</span><br><span class="line">      affinity:</span><br><span class="line">        nodeAffinity:</span><br><span class="line">          requiredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">            nodeSelectorTerms:</span><br><span class="line">            - matchExpressions:</span><br><span class="line">              - key: kubernetes.io/os</span><br><span class="line">                operator: In</span><br><span class="line">                values:</span><br><span class="line">                - linux</span><br><span class="line">      hostNetwork: <span class="literal">true</span></span><br><span class="line">      priorityClassName: system-node-critical</span><br><span class="line">      tolerations:</span><br><span class="line">      - operator: Exists</span><br><span class="line">        effect: NoSchedule</span><br><span class="line">      serviceAccountName: flannel</span><br><span class="line">      initContainers:</span><br><span class="line">      - name: install-cni</span><br><span class="line">        image: quay.io/coreos/flannel:v0.14.0</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - cp</span><br><span class="line">        args:</span><br><span class="line">        - -f</span><br><span class="line">        - /etc/kube-flannel/cni-conf.json</span><br><span class="line">        - /etc/cni/net.d/10-flannel.conflist</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: cni</span><br><span class="line">          mountPath: /etc/cni/net.d</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: /etc/kube-flannel/</span><br><span class="line">      containers:</span><br><span class="line">      - name: kube-flannel</span><br><span class="line">        image: quay.io/coreos/flannel:v0.14.0</span><br><span class="line">        <span class="built_in">command</span>:</span><br><span class="line">        - /opt/bin/flanneld</span><br><span class="line">        args:</span><br><span class="line">        - --ip-masq</span><br><span class="line">        - --kube-subnet-mgr</span><br><span class="line">        resources:</span><br><span class="line">          requests:</span><br><span class="line">            cpu: <span class="string">&quot;100m&quot;</span></span><br><span class="line">            memory: <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">          limits:</span><br><span class="line">            cpu: <span class="string">&quot;100m&quot;</span></span><br><span class="line">            memory: <span class="string">&quot;50Mi&quot;</span></span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: <span class="literal">false</span></span><br><span class="line">          capabilities:</span><br><span class="line">            add: [<span class="string">&quot;NET_ADMIN&quot;</span>, <span class="string">&quot;NET_RAW&quot;</span>]</span><br><span class="line">        env:</span><br><span class="line">        - name: POD_NAME</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.name</span><br><span class="line">        - name: POD_NAMESPACE</span><br><span class="line">          valueFrom:</span><br><span class="line">            fieldRef:</span><br><span class="line">              fieldPath: metadata.namespace</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: run</span><br><span class="line">          mountPath: /run/flannel</span><br><span class="line">        - name: flannel-cfg</span><br><span class="line">          mountPath: /etc/kube-flannel/</span><br><span class="line">      volumes:</span><br><span class="line">      - name: run</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /run/flannel</span><br><span class="line">      - name: cni</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/cni/net.d</span><br><span class="line">      - name: flannel-cfg</span><br><span class="line">        configMap:</span><br><span class="line">          name: kube-flannel-cfg</span><br></pre></td></tr></table></figure>

<h3 id="使用kubectl安装flannel插件"><a href="#使用kubectl安装flannel插件" class="headerlink" title="使用kubectl安装flannel插件"></a>使用kubectl安装flannel插件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装flannel插件</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl apply -f kube-flannel.yml</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次查看node状态，此时应该全为Ready状态</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl get nodes</span><br></pre></td></tr></table></figure>

<h3 id="4-4-1部署flannel网络插件时发现flannel-pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr"><a href="#4-4-1部署flannel网络插件时发现flannel-pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr" class="headerlink" title="4.4.1部署flannel网络插件时发现flannel pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr"></a>4.4.1<strong>部署flannel网络插件时发现flannel pod一直处于CrashLoopBackOff状态，查看日志提示没有分配cidr</strong></h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看pods运行状态</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl get pods --all-namespaces</span><br><span class="line"><span class="meta">#</span><span class="bash"> 针对失败的pods通过日志查找原因</span></span><br><span class="line">[root@k8s-worker6 yaml]# kubectl logs kube-flannel-ds-2qhdt -n kube-system</span><br></pre></td></tr></table></figure>

<p>解决方法如下,master节点修改/etc/kubernetes/manifests/kube-controller-manager.yaml文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# vim /etc/kubernetes/manifests/kube-controller-manager.yaml</span><br><span class="line">增加参数：</span><br><span class="line">--allocate-node-cidrs=true</span><br><span class="line">--cluster-cidr=10.244.0.0/16</span><br><span class="line">重启kubelet</span><br><span class="line">[root@k8s-worker6 ~]# systemctl restart kubelet</span><br><span class="line">[root@k8s-worker6 yaml]# kubectl get pods --all-namespaces</span><br></pre></td></tr></table></figure>

<h2 id="4-5-Master节点添加自动补全脚本到系统"><a href="#4-5-Master节点添加自动补全脚本到系统" class="headerlink" title="4.5 Master节点添加自动补全脚本到系统"></a>4.5 Master节点添加自动补全脚本到系统</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-worker6 ~]# yum install -y bash-completion</span><br><span class="line">[root@k8s-worker6 ~]# source /usr/share/bash-completion/bash_completion</span><br><span class="line">[root@k8s-worker6 ~]# source &lt;(kubectl completion bash)</span><br><span class="line">[root@k8s-worker6 ~]# echo &quot;source &lt;(kubectl completion bash)&quot; &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2022/01/15/%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99%E6%9C%89%E6%95%88%E7%9A%84%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2022/01/15/%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99%E6%9C%89%E6%95%88%E7%9A%84%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B/" class="post-title-link" itemprop="url">如何编写有效的测试用例</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-15 14:45:51" itemprop="dateCreated datePublished" datetime="2022-01-15T14:45:51+08:00">2022-01-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E6%B5%8B%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">测试</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="什么是测试用例？"><a href="#什么是测试用例？" class="headerlink" title="什么是测试用例？"></a>什么是测试用例？</h4><p>测试用例包含描述输入、动作或事件以及预期响应的组件，以确定应用程序的功能是否正常工作。</p>
<h4 id="测试用例的级别："><a href="#测试用例的级别：" class="headerlink" title="测试用例的级别："></a>测试用例的级别：</h4><ul>
<li> 级别 1: 您将根据可用的规范和用户文档编写基本的测试用例。</li>
<li> 级别 2: 这是一个实践阶段，在这个阶段，编写测试用例依赖于应用程序的实际功能和系统流程。</li>
<li>级别3 : 你将分组一些测试用例，并编写一个测试程序。测试过程只不过是一组小的测试用例，通常最多包含 10 个。</li>
<li>级别 4: 测试用例自动化。这个阶段将帮助测试人员将测试工作集中在新的功能上，而测试自动化将负责回归测试。</li>
</ul>
<h4 id="如何开始编写测试用例？"><a href="#如何开始编写测试用例？" class="headerlink" title="如何开始编写测试用例？"></a>如何开始编写测试用例？</h4><p>当您获得软件需求规格(SRS)文档时，您将首先通过需求来理解应用程序的功能和范围。一旦获得了正在开发的功能的完整概述，您将开始为分配给您的模块编写测试用例。首先，将从涵盖 SRS 文档中提到的所有业务规则的功能测试用例开始。</p>
<p>在编写测试用例时，最好从特定页面或屏幕上的所有需求开始。因此会写以下：<br>● 功能测试，<br>● 业务规则测试，<br>● 导航测试(链接、按钮等)),<br>● 集成测试(与其他模块的集成)，<br>● 安全测试，<br>● 端到端测试，<br>● 阴性测试，<br>● 负载和性能测试</p>
<h4 id="如何减少测试用例的编写和执行时间？"><a href="#如何减少测试用例的编写和执行时间？" class="headerlink" title="如何减少测试用例的编写和执行时间？"></a>如何减少测试用例的编写和执行时间？</h4><p>● 使用标准测试用例模板来编写所有的测试用例<br>● 在开始编写测试用例之前，清楚地理解需求。<br>● 遵循基于测试类型序列编写测试用例的方法。例如，首先开始编写功能测试用例，然后继续进行用户界面、兼容性、安全性等等。<br>● 如果没有使用任何测试管理工具，那么请使用微软Excel电子表格来编写测试用例。微软 Excel的功能非常强大，你可以用很少的时间编写很多类似的测试用例。例如，为了编写一个包含许多字段的长表单的测试用例，大多数测试用例都是重复的，只是字段名发生了变化。您可以使用电子表格函数在几分钟内编写这些测试用例。如果开始使用测试管理工具，甚至可以导入这些测试用例。建议尽快开始使用。<br>● 为了编写各种排列和组合的测试用例，首先使用真值表格式，然后描述测试用例。<br>● 编写测试用例时使用流程图。这将确保最大的测试覆盖率。此外，您将能够更快地编写涵盖所有用例的测试用例。<br>● 根据应用程序页面/屏幕或用例对您的测试用例进行分组。这两种方法对于维护测试用例都是有用且容易的。</p>
<p>测试执行时间取决于是自动执行还是手动执行。手动测试执行时间因测试用例的复杂性而异，它与编写测试用例所需的时间无关。一个测试用例可能在一分钟内编写完成，但是可能需要几个小时甚至几天的时间来执行。</p>
<p>执行时间也可以通过其他技术来节省，例如对基于web的应用程序使用浏览器自动填充功能。使用此功能，只需单击鼠标即可填写网页数据，因此无需在每次运行测试时输入数据。也可以考虑按顺序执行测试，以便与一个页面相关的所有测试用例(不包括集成和端到端测试)在进入下一个页面之前被执行。</p>
<h4 id="为什么要使用测试管理工具？"><a href="#为什么要使用测试管理工具？" class="headerlink" title="为什么要使用测试管理工具？"></a>为什么要使用测试管理工具？</h4><p>测试管理工具可以用来编写测试用例、管理需求、记录缺陷并将缺陷链接到测试用例并生成测试报告。<br>● 在一个地方组织你所有的测试用例将会帮助你减少你的测试用例管理时间。<br>● 测试管理工具可以随时为您提供测试进度的准确状态，帮助您对软件版本做出一些业务决策。<br>● 如果期限紧迫，您可以根据优先级来验证测试用例。<br>● 可以避免重复的测试用例。<br>● 可以有效地跟踪质量保证状态。<br>● 基于发布版本，容易逐步淘汰测试用例的执行。<br>● 良好的测试覆盖率报告。</p>
<h4 id="如何编写测试用例"><a href="#如何编写测试用例" class="headerlink" title="如何编写测试用例"></a>如何编写测试用例</h4><p>测试用例标识:每个测试用例的唯一标识。遵循一些惯例来指明测试的类型。例如‘TC _ UI _ 1’表示‘用户界面测试用例# 1’。</p>
<p>测试优先级(低/中/高):这在测试执行时很有用。业务规则和功能测试用例的测试优先级可以是中等或更高，而次要的用户界面用例可以是低优先级。测试优先级应由审查者设置。</p>
<p>模块名称–提及主模块或子模块的名称。</p>
<p>测试设计人: 测试人员姓名</p>
<p>测试设计日期: 编写的日期</p>
<p>测试执行人:执行此测试的测试人员的姓名。测试执行后填写。</p>
<p>测试执行日期:测试执行的日期。</p>
<p>先决条件:在执行这个测试用例之前必须满足的任何先决条件。列出成功执行这个测试用例的所有先决条件。</p>
<p>依赖性:提及对其他测试用例或测试需求的任何依赖性。</p>
<p>测试 标题/ / 名 称: 测试用 例标题 。 例如 ，使 用有效的用户名和密码验证 登 录 页。</p>
<p>测试 总 结/ / 描述: 简 要描述 测试目 标 。</p>
<p>测试步骤:详细列出所有测试执行步骤。按照应该执行的顺序编写测试步骤。确保提供尽可能多的细节。提示-为了有效地管理具有较少字段的测试用例，使用这个字段来描述测试条件、测试数据和运行测试的用户角色。</p>
<p>测试数据:使用测试数据作为这个测试用例的输入。您可以为不同的数据集提供精确的值作为输入。</p>
<p>预期结果:测试执行后系统输出应该是什么？详细描述预期结果，包括应在屏幕上显示的消息/错误。</p>
<p>后 置 条 件: : 执 行这 个 测试用 例 后 ， 系统应 该 是 什么状态？</p>
<p>实际结果:实际测试结果应在测试执行后填写。描述测试执行后的系统行为。</p>
<p>状态( 通 过/  失 败 ): 如 果 实 际结 果 不 符 合 预 期结 果 ， 将 该 测试 标 记 为 失 败 。 否则 更 新 为 通过。</p>
<p>注释/评论/问题:要支持上述字段，如果有一些特殊情况无法在上述任何字段中描述，或者有与预期或实际结果相关的问题，请在此处提及。</p>
<p>如 有 必要 ， 添 加 以 下 字段：</p>
<p>缺陷标识/链接:如果测试状态为失败，则包括到缺陷日志的链接或提及缺陷号。</p>
<p>测试类型/关键字:此字段可用于根据测试类型对测试进行分类。例如功能、可用性、业务规则等。</p>
<p>需求:为其编写测试用例的需求。最好是需求文档的准确章节号。</p>
<p>附件/参考:此字段对于复杂的测试场景非常有用。使用visio图表作为参考来解释测试步骤或预期结果。提供图表或文档实际路径的链接或位置。</p>
<p>自动化 ？( 是/ 否 ): 这 个 测试用 例 是 否 是自动化的。 当 测试用 例 自动化 时 ， 跟踪自动化状态很有用。</p>
<h4 id="测试用例语句基本格式"><a href="#测试用例语句基本格式" class="headerlink" title="测试用例语句基本格式"></a>测试用例语句基本格式</h4><p>核实</p>
<p>使用【工具名、标签名、对话框等】</p>
<p>有【条件】</p>
<p>返回【返回、显示、演示的内容】</p>
<p>验证:用作测试用例语句的第一个单词。</p>
<p>使用:识别正在测试的内容。在这里，您可以使用“输入”或“选择”，而不是使用“视情况而定”。</p>
<p>所有的测试用例都应该简单易懂。不要写长篇大论的解释</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2022/01/08/%E4%BB%80%E4%B9%88%E6%98%AFYARN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2022/01/08/%E4%BB%80%E4%B9%88%E6%98%AFYARN/" class="post-title-link" itemprop="url">YARN原理及工作流？</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-08 06:55:01" itemprop="dateCreated datePublished" datetime="2022-01-08T06:55:01+08:00">2022-01-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="YRAN是什么？"><a href="#YRAN是什么？" class="headerlink" title="YRAN是什么？"></a>YRAN是什么？</h4><p>YARN是hadoop集群中另一个资源管理者，为需要在Hadoop集群上执行的各种作业分配资源。在Hadoop 2.0中引入的。在Hadoop 2.0中引入了YARN，使用它能够超越MapReduce。</p>
<p><img src="Framework-Supported-by-YARN.jpg" alt="Framework-Supported-by-YARN"></p>
<p>正如你在图中看到的，我们在两者之间的底部有HDFS，我们有YARN并使用YARN，很多框架都能够连接和利用HDFS。因此，即使MapReduce也用于使用YARN进行连接以请求资源，并且只有这样它才能通过HDFS（即Hadoop Cluster）执行作业。</p>
<p>同样;SPARK，STORM和其他搜索引擎可以连接到HDFS。HBase是一个No SQL数据库也可以连接它。因此，HDFS的应用变得庞大，因为YARN能够为其他框架和其他大数据分析工具更好的分配资源。</p>
<h4 id="Hadoop-2-x-守护进程"><a href="#Hadoop-2-x-守护进程" class="headerlink" title="Hadoop 2.x 守护进程"></a>Hadoop 2.x 守护进程</h4><p>让我们快速看一下Hadoop 2.0中新引入的守护进程，它们运行组件，即存储和处理。</p>
<p>在HDFS一文中，我们详细理解了守护进程，即NameNode和DataNode。在此，我们将了解资源管理器和节点管理器如何在 Hadoop 2.x 群集中工作，以管理需要在 Hadoop 群集中执行的处理和作业。</p>
<p><img src="Hadoop-2-Daemons.jpg" alt="Hadoop-2-Daemons"></p>
<p>什么是资源管理器？资源管理器是在主计算机或 NameNode（高端计算机）上运行的主守护程序。另一方面，节点管理器是在从属机器或DataNodes上运行的守护进程，或者与DataNode进程一起运行。</p>
<h4 id="Hadoop-2-x-MapReduce-YARN-组件"><a href="#Hadoop-2-x-MapReduce-YARN-组件" class="headerlink" title="Hadoop 2.x MapReduce YARN 组件"></a>Hadoop 2.x MapReduce YARN 组件</h4><p>首先我们探讨下YARN的其他组件：</p>
<ul>
<li><strong>客户端：</strong>它是一个提交类似作业的命令行界面 （CLI） 的单元，客户端可以是 JAVA 应用程序。</li>
<li><strong>资源管理器：</strong>它是一个主守护程序，所有作业都从客户端提交到该守护程序，并且是分配所有群集级别资源以执行特定作业的主守护程序。它运行在具有高质量硬件和良好配置的高端计算机上，因为它是必须管理群集上所有内容的主计算机。</li>
<li><strong>节点管理器</strong>：它是一个在从属机器或DataNode上运行的从属守护进程，因此每个从属机器都有一个运行的节点管理器。它监视特定 DataNode 的资源，资源管理器管理群集资源，节点管理器管理 DataNode 资源。</li>
<li><strong>作业历史记录服务器：</strong>它是跟踪已在群集上执行或已提交到群集的所有作业的单元。它还跟踪状态，并保留在Hadoop集群上发生的每次执行的日志文件。</li>
<li><strong>应用程序主</strong>设备：它是一个通过节点计算机（从属计算机）执行的组件，由资源管理器创建以执行和管理作业。它是从资源管理器协商资源并最终与节点管理器协调以执行任务的那个。</li>
<li><strong>容器：</strong>它由节点管理器本身创建，该节点管理器已由资源管理器分配，所有作业最终在容器中执行。</li>
</ul>
<h4 id="YARN工作流程"><a href="#YARN工作流程" class="headerlink" title="YARN工作流程"></a>YARN工作流程</h4><p><img src="YARN-Work-Flow.jpg" alt="YARN-Work-Flow"></p>
<p>如上图所示，有一个资源管理器，所有作业都已提交到该管理器，并且有一个群集，其中有从属计算机，并且在每台从属计算机上，都有一个节点管理器正在运行。</p>
<p>资源管理器有两个组件，即计划程序和应用程序管理器。</p>
<p>应用程序主服务器和应用程序管理器之间有什么区别？</p>
<p>应用程序管理器是资源管理器的一个组件，可确保执行每个任务并为其创建应用程序主节点。另一方面，应用程序主服务器是执行任务并请求需要执行的所有资源的人员。</p>
<p>假设作业已提交到资源管理器，一旦作业提交，计划程序就会计划该作业。一旦计划程序计划要执行的作业，应用程序管理器将在其中一个DataNode 中创建一个容器，并且在此容器中，将启动应用程序主节点。</p>
<p>然后，此应用程序主机将向资源管理器注册，并请求容器来执行任务。分配容器后，应用程序主节点现在将与节点管理器连接，并请求启动容器。</p>
<p>正如我们所看到的，应用程序主节点被分配给DataNodes D和E，现在这个应用程序主节点请求节点管理器启动DataNode D和DataNode E的容器。</p>
<p>一旦容器启动，应用程序主服务器将在容器内执行任务，结果将发送回客户端。</p>
<h4 id="作业执行流程"><a href="#作业执行流程" class="headerlink" title="作业执行流程"></a>作业执行流程</h4><p>我们以一种顺序的方式理解资源申请流程。</p>
<p><img src="Sequence-of-Execution.jpg" alt="Sequence-of-Execution"></p>
<p>图中有四个组件，一个是客户端（client），一个是资源管理器（resource manager），一个是节点管理器（node manager），一个是程序主节点（application master）</p>
<p>第一步是将作业提交给资源管理器的客户端，在第二步中，资源管理器分配一个容器以启动从属计算机上的应用程序主站;第三步是应用程序主机向资源管理器注册。</p>
<p>一旦它注册，它就会请求容器执行任务，即第四步。在步骤 5 中，应用程序主机通知需要在其上启动容器的节点管理器。</p>
<p>在第六步中，节点管理器启动容器后，应用程序主机将在这些容器中执行代码。</p>
<p>最后，在第七步中，客户端联系资源管理器或应用程序主机以监视应用程序状态。</p>
<p>最后，应用程序主机将从资源管理器中注销自身，并将结果返回给客户端。因此，这是一个简单的顺序流，说明如何使用YARN框架执行MapReduce程序。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2022/01/03/%E4%BB%80%E4%B9%88%E6%98%AFMapReduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2022/01/03/%E4%BB%80%E4%B9%88%E6%98%AFMapReduce/" class="post-title-link" itemprop="url">MapReduce是什么？</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-03 09:01:16" itemprop="dateCreated datePublished" datetime="2022-01-03T09:01:16+08:00">2022-01-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="为什么需要MapReduce？"><a href="#为什么需要MapReduce？" class="headerlink" title="为什么需要MapReduce？"></a>为什么需要MapReduce？</h4><p><img src="Map-Reduce.jpg" alt="Map-Reduce"></p>
<p>MapReduce是**”处理单元”，**使用此组件，我们可以处理存储在Hadoop HDFS上的大数据。</p>
<p>但确切的要求是为什么我们需要Hadoop的这个组件？</p>
<p>存储在Hadoop HDFS上的大数据和传统存储不一样。数据被划分为存储在各个DataNodes中的数据块。因此，整个数据不会存储在一个集中的位置。</p>
<p>因此，像Java这样的本机客户端应用程序或任何此类应用程序无法以当前格式处理数据，我们需要一个特殊的框架来处理存储在各个DataNodes中的碎片化数据块。</p>
<p>处理是使用Hadoop MapReduce处理完成的。</p>
<h4 id="MapReduce简述"><a href="#MapReduce简述" class="headerlink" title="MapReduce简述"></a>MapReduce简述</h4><p><img src="NutShell-MapReduce.jpg" alt="NutShell-MapReduce"></p>
<p>如图所示显示了MapReduce的功能和用途。</p>
<p>让我们从MapReduce的应用程序开始及如何应用。它用于分类器，索引和搜索，以及在电子商务网站（Flipkart，Amazon等）上创建推荐引擎。它也被几家公司用作分析。</p>
<p>当我们从功能的角度来看，它是一个编程模型，可以用于像Hadoop HDFS这样的大规模分布式模型，并且具有并行编程的功能，使其非常有用。</p>
<p>当我们在Map Reduce中看到函数时，会执行两个函数，即Map Function和Reduce函数。</p>
<p>这项技术已经由谷歌，雅虎，Facebook等主要组织实施，也被Apache Hadoop采用，如HDFS，PIG，HIVE，并使用HBase存储数据或执行和处理大数据，也称为No-SQL。</p>
<h5 id="MapReduce的优点"><a href="#MapReduce的优点" class="headerlink" title="MapReduce的优点"></a>MapReduce的优点</h5><p>1、并行处理</p>
<p><img src="Advantage.jpg" alt="Advantage"></p>
<p>整个数据块被Hadoop HDFS分成HDFS块，MapReduce并行处理这些数据块，因此处理变得很快。</p>
<p>2、数据局部性</p>
<p>这是Hadoop MapReduce给出的一个多功能的东西，即我们可以在它所在的位置处理数据。</p>
<p><em><strong>这是什么意思？</strong></em></p>
<p>在之前的HDFS教程中，我们了解到我们移动到Hadoop Cluster中的数据被划分为HDFS块，这些块被保存到SlaveMachines或DataNodes中。Map-Reduce将处理和逻辑感知到数据驻留在HDFS块中的相应从节点或DataNodes。</p>
<p>处理在多个位置的较小数据块上并行执行。这节省了大量时间以及将大数据从一个位置移动到另一个位置所需的网络带宽。</p>
<p>请记住，我们正在处理的数据是分解成块的大数据，如果我们开始将大数据直接通过分配的网络通道移动到集中式计算机中并对其进行处理，那么它将不会给我们带来任何优势，因为我们将消耗整个带宽将数据移动到集中式服务器。</p>
<p>因此，使用Hadoop MapReduce，我们不只是在进行”并行处理”，我们还将数据处理到存在数据块的相应从节点或DataNodes上，因此我们也”节省了大量网络带宽”，这是非常有益的。</p>
<p>最后，SlaveMachines完成了对存储在SlaveMachines的数据的处理，它们将结果发送回主机器，因为结果不如SlaveMachines上存储的块大。因此，它不会占用大量带宽。</p>
<p>从属计算机将结果发送回主计算机，这些结果将聚合在一起，最终结果将发送回提交作业的客户端计算机。</p>
<p><em><strong>如何决定哪些数据应该在哪个DataNode上处理？</strong></em></p>
<p>客户端将作业提交给资源管理器，资源管理器是提供在数据所在的相应 DataNode 上执行作业的方向的资源管理器，它根据最近的可用 DataNode 做出决定，以便不会使用大量网络带宽。</p>
<h4 id="传统方式VSMapReduce方式"><a href="#传统方式VSMapReduce方式" class="headerlink" title="传统方式VSMapReduce方式"></a>传统方式VSMapReduce方式</h4><p>假设有五个保险公司分支机构，人们来申请人寿保险单。现在，还有一家保险公司的总部，该总部拥有有关可用和所在分支机构的所有信息。</p>
<p>但是，当人们来各自的分行A，B，C，D，E申请人寿保险时，保单申请保留在各自的分行本身，并且该信息不会与保险公司总部共享。</p>
<p>1、传统方式</p>
<p>传统为了上解决这个问题，所有申请将被转移到保险公司总部，然后申请过程将开始。</p>
<p>在这种情况下，我们需要将所有申请转移到保险公司总部，这是一件代价高昂的事情，即必须从保险公司分支机构收集所有申请并将其带到保险公司总部。</p>
<p>这就是成本以及进行此活动的巨大努力的方式。</p>
<p><img src="Traditional-way-1.jpg" alt="Traditional-way-1"></p>
<p><img src="Traditional-way-2.jpg" alt="Traditional-way-2"></p>
<p>另一个方面是保险公司总部负担过重，因为它必须处理人民在各自分支机构申请保单的所有申请。</p>
<p>由于保险公司正在处理所有分支机构都适用的申请，因此需要很长时间。最后，这个过程效果不是很好。</p>
<p>2、MapReduce方式</p>
<p>MapReduce遵循Data Locality，即它不会将所有应用程序带到保险公司总部，而是并行处理各个分支机构本身的应用程序。</p>
<p><img src="MapReduce-Way.jpg" alt="MapReduce-Way"></p>
<p>一旦应用于每个分支机构的申请得到处理，他们就会将处理后的详细信息发回保险公司总部。</p>
<p>现在，保险公司总部只需要汇总从各自分支机构发送的已处理申请的数量，并将详细信息保存在各自的数据库或存储中心。</p>
<p>通过这种方式，处理将非常容易和快速，保单持有人可以立即获得福利。</p>
<h4 id="MapReduce运行原理"><a href="#MapReduce运行原理" class="headerlink" title="MapReduce运行原理"></a>MapReduce运行原理</h4><p>在前面的示例中，我们有一个分布在各个分支之间的输入（应用程序），每个输入都由相应的 Map 函数处理。</p>
<p>我们知道MapReduce有两个函数，即Map Function和Reduce Function。</p>
<p>在各个分支上完成的处理部分由 Map 函数完成。因此，每个分支机构中的每个输入（应用程序）都使用Map函数进行处理，之后处理后的详细信息被发送到保险公司总部，聚合部分由Reduce功能完成。</p>
<p>聚合的已处理应用程序详细信息作为输出提供。</p>
<p><img src="MapReduce-in-Detail.jpg" alt="MapReduce-in-Detail"></p>
<p>这就是我们前面的例子中发生的事情。整个过程分为map任务和reduce任务。</p>
<p>映射任务获取输入，映射任务的输出作为输入提供给 Reduce 任务，此 Reduce 任务最终将输出提供给客户端。</p>
<p>为了更好地理解它，让我们来了解一下MapReduce的解剖结构。</p>
<p><img src="Anatomy-of-MapReduce.jpg" alt="Anatomy-of-MapReduce"></p>
<p>MapReduce任务在键值对上工作，因此当我们谈论Map时，Map将输入作为键值，并将输出作为键值列表给出。此键值列表将经历随机播放阶段，键的输入和值列表将转到化简器。</p>
<p>最后，Reducer 为我们提供了键值对的列表。</p>
<h4 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h4><ul>
<li>Hadoop Map Reduce是Hadoop的”处理单元”。</li>
<li>为了处理Hadoop HDFS存储的大数据，我们使用Hadoop Map Reduce。</li>
<li>它用于搜索和索引，分类，推荐和分析。</li>
<li>它具有编程模型，并行编程和大规模分布式模型等功能。</li>
<li>MapReduce的设计模式是：汇总，热门记录的分类，排序和分析，如连接和选择。</li>
<li>它只有两个功能，即mapper功能和reducer功能。</li>
<li>并行处理和数据局部性是Hadoop MapReduce的良好优势。</li>
<li>MapReduce的过程分为六个阶段，即输入，拆分，映射，洗牌，减少和最终结果</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2022/01/02/HDFS%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%91%BD%E4%BB%A4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2022/01/02/HDFS%E6%9E%B6%E6%9E%84%E5%8F%8A%E5%91%BD%E4%BB%A4/" class="post-title-link" itemprop="url">HDFS架构及命令</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-02 14:53:07" itemprop="dateCreated datePublished" datetime="2022-01-02T14:53:07+08:00">2022-01-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h4><p><img src="HDFS-Architecture.jpg" alt="HDFS-Architecture"></p>
<p>如图所示，有NameNode，因为已经知道哪个是HDFS架构中的主守护进程，它存储集群中存在的所有DataNode的元数据以及每个DataNode中存在的所有块的信息。</p>
<p>有像Rack-1这样的机架，它有三个DataNodes，Rack-2有两个DataNodes，如图所示。</p>
<p>还有一个应用于所有节点的复制因子。现在有一个客户端可以从DataNode读取数据，还有另一个客户端可以将数据写入这些数据节点。</p>
<p>因此，本质上两种机制是并行的，即读取机制，它是客户端为读取数据而生成的请求，而写入机制是为客户端写入数据而生成的。这就是客户端将数据移动到DataNode或Hadoop 集群中的方式。</p>
<h4 id="HDFS读写机制"><a href="#HDFS读写机制" class="headerlink" title="HDFS读写机制"></a>HDFS读写机制</h4><h5 id="写"><a href="#写" class="headerlink" title="写"></a>写</h5><p><img src="Write-Mechanism-in-HDFS.jpg" alt="Write-Mechanism-in-HDFS"></p>
<p>如图所示HDFS写入机制，客户端可以提出写入文件或读取文件的请求。步骤1表示客户端为块A生成的写入请求NameNode，NameNode的作用是它感知客户端可以写入块的IP地址列表，即块A。</p>
<p>现在，此客户端连接到交换机，然后最终向 DataNode 1、DataNode 4 和 DataNode 6 发送通知，为什么此 DataNode 本身，是因为这些是由 NameNode、NameNode 指定的 DataNode 发送的数据节点，数据必须写入 DataNode 1、4 和 6 中，这就是为什么客户端同时连接到所有这三个 DataNode 的原因。</p>
<p><img src="HDFS-Write-PipeLine.jpg" alt="HDFS-Write-PipeLine"></p>
<p>在第一步中，客户端从所有这些 DataNode 中获取确认，无论它们是否准备好对它们执行写入操作。它可能就像DataNode正在执行任务一样，目前还不可用。因此，第一步是接受他们的承认。</p>
<p>一旦他们说他们准备好了，写入管道就会创建。现在，客户端在 DataNode 1、4 和 6 上感知到写入请求，并且第一个副本是在 DataNode 1 中创建的，即在 DataNode 1 中创建/存储或写入的块 A。</p>
<p>然后，下一个副本由 DataNode 1 本身在 DataNode 4 中创建，正如您可以看到核心交换机的箭头所示，首先副本是在 DataNode 1 中创建的，DataNode 1 在 DataNode 4 中创建第二个副本。</p>
<p>现在不是客户端在做这项工作，而是DataNode实际在DataNode 4中创建副本，最后，DataNode 4在DataNode 6上创建副本，即块A的第三个副本。</p>
<p>在 DataNode 6 上创建第三个副本后，它会向 DataNode 4 发送回确认，DataNode 4 会将确认发回 DataNode 1，同样，DataNode 1 会将确认发送回客户端，最后客户端会将成功写回 NameNode 的消息作为确认。</p>
<p>一旦您通过NameNode获得成功消息，它就会在其末端更新元数据，即它将存储块A已存储在DataNode 1，4和6中的信息。因此，当我们谈论块A时，这是整个写入机制，这是按顺序发生的，即按顺序创建副本的副本。</p>
<p><img src="HDFS-Multi-Block-Write-Pipeline.jpg" alt="HDFS-Multi-Block-Write-Pipeline"></p>
<p>当有多个块时，它会变得有点复杂。上图显示，当有多个块（即块 A 和块 B）时，它将遵循相同的过程，就像客户端向 NameNode 发送请求一样。</p>
<p>NameNode 会将 DataNode 的列表返回给客户端，然后客户端将连接到核心交换机。当客户端连接到核心交换机时，它将并行写入两个块的第一个副本。</p>
<p>只需尝试理解这一点，您就可以看到1A和1B，即复制块A和块B的第一步，现在看到2A和2B向机架1的交换机发送请求，并将其他交换机发送到机架5的交换机，现在此交换机（机架1）连接到DataNode 1并创建块A的副本。</p>
<p>同时，客户端还在DataNode 7中创建了块B的副本，因此每个块的第一个副本，即块A和块B，即使有更多的块，块的第一个副本也将并行创建，而不是按顺序创建。</p>
<p>创建第一个副本后，将按顺序创建复制副本。首先，我们将看到块 A，DataNode 1 与 Rack 4 的数据节点 4 中的另一个块 A 副本一起按顺序创建。</p>
<p>创建此副本后，将在同一机架 4 的 DataNode 6 中创建块 A 的另一个副本。同样，块 B 是在 DataNode 9 中创建的，并且将根据发送到交换机的请求，在机架 1 的数据节点 3 中按顺序创建下一个副本。</p>
<p>如果您看到并行创建或写入HDFS的每个块的第一个副本，而这些块的副本由其后续DataNodes本身按顺序创建。</p>
<h5 id="读"><a href="#读" class="headerlink" title="读"></a>读</h5><p>阅读机制更容易理解，因为它非常简单。因此，客户端是发出所有请求的人，就像编写一样，它将从NameNode请求特定块。NameNode将通过存储这些特定块的数据节点发送。</p>
<p><img src="HDFS-Read-Mechanism.jpg" alt="HDFS-Read-Mechanism"></p>
<p>如图所示，客户端已从NameNode请求块A和B，NameNode将DN1（即DataNode 1和DN3，即DataNode 3）的地址发送回客户端计算机。</p>
<p>现在，此客户端计算机将与核心交换机建立连接，它将从 DataNode 1 读取块 A，从 DataNode 3 读取块 B，并将核心交换机设置的此数据发送回客户端计算机。客户端可以将这些数据用于所需的任何目的。</p>
<p>NameNode将确保客户端没有分配用于获取数据或读取数据的工作。</p>
<p>它将确保存储实际数据的DataNodes非常接近，并且客户端不必消耗大量网络带宽来读取数据。这是一件非常关键的事情，由NameNode负责，它有很大帮助。</p>
<h4 id="HDFS命令"><a href="#HDFS命令" class="headerlink" title="HDFS命令"></a>HDFS命令</h4><p>下面列出的是常用的 Hadoop/HDFS 命令。我们需要 FsShell 系统来运行这些命令。首先，从命令提示符转到主目录或工作目录，然后编写命令。</p>
<p><strong>#1）查看HDFS中可用命令的列表。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs–help</span><br></pre></td></tr></table></figure>

<p><strong>#2）在HDFS中创建目录。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs-mkdir &lt;path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#3）查看特定目录下的内容。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs–ls</span><br></pre></td></tr></table></figure>

<p><strong>此外，我们可以将 -d、-h 或 –r 与 ls 命令一起使用。</strong></p>
<ul>
<li>-d 目录列为普通文件。</li>
<li>-h 以人类可读的方式（而不是字节数）格式化文件大小。</li>
<li>-R 递归列出目录的内容</li>
</ul>
<p><strong>#4）查看文件的内容。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs -cat&lt;Path of file&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#5）将文件从本地文件系统复制到HDFS。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs-put &lt;source-path&gt;&lt;destination-path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>此外，我们可以将 –p 或 –f 与 cat 命令一起使用。</strong></p>
<ul>
<li>-p 保留访问和修改时间。</li>
<li>-f 覆盖目标。</li>
</ul>
<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Hadoop fs –copyFromLocal &lt;source-path&gt;&lt;destination-path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#6）将文件从HDFS复制到本地。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs-put &lt;source-hadoop-path&gt;&lt;destination-local-path&gt;</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ Hadoop fs –copyToLocal &lt;source-hadoop-path&gt;&lt;destination-local-path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#7） 删除由路径标识的文件或空目录。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs -rm &lt;File Path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#8）将src标识的文件或目录复制到HDFS中。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs cp &lt;src&gt;&lt;dest&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#9）将src指示的文件或目录移动到HDFS中的dest。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs mv &lt;src&gt;&lt;dest&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#10） 显示磁盘使用情况，以字节为单位。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfsdu &lt;path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#11） 将所有给定本地文件的内容追加到 HDFS 上的给定目标文件中。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs-appendToFile&lt;local files separated by space&gt;&lt;hdfs destination file&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#12） 显示文件的最后 1KB。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs -tail &lt;filename&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#13）在HDFS中创建长度为零的文件。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs-touchz &lt;path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#14） 将文件的复制因子更改为特定名称，而不是 HDFS 中其余文件的复制因子的默认值。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$hadoopfs-setrep&lt;replication factor number&gt;&lt;file/path name&gt;</span><br></pre></td></tr></table></figure>

<p><strong>此外，我们可以将 -r 或 -w 与 -setrep 一起使用。</strong></p>
<ul>
<li>-w 请求命令等待复制完成。</li>
<li>-R 被接受为向后兼容性。</li>
</ul>
<p><strong>#15） 将 HDFS 上一个目录中的文件列表合并到本地文件系统上的单个文件中。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs getmerge &lt;src&gt;&lt;localDest&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#16） 计算路径下的目录、文件和字节数。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs -count &lt;path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#17）显示空间量，以字节为单位。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs -du &lt;path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>此外，我们可以将 -s 或 -h 与 du 命令一起使用。</strong></p>
<ul>
<li>-s 显示总（摘要）大小。</li>
<li>-h 以人类可读的方式格式化文件大小</li>
</ul>
<p><strong>#18） 更改文件的权限。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs chmod [-R] mode,mode,... &lt;path&gt;...</span><br></pre></td></tr></table></figure>

<p>此处，-R 以递归方式修改文件。</p>
<p><strong>#19） 更改文件或路径的组。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoopfs -chgrp [-R] groupname&lt;path&gt;</span><br></pre></td></tr></table></figure>

<p><strong>#20） 更改文件的所有者和组。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -chown [-R] [OWNER][:[GROUP]] PATH</span><br></pre></td></tr></table></figure>

<h4 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h4><p>Hadoop的文件存储结构以及读写机制我们已经了解完成了，下一篇文章，我们会了解下MapReduce数据处理机制。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2022/01/02/HDFS%E7%AE%80%E4%BB%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2022/01/02/HDFS%E7%AE%80%E4%BB%8B/" class="post-title-link" itemprop="url">HDFS简介</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-01-02 08:45:39" itemprop="dateCreated datePublished" datetime="2022-01-02T08:45:39+08:00">2022-01-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="Hadoop-分布式文件系统"><a href="#Hadoop-分布式文件系统" class="headerlink" title="Hadoop 分布式文件系统"></a>Hadoop 分布式文件系统</h4><p><strong>HDFS</strong>解决了大数据的存储问题，<strong>Map Reduce</strong>解决了与处理部分大数据相关的问题。</p>
<h4 id="Hadoop的组件"><a href="#Hadoop的组件" class="headerlink" title="Hadoop的组件"></a>Hadoop的组件</h4><p>HDFS有两个主要组件来解决大数据问题：</p>
<ul>
<li>用于存储大数据的HDFS</li>
<li>用于处理大数据的MapReduce</li>
</ul>
<p><img src="Hadoop-Component-1.jpg" alt="Hadoop-Component-1"></p>
<p>如图所示，Hadoop的架构，一个是HDFS，Hadoop的文件存储系统，一个是YARN和MapReduce，大数据处理部分。</p>
<p>使用HDFS，Hadoop使我们能够存储大数据，使用YARN和Map Reduce，Hadoop使我们能够处理存储在HDFS中的相同大数据。</p>
<p><img src="Hadoop-Core-Components.jpg" alt="Hadoop-Core-Components"></p>
<p>正如您在上图中看到的，HDFS有两个主要的守护进程，或者您可以将它们称为进程或线程，它们只不过是JAVA进程，即在JVM中运行 - NameNode和DataNode。</p>
<p>NameNode是一个在Master Machine上运行的主守护程序，即本质上是高端机器，DataNode是在商用硬件上运行的从机。可以有更多的DataNode，因为从机不仅仅是主机。</p>
<p>因此，我们总是在从属机器上运行一个NameNode和多个DataNode。</p>
<p>同样，我们在另一端有YARN，它又有两个守护进程，一个是运行在主计算机上的资源管理器，另一个是运行在从机上的节点管理器，就像DataNode一样。因此，每台从属机器都有两个守护进程 - 一个是DataNode，另一个是Node Manager。</p>
<p>主计算机正在运行 NameNode 并运行资源管理器。NameNode 负责管理 Hadoop 分布式文件系统上的数据，资源管理器负责对此存储的数据执行处理任务。</p>
<h4 id="name-node-和data-node"><a href="#name-node-和data-node" class="headerlink" title="name node 和data node"></a>name node 和data node</h4><h5 id="name-node"><a href="#name-node" class="headerlink" title="name node"></a>name node</h5><ul>
<li>主守护进程。</li>
<li>管理和维护数据节点。</li>
<li>记录元数据。</li>
<li>接收来自所有 DataNode 的检测信号和阻止报告。</li>
</ul>
<p>data node</p>
<ul>
<li>守护进程。</li>
<li>实际数据存储在此处。</li>
<li>为来自客户端的读取和写入请求提供服务。</li>
</ul>
<p><img src="NameNode-DataNode.jpg" alt="NameNode-DataNode"></p>
<p>有一个集中式机器名称节点，它控制着各种DataNode，即商用硬件。因此，Name Node只不过是维护所有DataNode的主守护进程。</p>
<p>这些名称节点具有有关存储在 DataNode 中的数据的所有信息。DataNode顾名思义，用于存储Hadoop集群中存在的数据。</p>
<p>NameNode仅包含有关哪些数据存储在哪个DataNode上的信息。因此，我们可以说的是NameNode存储存储在DataNodes上的数据的元数据。</p>
<p>DataNode还执行另一项任务，即它定期将检测信号发送回NameNode。心跳实际上告诉NameNode这个DataNode仍然活着。</p>
<p>DataNodes将检测信号发送回NameNode，这样NameNode就可以知道这些数据节点是活跃的，因此NameNode可以使用这些数据节点来存储更多数据或从这些数据节点读取数据。</p>
<p>现在我们来看看DataNode，DataNode只不过是从属守护进程，它实际上存储着发送到Hadoop集群的数据。这些数据节点是实际为客户端发出的读取和写入请求提供服务的节点。</p>
<p>如果有人想从Hadoop集群中读取数据，那么这些请求实际上由数据所在的DataNodes处理。</p>
<h4 id="Hadoop-集群架构"><a href="#Hadoop-集群架构" class="headerlink" title="Hadoop 集群架构"></a>Hadoop 集群架构</h4><p><img src="Hadoop-Cluster.jpg" alt="Hadoop-Cluster"></p>
<p>如图所示，Hadoop 集群r只不过是一个主从拓扑，其中有一个主机器，正如你在顶部看到的那样，即Hadoop 集群。在此主计算机中，有一个 NameNode 和正在运行的资源管理器，即主守护程序。</p>
<p>主机使用核心交换机连接到所有从机，这是因为这些数据节点实际上存储在各种机架中，因此您可以看到计算机1，计算机2，计算机3直到计算机N。这只不过是从属机器或DataNodes，它们都存在于一个机架中。</p>
<h5 id="HDFS将如何存取数据？"><a href="#HDFS将如何存取数据？" class="headerlink" title="HDFS将如何存取数据？"></a>HDFS将如何存取数据？</h5><p>将文件存储在HDFS中时，数据被存储为HDFS中的块。整个文件不存储在HDFS中，这是因为如您所知，Hadoop是一个分布式文件系统。</p>
<p>因此，如果您的文件大小可能为1 PB（Peta Byte），那么这种存储就不会存在于单台计算机中，因为Hadoop集群是使用商用硬件制作的。一台计算机中的硬件大约为 1 TB 或 2 TB。</p>
<p>因此，整个文件需要分解为称为HDFS块的数据块。</p>
<ul>
<li>每个文件都作为块存储在HDFS上。</li>
<li>在Apache Hadoop 2.x中，每个块的默认大小约为128 MB（在以前的版本，即Apache Hadoop 1.x中为64mb）。</li>
<li>有一个工具可以使用Hadoop软件包附带的配置文件（即hdfssite.xml）来增加或减少块的文件大小。</li>
</ul>
<p>让我们在这里考虑一个248 MB的文件，现在如果我们打破这个文件，或者如果我们把这个文件移动到Hadoop Cluster（即2.x）中，那么这个文件将被分解成一个块，即128 MB的块A和另一个120 MB的块B。</p>
<p>如您所见，第一个块为128 MB，即第一个板块在那里削减，这就是为什么另一个块为120 MB而不是128 MB，即如果剩余的文件大小小于默认块大小，则不会浪费任何空间。</p>
<p><img src="Example-Diagram.jpg" alt="Example-Diagram"></p>
<p>现在我们面前还有另一个问题，即每个块的单个副本是否安全？</p>
<p>答案是否定的，因为系统可能会失败，而它只是商品硬件，因此我们可能会遇到大麻烦。为了克服这个问题，Hadoop HDFS有一个很好的解决方案，即**”块的复制”。**</p>
<h5 id="Hadoop-架构块复制"><a href="#Hadoop-架构块复制" class="headerlink" title="Hadoop 架构块复制"></a>Hadoop 架构块复制</h5><p>Hadoop创建存储到Hadoop分布式文件系统中的每个块的副本，这就是Hadoop作为容错系统的方式，即即使您的系统出现故障或DataNode失败或副本丢失，您也会在其他DataNode或其他服务器中存在多个其他副本，以便您始终可以从那里选择这些副本。</p>
<p><img src="Block-Replication.jpg" alt="Block-Replication"></p>
<p>如图所表示块复制，文件有五个不同的块，即块 1、2、3、4、5。让我们先检查一下块 1，您将在节点 1、节点 2 和节点 4 中找到块 1 的副本。</p>
<p>同样，块 2 也有三个副本，即节点 2、节点 3 和节点 4，因此在各自的节点中，块 3、4 和 5 也是如此。</p>
<p>因此，除了创建的副本之外，每个块都被复制了三次，即Hadoop遵循默认的复制因子为3，这意味着您复制到Hadoop分发文件系统中的任何文件都会被复制三次。</p>
<p>换句话说，如果您将1 GB的文件复制到Hadoop分发文件系统中，它实际上将3 GB的文件存储在HDFS中。好的部分是，通过更改Hadoop的配置文件，默认复制因子是可以更改的。</p>
<p>*<strong>Hadoop 如何决定存储副本的位置？*</strong></p>
<p>Hadoop实际上遵循Rack Awareness的概念来决定在哪里存储Block的副本。如图所示机架感知算法图表。</p>
<p><img src="Rack-Awareness-Algorithm.jpg" alt="Rack-Awareness-Algorithm"></p>
<p>Rack-1有四个DataNodes，Rack-2和Rack-3也是如此，因此整个Hadoop集群总共将由所有三个机架组成，并且将有12个DataNode。</p>
<p>假设块 A 在 Rack-1 的 DataNode 1 上复制，根据 Rack Aware 的概念，块 A 的副本不能在同一机架中创建，并且需要在 Rack-1 之外的任何其他机架中创建，因为主文件已经存在于 Rack-1 中。</p>
<p>如果我们在同一机架-1中创建块A的副本，并且如果整个Rack-1发生故障，那么我们肯定会丢失数据，因此副本必须存储在任何其他机架中，而不是存储在Rack-1中。</p>
<p>因此，将在 Rack-2 的 DataNode 6 和 8 中创建副本。同样，对于块 B 和块 C，副本将在不同的机架中创建，如上图所示。</p>
<h4 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h4><ul>
<li>Hadoop HDFS解决了大数据的存储问题。</li>
<li>Hadoop Map Reduce解决了与大数据处理相关的问题。</li>
<li>NameNode 是一个主守护进程，用于管理和维护 DataNode。</li>
<li>DataNode是一个从属守护进程，实际数据存储在这里。它用于读取和写入来自客户端的请求。</li>
<li>在Hadoop Cluster中，机架实际上是一组物理上存在于一个特定位置并相互连接的机器。</li>
<li>每个文件都作为块存储在HDFS上。</li>
<li>在Apache Hadoop 2.x中，每个块的默认大小约为128 MB（在以前的版本，即Apache Hadoop 1.x中为64 MB）。</li>
<li>有一个工具可以使用Hadoop软件包附带的配置文件（即hdfssite.xml）来增加或减少块的文件大小。</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2021/12/27/%E4%BB%80%E4%B9%88%E6%98%AFhadoop%EF%BC%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2021/12/27/%E4%BB%80%E4%B9%88%E6%98%AFhadoop%EF%BC%9F/" class="post-title-link" itemprop="url">hadoop是什么？</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-12-27 19:43:27" itemprop="dateCreated datePublished" datetime="2021-12-27T19:43:27+08:00">2021-12-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Apache Hadoop是一个开源框架，用于管理所有类型的数据（结构化，非结构化和半结构化）。</p>
<p>众所周知，如果我们想处理，存储和管理我们的数据，那么RDBMS是最好的解决方案。但是，数据应采用结构化格式，以便使用 RDBMS 进行处理。此外，如果数据大小增加，则RDBMS无法处理它，我们需要定期执行数据库清理。</p>
<p>这可能会导致历史数据丢失，并且无法在某些行业（如天气预报，银行，保险，销售等）中生成准确可靠的结果。RDBMS的另一个问题是，如果主服务器出现故障，那么我们可能会丢失重要数据并遭受很多损失。</p>
<p>在本教程中，我们将看到如何使用Apache Hadoop克服这些问题。</p>
<p>Hadoop是一个分布式文件系统，可以存储大量数据（PB级和TB级数据）。数据处理速度也非常快，并且具有非常高的容错系统，因此可提供可靠的结果。</p>
<p>Hadoop是一个基于Java的开源编程框架，支持在分布式计算环境中存储和处理大型数据集。</p>
<p>Hadoop基于使用商用硬件的集群概念。它不需要任何复杂的配置，我们可以用更便宜，简单和轻量级的配置硬件建立Hadoop环境。</p>
<p>简而言之，群集概念是以复制格式存储在多台计算机上的数据，因此，当数据所在的某个位置发生任何问题或灾难时，必须在另一个位置上安全地提供该数据的重复副本。</p>
<h4 id="hadoop-VS-RDMBS"><a href="#hadoop-VS-RDMBS" class="headerlink" title="hadoop VS RDMBS"></a>hadoop VS RDMBS</h4><table>
<thead>
<tr>
<th>Feature</th>
<th>Hadoop</th>
<th>RDBMS</th>
</tr>
</thead>
<tbody><tr>
<td><strong>体系结构</strong></td>
<td>Hadoop基于HDFS，MapReduce和YARN。</td>
<td>RDBMS 基于 ACID 属性。</td>
</tr>
<tr>
<td><strong>规模</strong></td>
<td>可以处理大量数据。</td>
<td>RDBMS 无法处理大量数据。</td>
</tr>
<tr>
<td><strong>数据的种类/类型</strong></td>
<td>可以处理结构化，半结构化和非结构化数据，如视频，图像，CSV文件，xml等。</td>
<td>仅处理结构化数据。</td>
</tr>
<tr>
<td><strong>速度</strong></td>
<td>快速处理大量数据。</td>
<td>处理大量数据时非常慢。</td>
</tr>
<tr>
<td><strong>吞吐量</strong></td>
<td>高吞吐量。</td>
<td>吞吐量低。</td>
</tr>
<tr>
<td><strong>容错</strong></td>
<td>非常好</td>
<td>如果主服务器出现故障，则无法恢复丢失的数据。</td>
</tr>
<tr>
<td><strong>存储</strong></td>
<td>非常高的存储容量。</td>
<td>无法存储大数据。</td>
</tr>
<tr>
<td><strong>可靠性</strong></td>
<td>非常可靠，可生成准确的历史和当前报告。</td>
<td>在大数据方面不可靠。</td>
</tr>
</tbody></table>
<h4 id="hadoop-功能"><a href="#hadoop-功能" class="headerlink" title="hadoop 功能"></a>hadoop 功能</h4><p>Hadoop框架</p>
<p><img src="Hadoop-Features.webp" alt="Hadoop-Features"></p>
<ul>
<li>Hadoop yarn</li>
<li>Hadoop common</li>
<li>Hadoop HDFS(Hadoop Distributed File System)</li>
<li>Hadoop Mapreduce</li>
</ul>
<p><strong>#1）Hadoop YARN：YARN</strong>代表**”Y**et <strong>A</strong>nother <strong>R</strong>esource <strong>N</strong>egotiator”，用于管理云的集群技术。它用于作业计划。</p>
<p><strong>#2）Hadoop Common：</strong>这是用于与Hadoop的其他功能（如YARN，MapReduce和HDFS）进行通信的详细库或实用程序。</p>
<p><strong>#3）Hadoop HDFS：</strong>分布式文件系统在Hadoop中用于存储和处理大量数据。此外，它还用于访问群集中的数据。</p>
<p><strong>#4） Hadoop MapReduce：</strong> MapReduce是Hadoop的主要功能，负责处理集群中的数据。它用于作业调度和数据处理监控。</p>
<h4 id="Hadoop-架构"><a href="#Hadoop-架构" class="headerlink" title="Hadoop 架构"></a>Hadoop 架构</h4><p>Hadoop组件：</p>
<ul>
<li>HDFS</li>
<li>MapReduce</li>
<li>YARN</li>
</ul>
<p><img src="Hadoop-framework.png" alt="Hadoop-framework"></p>
<p>这些是Hadoop架构的三个重要组成部分。我们还应该了解架构的一些术语或概念，并了解它们是如何工作的。</p>
<ol>
<li>管理节点–manager node</li>
<li>数据节点–data node</li>
<li>辅助管理节点–secondary manager node </li>
<li>块–blocks</li>
</ol>
<p>1）name node–管理节点</p>
<p>管理节点是 HDFS 中的主节点。它包含HDFS的元数据，如文件信息，目录结构，块信息以及数据节点的所有信息等。管理节点仅负责从客户端访问的数据或文件。它跟踪文件中的所有事务或所做的更改。</p>
<p>它主要适用于两个文件，即FsImage和EditLogs。Name Node有一个JobTracker，其中包含数据节点的所有详细信息，例如哪个数据节点具有什么任务，每个数据节点有多少块，每个数据节点的检测信号，群集中的作业计划详细信息等。</p>
<p>简而言之，我们可以说 JobTracker 包含每个数据节点的 TaskTracker。</p>
<p>2） data node – 数据节点</p>
<p>数据节点是HDFS中的从节点。数据节点负责数据的实际存储和处理。它的主要任务是将作业划分为三个块，并将其存储在不同的数据节点中。之后开始处理数据。</p>
<p>此外，它还具有TaskTracker，它具有每个块的完整信息，以及哪个块负责哪个任务，哪些块完成了任务等，并且在处理数据后，它将信息发送到manager Node。每次数据节点启动时，它都会再次将所有信息发送到管理节点。</p>
<p>3）辅助管理节点–secondary manager node </p>
<p>辅助管理节点用于容错情况。在两种情况下，管理节点已关闭，并且整个 Hadoop 结构将失败，因为管理节点是单点故障。</p>
<p>（i）如果管理节点由于任何问题而重新启动，那么由于它具有大量数据而再次出现，那么恢复它需要时间。</p>
<p>（ii）在管理节点崩溃的情况下，所有HDFS数据都将丢失并且无法再次恢复，因为管理节点是单点故障。因此，为了克服这些问题，辅助管理节点就在那里。它还包含与管理节点相同的命名空间映像和编辑日志。</p>
<p>在一段时间后，它将复制命名空间映像，并从管理节点更新编辑日志。因此，在管理节点失败的情况下，辅助管理节点进入图片并表现得与主名称节点类似。由于此过程，它可以防止完全失败。</p>
<p>4）blocks–块</p>
<p>块是HDFS中最小的单位。Hadoop可以处理大量的文件，因为它将其分成小块。我们可以说，块只不过是一个大文件的数据。每个块的大小为128MB。这些块保存在数据节点中并处理数据。</p>
<p><img src="Components-used-in-Hadoop.png" alt="Components-used-in-Hadoop"></p>
<p>Hadoop 分布式文件系统 （HDFS） 是 Hadoop 集群中使用的文件系统。HDFS主要用于在集群中存储Hadoop数据。HDFS通常致力于顺序数据处理。正如我们已经知道的那样，它基于主从架构。</p>
<p>集群的所有元数据都保存在 JobTracker 的 Name 节点上，实际数据存储在 TaskTracker 的 HDFS 的数据节点中。</p>
<p>MapReduce负责数据的处理。每当任何文件进入集群进行处理时，第一个数据节点都会将其划分为块，每个块包含64MB的数据，它可以存储128MB。然后，每个块将复制两次，并存储在群集中任何位置的不同数据节点中。</p>
<p>所有这些信息都将发送到名称节点，名称节点将以元数据的形式存储此信息。然后，数据的实际处理将启动数据节点，并将每三秒向名称节点发送一次检测信号，以便名称节点具有此数据节点正在处理的信息。</p>
<p>如果数据节点中的任何人发送检测信号失败，则名称节点将再次在另一个数据节点上创建该块的副本并开始处理。</p>
<p>所有这些信息或快照将存储在FsImage中，如果完成任何事务，则编辑日志合并新信息并始终保留日志的新副本。</p>
<p>将采用首先完成任务的块，数据节点将向名称节点发送信息，名称节点将采取相应的操作。</p>
<p>在整个过程中，YARN将支持并向系统提供所需的资源，因此不会影响数据处理和速度。处理数据后，结果将保存在HDFS中以供进一步分析。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2021/12/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%95%B0%E6%8D%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2021/12/19/%E4%BB%80%E4%B9%88%E6%98%AF%E5%A4%A7%E6%95%B0%E6%8D%AE/" class="post-title-link" itemprop="url">大数据是什么？</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-12-19 14:24:32" itemprop="dateCreated datePublished" datetime="2021-12-19T14:24:32+08:00">2021-12-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="什么是大数据？"><a href="#什么是大数据？" class="headerlink" title="什么是大数据？"></a>什么是大数据？</h3><p>“巨大”这个词不足以解释大数据，某些特征将数据分类为大数据。</p>
<p>我们有大数据的三个主要特征，如果任何数据满足这些特征，那么它将被视为大数据。它是下面提到的三个 V 的组合：</p>
<ul>
<li>volume：体积</li>
<li>velocity：速度</li>
<li>variety：多样性</li>
</ul>
<p><img src="Three-Vs.png"></p>
<p>volume：应该是巨大体积的数据。大数据具有维护大量数据的解决方案，这些数据以TB或PB为单位。我们可以轻松有效地对大数据执行CRUD（创建，读取，更新和删除）操作。</p>
<p>volecity：更快地访问数据。如今的社交媒体需要在很短的时间内快速交换数据，而大数据是它的最佳解决方案。因此，速度是另一个特征，它是数据的处理速度。</p>
<p>variety：在社交媒体上，我们正在处理非结构化数据，如音频或视频记录，图像等。此外，银行领域等各个行业都需要结构化和半结构化数据。大数据是在一个地方维护两种类型的数据的解决方案。</p>
<p>多样性意味着不同类型的数据，如多个来源的结构化/非结构化数据。</p>
<p><strong>结构化数据</strong>：具有适当结构的数据或可以轻松存储在任何关系数据库中（如Oracle，SQL Server或MySQL）中的表格形式的数据称为结构化数据。我们可以轻松有效地处理或分析它。</p>
<p>结构化数据的一个例子是存储在关系数据库中的数据，可以使用SQL（结构化查询语言）进行管理。<strong>例如</strong>员工数据（姓名、ID、职称和薪水）可以以表格格式存储。</p>
<p>在传统数据库中，只有在非结构化或半结构化数据格式化或适合关系数据库后，我们才能执行操作或处理数据。结构化数据<strong>的示例</strong>包括 ERP、CRM 等。</p>
<p><strong>半结构化数据：</strong>半结构化数据是未完全格式化的数据。它不存储在数据表或任何数据库中。但是，我们仍然可以轻松准备和处理它，因为此数据包含标记或逗号分隔值等。半结构化数据的示例：XML文件，CSV文件等。</p>
<p><strong>非结构化数据：</strong>非结构化数据是没有任何结构的数据。它可以是任何形式，没有预定义的数据模型。我们无法将其存储在传统数据库中。搜索和处理它很复杂。</p>
<p>此外，非结构化数据的数量也非常高。非结构化数据的示例：电子邮件正文、音频、视频、图像、实现的文档等。</p>
<h4 id="传统数据库的挑战"><a href="#传统数据库的挑战" class="headerlink" title="传统数据库的挑战"></a>传统数据库的挑战</h4><p><img src="Challenges-of-Traditional-Databases.png" alt="Challenges-of-Traditional-Databases"></p>
<ul>
<li>传统数据库不支持各种数据，即它无法处理非结构化和半结构化数据。</li>
<li>传统数据库在处理大量数据时速度很慢。</li>
<li>在传统数据库中，处理或分析大量数据非常困难。</li>
<li>传统数据库能够存储以 TB 或 PB 为单位的数据。</li>
<li>传统数据库无法处理历史数据和报告。</li>
<li>经过一定时间后，需要对数据库进行数据清理。</li>
<li>使用传统数据库，维护大量数据的成本非常高。</li>
<li>传统数据库中的数据准确性较低，因为其中未维护完整的历史数据。</li>
</ul>
<h4 id="与传统数据库相比，大数据的优势"><a href="#与传统数据库相比，大数据的优势" class="headerlink" title="与传统数据库相比，大数据的优势"></a>与传统数据库相比，大数据的优势</h4><p><img src="Advantages-of-BigData-over-Traditional-database.png" alt="Advantages-of-BigData-over-Traditional-database"></p>
<ul>
<li>大数据负责处理、管理和处理不同类型的数据，如结构化、半结构化和非结构化数据。</li>
<li>它在维护大量数据方面具有成本效益。它适用于分布式数据库系统。</li>
<li>我们可以使用大数据技术长时间保存大量数据。因此，处理历史数据和生成准确报告很容易。</li>
<li>数据处理速度非常快，因此社交媒体正在使用大数据技术。</li>
<li>数据准确性是大数据的一大优势。</li>
<li>它允许用户根据当前和历史数据为其业务做出有效的决策。</li>
<li>错误处理、版本控制和客户体验在大数据中非常有效。</li>
</ul>
<h4 id="大数据中的挑战和风险"><a href="#大数据中的挑战和风险" class="headerlink" title="大数据中的挑战和风险"></a>大数据中的挑战和风险</h4><p><strong>挑战：</strong></p>
<ol>
<li>大数据面临的主要挑战之一是管理大量数据。如今，数据来自各种来源的系统，种类繁多。因此，对于公司来说，妥善管理它是一个非常大的挑战。如，要生成包含过去 20 年数据的报告，它需要保存和维护系统过去 20 年的数据。为了提供准确的报告，有必要仅将相关数据放入系统。它不应该包含不相关或不必要的数据，否则保持如此大量的数据对公司来说将是一个巨大的挑战。</li>
<li>该技术的另一个挑战是各种类型数据的同步。众所周知，大数据支持来自不同来源的结构化、非结构化和半结构化数据，因此同步数据并获得数据的一致性非常困难。</li>
<li>公司面临的下一个挑战是专家的差距，他们可以帮助和实施他们在系统中面临的问题。这个领域的人才缺口很大。</li>
<li>处理合规性方面成本高昂。</li>
<li>大数据的数据收集、聚合、存储、分析和报告具有巨大的成本。组织应该能够管理所有这些成本。</li>
</ol>
<p><strong>风险：</strong></p>
<ol>
<li>它可以处理各种数据，但如果公司无法正确理解需求并控制数据源，那么它将提供有缺陷的结果。因此，它将需要大量的时间和金钱来调查和纠正结果。</li>
<li>数据安全是大数据的另一个风险。由于数据量很大，因此有人窃取数据的可能性更高。数据黑客可能会窃取和出售公司的重要信息（包括历史数据）。</li>
<li>此外，数据隐私是大数据的另一个风险。如果我们想保护个人和敏感数据免受黑客攻击，那么它应该受到保护，并且必须通过所有隐私政策。</li>
</ol>
<h4 id="大数据技术"><a href="#大数据技术" class="headerlink" title="大数据技术"></a>大数据技术</h4><ol>
<li>Apache Hadoop</li>
<li>Microsoft HDInsight</li>
<li>No SQL</li>
<li>Hive</li>
<li>Sqoop</li>
<li>BigData in Excel</li>
</ol>
<h4 id="大数据和数据仓库"><a href="#大数据和数据仓库" class="headerlink" title="大数据和数据仓库"></a>大数据和数据仓库</h4><p>数据仓库是我们在讨论Hadoop或大数据测试之前需要了解的基本概念。</p>
<p>让我们从实时示例中了解数据仓库。<strong>例如</strong>，有一家公司在三个不同的国家建立了分支机构，让我们假设在印度，澳大利亚和日本设有分支机构。</p>
<p>在每个分支机构中，整个客户数据存储在本地数据库中。这些本地数据库可以是普通的经典RDBMS，如Oracle或MySQL或SQL Server等，所有客户数据都将每天存储在其中。</p>
<p>现在，每个季度、每半年或每年，组织都希望分析这些数据以进行业务开发。为了做同样的事情，组织将从多个来源收集所有这些数据，然后将其放在一个地方，这个地方被称为**”数据仓库”。**</p>
<p>数据仓库是一种数据库，它包含通过**”ETL”（<strong>即 E xtract、T ransform 和</strong>L**oad）过程从多个源或多个数据库类型中提取的所有数据。数据在数据仓库中准备就绪后，我们可以将其用于分析目的。</p>
<p>因此，为了进行分析，我们可以根据数据仓库中的可用数据生成报告。可以使用商业智能工具生成多个图表和报告。</p>
<p>我们需要数据仓库用于分析目的，以发展业务并为组织做出适当的决策。</p>
<p><img src="Organization-Data-WareHouse.jpg" alt="Organization-Data-WareHouse"></p>
<p>在此过程中发生了三件事，首先是我们从多个源中提取数据，并将其放在数据仓库的单个位置。</p>
<p>在这里，我们使用”ETL”过程，因此在将数据从多个源加载到一个地方时，我们将在转换根中应用它，然后我们可以在这里使用各种ETL工具。</p>
<p>一旦数据准备好进入数据仓库，我们就可以生成各种报告，以使用商业智能（BI）工具分析业务数据，或者我们称之为报告工具。Tableau 或 Cognos 等工具可用于生成报告和 DashBoard，用于分析业务数据。</p>
<h4 id="OLTP-和-OLAP"><a href="#OLTP-和-OLAP" class="headerlink" title="OLTP 和 OLAP"></a>OLTP 和 OLAP</h4><p>本地维护并用于事务目的的数据库称为<strong>OLTP，即联机事务处理。</strong>日常事务将存储在此处并立即更新，这就是为什么我们称它们为OLTP系统。</p>
<p>在这里，我们使用传统数据库，我们有多个表，并且有关系，因此一切都是根据数据库系统地规划的。我们不会将这些数据用于分析目的。在这里，我们可以使用经典的RDMBS数据库，如Oracle，MySQL，SQL Server等。</p>
<p>当我们进入数据仓库部分时，我们使用Teradata或Hadoop系统，它们也是一种数据库，但DataWarehouse中的数据通常用于分析目的，称为<strong>OLAP</strong>或<strong>在线分析处理。</strong></p>
<p>在这里，数据可以每季度，每半年或每年更新一次。有时数据也会”Offerly”更新，其中Offerly表示根据客户要求更新和获取数据以进行分析。</p>
<p>此外，用于分析的数据不会每天更新，因为我们将按计划从多个来源获取数据，并且可以执行此 ETL 任务。这就是在线分析处理系统的工作原理。</p>
<p>同样，BI工具或报告工具可以生成报告以及仪表板，并且基于此，业务人员将做出改进其业务的决策。</p>
<h3 id="大数据从何而来？"><a href="#大数据从何而来？" class="headerlink" title="大数据从何而来？"></a>大数据从何而来？</h3><p>大数据是超出传统数据库的存储和处理能力的数据，它采用结构化和非结构化格式，因此无法由本地RDBMS系统处理。</p>
<p>这种数据将以TB（TB）或PB或更高速率生成，并且现在正在迅速增加。有多个来源可以获得这种数据，例如Facebook，WhatsApp（与社交网络有关）;亚马逊，与电子商务相关的Flipkart;Gmail，Yahoo，Rediff与电子邮件和Google等搜索引擎有关。我们还从手机中获取大数据，例如SMS数据，通话记录，通话记录等。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>大数据是高效、安全地处理大量数据的解决方案。它还负责维护历史数据。这项技术有很多优点，这就是为什么每家公司都想转向大数据</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://hugfeature.github.io/Echo/2021/12/16/JMeter%E5%A4%84%E7%90%86%E5%99%A8%E5%92%8C%E6%8E%A7%E5%88%B6%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/Echo/images/avatar.gif">
      <meta itemprop="name" content="丑牛">
      <meta itemprop="description" content="曾经梦想仗剑走天涯!<br>因为遇见她，所以回了家！">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="青春召唤师">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/Echo/2021/12/16/JMeter%E5%A4%84%E7%90%86%E5%99%A8%E5%92%8C%E6%8E%A7%E5%88%B6%E5%99%A8/" class="post-title-link" itemprop="url">JMeter处理器和控制器</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-12-16 20:50:10" itemprop="dateCreated datePublished" datetime="2021-12-16T20:50:10+08:00">2021-12-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/Echo/categories/%E6%B5%8B%E8%AF%95/" itemprop="url" rel="index"><span itemprop="name">测试</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h5 id="预处理器–pre-processor"><a href="#预处理器–pre-processor" class="headerlink" title="预处理器–pre processor"></a>预处理器–pre processor</h5><p>执行采样器之前执行的元素。您可以将预处理器与要在请求中进行一些更改的采样器连接在一起。</p>
<p>最简单的情况可能是在 HTTP 请求中添加”示例超时”预处理器，以便此请求仅运行定义的时间量。它还确保仅对父采样器执行此修改,以下是JMeter中的预处理器：</p>
<p><img src="image-20211217094257136.png" alt="image-20211217094257136"></p>
<h6 id="用户参数–-user-parameters"><a href="#用户参数–-user-parameters" class="headerlink" title="用户参数– user parameters"></a>用户参数– user parameters</h6><p>用户参数用于在取样器中使用变量之前定义变量的值。当JMeter执行此预处理器元素时，会将值存储在变量中，这些变量可由同一线程组中的任何取样器使用。</p>
<p><img src="image-20211217100245301.png" alt="image-20211217100245301"></p>
<p>示例超时–sample timeout</p>
<p>用于定义请求的超时持续时间。例：如果将取样时间设置为 400 毫秒，则所有需要时间的请求&gt;400 都将具有失败的响应。请看下面的截图</p>
<p><img src="image-20211217134259470.png" alt="image-20211217134259470"></p>
<p><img src="image-20211217134313658.png" alt="image-20211217134313658"></p>
<h5 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h5><p>控制器在构建实时JMeter测试计划方面十分重要，用于定义请求发送到服务器的顺序。JMeter中的控制器有以下：</p>
<p><img src="image-20211217150511568.png" alt="image-20211217150511568"></p>
<h6 id="简单控制器–simple-controller"><a href="#简单控制器–simple-controller" class="headerlink" title="简单控制器–simple controller"></a>简单控制器–simple controller</h6><p>简单的控制器不执行任何特定功能。它只是一种容器，您可以在其中保留类似的请求，以使测试计划易于理解。</p>
<p><img src="image-20211217154100877.png" alt="image-20211217154100877"></p>
<h6 id="循环控制器–Loop-Controller"><a href="#循环控制器–Loop-Controller" class="headerlink" title="循环控制器–Loop Controller"></a>循环控制器–Loop Controller</h6><p>如果希望某些特定请求运行的迭代次数多于”线程组”中指定的迭代次数，则可以将它们放在”循环控制器”下，然后在控制器设置中输入循环计数。</p>
<p><img src="image-20211217154238730.png" alt="image-20211217154238730"></p>
<p>图中的每个取样器将执行6次。</p>
<h6 id="仅一次控制器–once-ONLY-controller"><a href="#仅一次控制器–once-ONLY-controller" class="headerlink" title="仅一次控制器–once ONLY controller"></a>仅一次控制器–once ONLY controller</h6><p>当您只想运行某个特定请求一次时，即使线程组中有多个线程，也会使用此控制器。可以考虑的最简单的例子是”获取网站主页”或”登录到Web应用程序”。实时方案希望它只发生一次，其他请求（如搜索或编辑/删除某些内容）将多次发生。</p>
<p>仅执行一次的请求可以放在”仅一次控制器”下。截图以供参考。一次 只有控制器设置绕过父线程组设置。</p>
<p><img src="image-20211217160551520.png" alt="image-20211217160551520"></p>
<h6 id="录制控制器–HTTP（S）-TEST-Script-Recorder"><a href="#录制控制器–HTTP（S）-TEST-Script-Recorder" class="headerlink" title="录制控制器–HTTP（S） TEST Script Recorder"></a>录制控制器–HTTP（S） TEST Script Recorder</h6><p>就像简单控制器一样，录制控制器不会修改发送到服务器的任何请求序列。它与HTTP（S）脚本记录器一起使用。使用此非测试元素记录的所有请求都保存在记录控制器下。需要指定目标控制器以保存对服务器发出的记录请求。</p>
<p><img src="image-20211217160800045.png" alt="image-20211217160800045"></p>
<h6 id="吞吐量控制器–Throughput-controller"><a href="#吞吐量控制器–Throughput-controller" class="headerlink" title="吞吐量控制器–Throughput controller"></a>吞吐量控制器–Throughput controller</h6><p>此控制器还用于控制执行流。如下图所示，该控制器进一步分为两部分：</p>
<p><img src="image-20211217160905035.png" alt="image-20211217160905035"></p>
<p>执行百分比–Percent Executions ： 选中后 Jmeter 将仅执行此控制器下采样器总迭代的一定百分比。也可以选中”每用户”复选框以在用户级别进行控制。</p>
<p>执行总数– total Executions: 将允许用户直接为此控制器下包含的采样器指定迭代次数。</p>
<h6 id="交错控制器–-interleave-controller"><a href="#交错控制器–-interleave-controller" class="headerlink" title="交错控制器– interleave controller"></a>交错控制器– interleave controller</h6><p>此控制器允许您通过以 n 种方式修改序列来增加性能测试的范围，以便在应用程序以不同的顺序命中请求时测试服务器上的负载。交错控制器在其下方的采样器进行替代选择。</p>
<p>如果此块下有其他控制器（如 Simple Controller），则交错控制器授予从容器中为每个迭代选择一个采样器的权限。为了进一步解释它，见图</p>
<p><img src="image-20211217162333245.png" alt="image-20211217162333245"></p>
<p>Jmeter 将在每次迭代的控制器之间交替迭代。执行顺序为：<em>请求1 -&gt; 请求3 -&gt; 请求 5 – 请求2 -&gt; 请求4 -&gt; 请求6</em></p>
<h6 id="随机控制器–random-controller"><a href="#随机控制器–random-controller" class="headerlink" title="随机控制器–random controller"></a>随机控制器–random controller</h6><p>顾名思义随机选择子控制器和其中的采样器。工作方式几乎与交错控制器类似，但不按顺序选取采样器。</p>
<p>条件控制器–If controller</p>
<p>if 控制器 以类似的方式工作，则以任何编程语言处理 IF 表达式。首先验证条件，然后执行此容器下的组件（如果条件为 TRUE），否则将执行 IF 控制器外部的元素。</p>
<p><img src="image-20211217165030335.png" alt="image-20211217165030335"></p>
<p>测试计划设计如下：如果 IF 条件被评估为<strong>False，</strong>则只有 Request3、Request4 和 Request5 将执行。</p>
<h6 id="while-控制器"><a href="#while-控制器" class="headerlink" title="while 控制器"></a>while 控制器</h6><p>此控制器执行其下的组件，直到条件变为 false。</p>
<h5 id="JMeter的记录模板"><a href="#JMeter的记录模板" class="headerlink" title="JMeter的记录模板"></a>JMeter的记录模板</h5><p>Jmeter的File目录选择template ，然后切换recording</p>
<p><img src="image-20211217165849700.png" alt="image-20211217165849700"></p>
<p>选择此录制模板后，会看到一些组件已添加到测试计划中。</p>
<ul>
<li>工作台下的 HTTP 脚本记录器</li>
<li>HTTP 请求默认值和 HTTP Cookie 管理器</li>
<li>“线程组”下的记录控制器。</li>
<li><img src="image-20211217170049709.png" alt="image-20211217170049709"></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/Echo/archives/page/2/">2</a><a class="page-number" href="/Echo/archives/page/3/">3</a><a class="extend next" rel="next" href="/Echo/archives/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2020 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">丑牛</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/Echo/js/comments.js"></script><script src="/Echo/js/utils.js"></script><script src="/Echo/js/motion.js"></script><script src="/Echo/js/next-boot.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/Echo/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
